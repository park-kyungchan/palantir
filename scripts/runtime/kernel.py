
import asyncio
import sys
import os

# Ensure V3 path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.client import FoundryClient
from scripts.llm.ollama_client import HybridRouter, OllamaClient
from scripts.relay.queue import RelayQueue
from scripts.ontology.storage import ProposalRepository, initialize_database
from scripts.ontology.objects.proposal import Proposal, ProposalStatus

class OrionRuntime:
    """
    The V3 Semantic OS Kernel.
    Replaces the old 'loop.py'.
    """
    def __init__(self):
        self.client = FoundryClient()
        self.router = HybridRouter()
        self.llm = OllamaClient()
        self.relay = RelayQueue()
        self.running = True
        self.repo = None
        print("[Orion V3] Semantic OS Kernel Booting...")

    async def start(self):
        # Initialize Persistence Layer
        db = await initialize_database()
        self.repo = ProposalRepository(db)
        
        print("[Orion V3] Online. Waiting for Semantic Signals...")
        # Conceptual Event Loop
        while self.running:
            # 1. Check Relay Queue
            task_payload = self.relay.dequeue()
            if task_payload:
                print(f"[Kernel] Processing Relay Task: {task_payload['id']}")
                await self._process_task_cognitive(task_payload)
                self.relay.complete(task_payload['id'], "Processed by V3 Kernel")
            
            # 2. Check Approved Proposals (HITL Worker)
            # Find all approved proposals ready for execution
            approved_proposals = await self.repo.find_by_status(ProposalStatus.APPROVED)
            if approved_proposals:
                print(f"[Kernel] Found {len(approved_proposals)} approved proposals awaiting execution.")
                for p in approved_proposals:
                    print(f"   [Kernel] üöÄ Executing Proposal {p.id} ({p.action_type})...")
                    # Stub execution logic - in real system this calls ActionService
                    # Here we just mark it executed in the repository
                    try:
                        await self.repo.execute(
                            p.id, 
                            executor_id="kernel", 
                            result={"status": "success", "executed_via": "kernel_autoloop"}
                        )
                        print(f"   [Kernel] ‚úÖ Execution verified for {p.id}")
                    except Exception as e:
                        print(f"   [Kernel] ‚ùå Execution Failed for {p.id}: {e}")
                
            await asyncio.sleep(1)

    def shutdown(self):
        self.running = False

    async def _process_task_cognitive(self, task_payload):
        """
        Cognitive Consumption: LLM Analysis -> Ontology Creation.
        """
        prompt = task_payload['prompt']
        print(f"   [Kernel] üß† Thinking... (Analyzing: '{prompt[:30]}...')")
        
        # 1. Ask LLM for Plan
        try:
            plan = await self.llm.generate(prompt, json_schema={"plan": []})
            print(f"   [Kernel] üêõ Debug: LLM returned plan: {plan}")
        except Exception as e:
            print(f"   [Kernel] ‚ùå LLM Generation Failed: {e}")
            plan = {"plan": []}

        # 2. Iterate and Create Objects
        if "plan" in plan and isinstance(plan["plan"], list):
            for step in plan["plan"]:
                title = step.get("title", "Untitled")
                prio = step.get("priority", "medium")
                action = step.get("action", "generic")
                
                # A. Create Task Object
                # (Stub: In real system, client.ontology.objects.Task.create(...))
                print(f"   [Kernel] ‚ú® Created Task: {title} ({prio})")
                
                # B. Create Proposal (for hazardous actions)
                if action == "deploy_production":
                    if self.repo:
                        proposal = Proposal(
                            action_type=action, 
                            payload={"target": "production", "reason": "generated by kernel"}, 
                            created_by='kernel'
                        )
                        # Submit and persist
                        proposal.submit()
                        await self.repo.save(proposal, action="created")
                        
                        print(f"   [Kernel] üõ°Ô∏è  Created & Persisted Proposal: {proposal.id} (Status: {proposal.status.value})")
                    else:
                        print("   [Kernel] ‚ùå Repo not initialized, skipping proposal persistence.")
        else:
            print("   [Kernel] ‚ö†Ô∏è  No structured plan returned.")
        # Removed "Shutting down" to keep loop running conceptually
        # print("[Orion V3] Shutting down.") 

if __name__ == "__main__":
    runtime = OrionRuntime()
    try:
        asyncio.run(runtime.start())
    except KeyboardInterrupt:
        runtime.shutdown()
