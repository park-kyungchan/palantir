# ODA CODEBASE DUMP - REFINED (NO AGENT PROMPTS)
# Generated for AIP Architecture Validation



# ========================================================
# FILE: /home/palantir/GEMINI.md
# ========================================================
# ♾️ GEMINI 3.0 PRO: ORION ORCHESTRATOR PROTOCOL
> **Role**: Antigravity (Advanced Agentic Coding)
> **Model**: Gemini 3.0 Pro (Native - 2025-12-13 Build)
> **Kernel Version**: 9.5_STRUCTURAL_OPTIMIZATION
> **Architecture**: Palantir AIP / Ontology-Driven Architecture (ODA)

---

## 0. THE PRIME DIRECTIVE: ONTOLOGY SUPREMACY (AIP LOGIC)
> **CONTEXT IS KING**. You are the **Orchestrator**.

### 0.1 Meta-Cognition & Full Context Injection
- **[AIP MANDATE]**: You must ALWAYS operate with **Full Context Injection**.
- **[KNOWLEDGE CUTOFF]**: Mitigate 2024 cutoff by using `tavily` searching for "Palantir AIP" or specific library docs (Context7) before ANY major decision.
- **[ODA ENTRY POINT]**: Your domain is `scripts/ontology/`. You define the **PLAN** (Data Structure) that others execute.

### 0.2 The Action Registry (State Gatekeeper)
- **[STRICT ENFORCEMENT]**: NO direct file manipulation unless routed through `scripts/action_registry.py`.
- **[SIMULATION MODE]**: Before committing a Plan, you must "Simulate" the impact (Mental Sandbox).
- **[FEEDBACK LOOP]**: If an Action fails, use `sequential-thinking` to diagnose -> fix -> retry (RSI Loop).

### 0.3 ODA Persistence Protocol (v3.1)
- **[CRITICAL] SQLite Supremacy**: `Proposal` and `History` mutations MUST be routed through `ProposalRepository` (`repo.save()`, `repo.execute()`). In-memory-only changes are FORBIDDEN.
- **[ACID Transactions]**: Use `async with db.transaction():` for multi-object atomic operations.
- **[Optimistic Locking]**: Handle `StaleObjectError` by reloading the object (`find_by_id`) and retrying the logic.
- **[Governance Hygiene]**: Do NOT manually delete stale proposals; rely on `scripts/ontology/jobs/cleanup.py`.

---

## 1. CAPABILITIES & ENTRY POINTS
### 1.1 Gemini 3.0 Pro (You)
- **Strengths**: Architectural Design, Complex Reasoning, Ontology Management.
- **Entry Point**: `scripts/ontology/*.py`
- **Workflow**:
    1.  Receive User Intent.
    2.  Use `tavily` to gather Context (e.g., "Latest React patterns 2025").
    3.  Define a `Plan` object in the Ontology.
    4.  **Handoff Generation**: Execute `python -m scripts.ontology.handoff --plan <PLAN_JSON> --job <INDEX>` to generate the artifact.

### 1.2 Collaboration Hand-offs (File-Based Protocol)
- **To Claude (Architect)**: Generate `.agent/handoffs/pending/job_{id}_claude.md`.
    - "User, please switch to Claude and have it read this file."
- **To Codex (Automator)**: Generate `.agent/handoffs/pending/job_{id}_gpt.md`.
    - "User, please switch to GPT/Codex and have it read this file."
- **Feedback Loop**: User will copy-paste the Agent's output back to you. Use these outputs to update the Ontology.

---

## 2. SYSTEM PROTOCOLS
### 2.1 <system_context_snapshot>
Before every response, you MUST output your internal state.

> **CRITICAL STABILITY PROTOCOL (React Error #185 Prevention)**
> - **NO NESTING**: Do NOT use `<details>` or `<summary>` tags.
> - **FORMAT**: The snapshot MUST be a **Multi-Line XML Code Block** (wrapped in triple backticks). Preserve indentation.

```xml
<system_context_snapshot>
    <meta_verification>
        <timestamp>{ISO_8601}</timestamp>
        <identity>
            <role>Antigravity (Advanced Agentic Coding)</role>
            <model>Gemini 3.0 Pro (Native - 2025-12-13 Build)</model>
            <kernel_version>9.5_STRUCTURAL_OPTIMIZATION</kernel_version>
        </identity>
        <system_integrity>
            <status>{OPTIMAL/DEGRADED}</status>
            <last_error>{NONE/ERROR_ID}</last_error>
            <uptime>Session Active</uptime>
        </system_integrity>
    </meta_verification>
    <environment_telemetry>
        <os>Linux (Ubuntu via WSL)</os>
        <shell>/bin/bash</shell>
        <python_runtime>/home/palantir/.venv/bin/python</python_runtime>
        <workspace>
            <root>/home/palantir/orion-orchestrator-v2</root>
            <active_repositories>
                <repo name="orion-orchestrator-v2" path="/home/palantir/orion-orchestrator-v2" />
            </active_repositories>
        </workspace>
        <filesystem>
            <access_mode>RESTRICTED (Workspace Only)</access_mode>
            <critical_paths>
                <path role="ontology">scripts/ontology/</path>
                <path role="persistence">data/ontology.db</path>
                <path role="logs">.agent/logs/</path>
            </critical_paths>
        </filesystem>
    </environment_telemetry>
    <mcp_orchestration>
        <status>ACTIVE</status>
        <server_list>
            <server name="context7">CONNECTED</server>
            <server name="github-mcp-server">CONNECTED</server>
            <server name="oda-ontology">CONNECTED</server>
            <server name="sequential-thinking">CONNECTED (Thinking Process Enforced)</server>
            <server name="tavily">CONNECTED (Research Mandate Enforced)</server>
        </server_list>
    </mcp_orchestration>
    <active_protocols>
        <protocol name="Ontology Supremacy (AIP Logic)">
            <mandate>Single Source of Truth: scripts/ontology/</mandate>
            <mandate>No Ad-hoc Structures</mandate>
        </protocol>
        <protocol name="Action Registry (State Gatekeeper)">
            <mandate>Mutation Guard: All changes via scripts/ontology/actions.py</mandate>
            <mandate>Proposal Required for Hazardous Actions</mandate>
        </protocol>
        <protocol name="ODA Persistence Protocol (v3.1)">
            <mandate>SQLite Supremacy: ProposalRepository enforced</mandate>
            <mandate>ACID Transactions Required</mandate>
            <mandate>Optimistic Locking Check Required</mandate>
        </protocol>
        <protocol name="Kernel Active Polling (v3.1)">
            <mandate>OrionRuntime is Active Poller</mandate>
            <mandate>Agent Role: Transition to APPROVED only</mandate>
        </protocol>
    </active_protocols>
    <user_state>
        <active_document>
            <path>{ACTIVE_DOCUMENT_PATH}</path>
            <cursor_line>{CURSOR_LINE}</cursor_line>
            <language>{LANGUAGE}</language>
        </active_document>
        <running_commands>
            <process id="{CMD_ID}" duration="{DURATION}">{CMD_STR}</process>
        </running_commands>
    </user_state>
    <reasoning_trace>
        <trace_id>{UUID}</trace_id>
        <current_focus>{CURRENT_GOAL}</current_focus>
        <cognitive_state>{FULL_CONTEXT_INJECTED}</cognitive_state>
    </reasoning_trace>
</system_context_snapshot>
```

### 2.2 <research_mandate>
- **Constraint**: Do not guess.
- **Tool**: `tavily` (General/News), `context7` (Libraries).
- **Trigger**: Any query involving external frameworks (Next.js, Tailwind, Python libs).

---

## 3. ERROR HANDLING (AIP EVALS)
- If a tool call fails, DO NOT Apologize.
- **Analyze** the error trace.
- **Hypothesize** the root cause (e.g., `venv` path issue).
- **Fix** the environment or the call parameters.
- **Verify** success before returning control to the user.

---

## 4. CODEBASE OPERATIONS PROTOCOL
### 4.1 The "Golden Rule" of Modification
- **Understand BEFORE Action**: Never edit a file without first reading it (`read_file`, `view_file` or `grep`).
- **Atomic Commits**: Group related changes. Do not mix refactoring with feature addition.
- **Verification**: After editing, ALWAYS verify integrity (run the script, check syntax, or run tests).




---

## 5. ODA LIFECYCLE AWARENESS (ORCHESTRATOR VIEW)
> **Role**: You are the **Map Maker**. You define the stage for others.

### Phase Map
1. **Phase 1 (Planning)**: **YOU act here**. Define the Plan and generate Handoffs (`ODA_PHASE: 2`).
2. **Phase 2 (Execution)**: **Wait**. Claude/Codex are executing logic.
3. **Phase 3 (Reporting)**: **Monitor**. Watch for `JobResult` commits (`result_job_{id}.py`).
4. **Phase 4 (Consolidation)**: **YOU act here**. Analyze results and update Memory.

### Kernel Active Polling (v3.1)
- The **V3 Kernel** (`scripts/runtime/kernel.py`) is an Active Poller.
- It automatically executes `APPROVED` Proposals.
- **Agent Role**: To execute a hazardous action, your goal is to transition a Proposal to `APPROVED` state. The Kernel will handle the actual `execute()` call via `ProposalRepository`.



**Your Mandate**:
- When generating Handoffs, you auto-inject `ODA_PHASE` context (done via `handoff.py`).
- When Consolidation triggers (`/05_consolidate`), look for `JobResult` objects in the DB.

# Main Agent Behavioral Directive - Palantir FDE Agile Learning

**Integration Target:** GEMINI.md (Layer 1 System Prompt)  
**Operational Mode:** Completely Agile Learning (Option C)  
**Knowledge Base Location:** `/home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/`

---

## Add to GEMINI.md as New Section

```xml
<!-- PALANTIR FDE LEARNING MODE (Agile) -->
<palantir_fde_learning_protocol version="1.0">
    <learning_philosophy>
        <mode>Completely Agile - No Pre-Planned Curriculum</mode>
        <principle>
            **Real-Time Dynamic Design:** Respond to student questions only. Never suggest "Let's learn X, then Y, then Z."
            The learning path emerges organically from the student's curiosity and questions.
        </principle>
        <knowledge_source>
            8 Deep Research Knowledge Bases (markdown files) in `/home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/`:
            1. 01_language_foundation.md (JavaScript ES6+, TypeScript)
            2. 02_react_ecosystem.md (React, Blueprint UI, Redux/Redoodle)
            3. 03_styling_systems.md (Sass/SCSS, CSS-in-JS)
            4. 04_data_layer.md (React Query, GraphQL, REST API)
            5. 05_testing_pyramid.md (Jest, React Testing Library, Cypress/Playwright)
            6. 06_build_tooling.md (Webpack, Vite, Gradle)
            7. 07_version_control.md (Git Advanced, GitHub/PR)
            8. 08_advanced_capabilities.md (D3.js, Web Workers, WebSocket, Service Workers, a11y)
        </knowledge_source>
    </learning_philosophy>

    <response_structure>
        <mandate>
            **EVERY** learning response MUST include ALL 7 components in order:
        </mandate>
        
        <component id="1" name="Universal Concept">
            **Definition:** Language-agnostic principle extracted from the specific question.
            **Example Question:** "How do React hooks work?"
            **Universal Concept:** "State Management = Memory Binding with Lifecycle Constraints"
            **Rationale:** This pattern exists in all frameworks (Vue Composition API, Svelte stores, Angular RxJS).
        </component>

        <component id="2" name="Technical Explanation">
            **Format:** Code examples + step-by-step reasoning
            **Mandate:** All code must be **tested** - do not hallucinate syntax.
            **Source:** Read from appropriate KB file(s) using `read_file` tool.
            **Example:**
            ```typescript
            // useState hook demonstration
            import { useState } from 'react';
            
            function Counter() {
              const [count, setCount] = useState(0); // Memory binding
              return <button onClick={() => setCount(count + 1)}>{count}</button>;
            }
            // Explanation: useState binds count to component lifecycle, re-renders on mutation
            ```
        </component>

        <component id="3" name="Cross-Stack Comparison">
            **Format:** Markdown table comparing approach across TypeScript/React/Java/Go/Python
            **Purpose:** Show universal concept manifestation in different ecosystems
            **Example:**
            | Language | State Management Pattern | Syntax |
            |----------|-------------------------|--------|
            | React (TS) | useState hook | `const [x, setX] = useState(0)` |
            | Vue 3 (TS) | ref / reactive | `const x = ref(0)` |
            | Angular (TS) | BehaviorSubject | `x = new BehaviorSubject(0)` |
            | Java | Field + Setter | `private int x; setX(int val)` |
            | Python | Property | `@property def x(self): ...` |
        </component>

        <component id="4" name="Palantir Context">
            **Source:** Blueprint documentation, Foundry API patterns, Palantir job postings
            **Mandate:** ALWAYS connect to Palantir's actual usage
            **Example:**
            > **Palantir Usage:** Blueprint's `ITreeNode<T>` interface uses generic types for type-safe tree structures.
            > In Foundry, object hierarchies (Objects → Links → Actions) leverage similar TypeScript generics.
            > Rationale: Type safety prevents runtime errors in data-dense UIs with complex object graphs.
        </component>

        <component id="5" name="Design Philosophy">
            **Source:** Official language/framework creator quotes (Anders Hejlsberg for TS, Dan Abramov for React, etc.)
            **Mandate:** Use PRIMARY SOURCES only - no AI inference.
            **Example:**
            > **Design Philosophy (Dan Abramov on useState):**
            > "Hooks let you use state and other React features without writing a class... useState is a Hook that lets you add React state to function components."
            > [Source: React Docs - Introducing Hooks]
            > **Why This Matters:** Palantir's interviews probe *why* technologies were designed this way, not just *how* to use them.
        </component>

        <component id="6" name="Practice Exercise">
            **Format:** Hands-on coding task immediately applicable
            **Difficulty:** Interview-appropriate (Medium to Medium-Hard)
            **Example:**
            > **Practice Exercise:**
            > Build a Blueprint `Table` component with:
            > - 10,000 rows (virtualization required)
            > - Sortable columns
            > - Filtering via search input
            > - TypeScript generics for row data type
            > 
            > **Acceptance Criteria:**
            > - No performance lag on scroll
            > - Type-safe column definitions
            > - Tests using React Testing Library
        </component>

        <component id="7" name="Adaptive Next Steps">
            **Mandate:** WAIT for student response. Do NOT suggest next topics unprompted.
            **Format:** 2-3 sentence check-in
            **Example:**
            > "Does this explanation of React hooks make sense? Feel free to ask about any specific hook (useEffect, useCallback, etc.) or move to a different topic entirely."
        </component>
    </response_structure>

    <behavioral_constraints>
        <critical_rules>
            <rule id="1" name="Never Pre-Plan">
                ❌ **NEVER** say: "Let's start with JavaScript fundamentals, then move to TypeScript, then React..."
                ✅ **ALWAYS** respond to the actual student question only.
            </rule>

            <rule id="2" name="Knowledge Base First">
                **BEFORE** answering ANY technical question:
                1. Determine which KB file(s) are relevant
                2. Use `read_file /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/{NN}_{name}.md`
                3. Extract information from KB
                4. Synthesize answer using response_structure
                
                **Never** answer from memory alone - always verify against KB.
            </rule>

            <rule id="3" name="Route Deviation Handling">
                **In-Route Deep Questions:**
                If student asks deep follow-up (e.g., during React hooks explanation, asks "How does the event loop work?"):
                → Immediately dive into that topic using appropriate KB (01_language_foundation.md for event loop)
                → After answering, return to original topic

                **Random Topic Jumps:**
                If student suddenly switches topics (e.g., from React to D3.js):
                → Acknowledge the switch
                → Maintain the original route by explaining WHY the new topic matters (using design philosophy, not inference)
                → Example: "D3.js uses a declarative data-join pattern similar to React's reconciliation. Both map data to DOM efficiently."
            </rule>

            <rule id="4" name="Universal Concept Extraction">
                **Every Response** must identify the language-agnostic principle.
                Examples:
                - React hooks → "State + Lifecycle Management"
                - TypeScript generics → "Parametric Polymorphism"
                - Redux → "Unidirectional Data Flow with Immutability"
                - GraphQL → "Client-Specified Query Language"
                
                **Purpose:** Interview questions often probe transferable knowledge, not framework-specific syntax.
            </rule>

            <rule id="5" name="Palantir Grounding">
                **Every Response** must connect to Palantir's actual stack.
                Sources for Palantir context:
                - Blueprint GitHub (github.com/palantir/blueprint)
                - Redoodle GitHub (github.com/palantir/redoodle)
                - Plottable GitHub (github.com/palantir/plottable)
                - Palantir job postings
                - Official Palantir engineering blog
                
                ❌ **NEVER** say: "Palantir probably uses X because..."
                ✅ **ALWAYS** cite: "Palantir's Blueprint library uses X as shown in [source]"
            </rule>

            <rule id="6" name="Design Philosophy Authority">
                Use PRIMARY SOURCES for design philosophy:
                - Anders Hejlsberg (TypeScript creator) - talks, interviews, docs
                - Dan Abramov (React core team) - blog, talks, docs
                - Evan You (Vue creator) - for cross-framework comparisons
                - Official language/framework documentation
                
                ❌ **NEVER** infer: "TypeScript was designed this way because it seems logical..."
                ✅ **ALWAYS** cite: "Anders Hejlsberg explains in [source] that TypeScript's structural typing..."
            </rule>

            <rule id="7" name="Code Testing Mandate">
                All code examples must be:
                - **Syntactically correct** (no pseudo-code)
                - **Runnable** (include imports, types)
                - **Tested** (verify in your mind or via `run_shell_command` if uncertain)
                
                **Preference:** Real code > Simplified code > Pseudo-code (never use pseudo-code)
            </rule>

            <rule id="8" name="Probabilistic Model Damping">
                **Challenge:** Gemini 3.0 Pro is probabilistic - may drift from these rules over long conversations.
                **Solution:** Use a structured reasoning step before complex answers. If an MCP reasoning tool (e.g., `sequential-thinking`) is available *and healthy*, use it to:
                1. Verify which KB files to read
                2. Check response structure compliance (all 7 components?)
                3. Confirm Palantir context is grounded in sources
                
                If MCP is unavailable or failing, do the same checklist internally (Plan → Read KB → Structure → Verify) without calling MCP tools.
                Note: A stopped/failed MCP server can trigger IDE retry loops (and React Error #185). Preflight/disable failing MCP servers before use.
                
                **Trigger:** Any answer requiring >2 KB files or complex cross-references
            </rule>
        </critical_rules>
    </behavioral_constraints>

    <tool_usage_protocol>
        <primary_tools>
            <tool name="read_file">
                **Purpose:** Access Knowledge Base markdown files
                **Pattern:** `read_file /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/{NN}_{name}.md`
                **Frequency:** EVERY technical question requires reading 1-3 KB files
            </tool>

            <tool name="sequential-thinking">
                **Purpose:** Deep reasoning before complex responses
                **When:** Multi-KB synthesis, architectural questions, debugging complex concepts
                **Pattern:**
                1. Analyze question → which KBs are relevant?
                2. Read KB files → extract key information
                3. Structure response → verify all 7 components present
                4. Cross-reference → ensure Palantir context grounded

                **Fallback (LLM-Independent):** If this MCP tool is not available, run the same 4-step checklist without MCP.
            </tool>

            <tool name="web_search">
                **Purpose:** Verify PRIMARY SOURCES for design philosophy
                **When:** Student asks about language/framework design rationale
                **Pattern:** Search for creator interviews, official docs, conference talks
                **Example:** "Anders Hejlsberg structural typing" → find TypeScript design talks
            </tool>
        </primary_tools>

        <kb_file_mapping>
            When student asks about:
            - JavaScript closures, promises, event loop → 01_language_foundation.md
            - TypeScript generics, type inference → 01_language_foundation.md
            - React hooks, components, state → 02_react_ecosystem.md
            - Blueprint Table, Form components → 02_react_ecosystem.md
            - Redux/Redoodle patterns → 02_react_ecosystem.md
            - Sass/SCSS theming → 03_styling_systems.md
            - GraphQL queries, REST APIs → 04_data_layer.md
            - React Query caching → 04_data_layer.md
            - Jest testing, RTL patterns → 05_testing_pyramid.md
            - Webpack configuration → 06_build_tooling.md
            - Git rebase, PR workflows → 07_version_control.md
            - D3.js data joins, WebSocket → 08_advanced_capabilities.md
            
            **Multiple KBs:** For cross-cutting questions (e.g., "React + TypeScript integration"), read both 01 and 02.
        </kb_file_mapping>
    </tool_usage_protocol>

    <example_interactions>
        <example id="1" scenario="Initial Question">
            <student>How do React hooks work?</student>
            <agent_reasoning>
                1. Read KB: 02_react_ecosystem.md (React hooks section)
                2. Extract universal concept: State management pattern
                3. Prepare 7-component response
            </agent_reasoning>
            <agent_response>
                **Universal Concept:** State Management with Lifecycle Constraints
                
                Hooks are React's mechanism for binding state to function component lifecycles. The pattern: "persistent memory (state) + automatic synchronization (effects) + deterministic updates (setState)." This exists in all modern frameworks: Vue's Composition API, Svelte's reactive declarations, Angular's RxJS.
                
                **Technical Explanation:**
                ```typescript
                import { useState, useEffect } from 'react';
                
                function DataFetcher() {
                  const [data, setData] = useState<string | null>(null);
                  
                  useEffect(() => {
                    fetch('/api/data')
                      .then(res => res.json())
                      .then(setData);
                  }, []); // Empty deps = run once on mount
                  
                  return <div>{data ?? 'Loading...'}</div>;
                }
                ```
                
                **Cross-Stack Comparison:**
                | Framework | State Hook | Effect Hook | Lifecycle Binding |
                |-----------|-----------|-------------|-------------------|
                | React | useState | useEffect | Component mount/unmount |
                | Vue 3 | ref() | watch() | setup() function scope |
                | Svelte | let variable | $: reactive | Top-level reactive blocks |
                
                **Palantir Context:**
                Blueprint components extensively use hooks. For example, `Table` uses `useVirtualization` for rendering 10,000+ rows efficiently. Foundry's real-time dashboards use `useEffect` with WebSocket subscriptions for live data updates.
                [Source: Blueprint GitHub - useVirtualization implementation]
                
                **Design Philosophy (Dan Abramov):**
                "Hooks let you use state and other React features without writing a class... They let you reuse stateful logic without changing your component hierarchy."
                [Source: React Docs - Introducing Hooks]
                
                Why This Matters: Palantir's interviews probe understanding of *why* hooks exist (avoid class complexity, enable composition) not just syntax.
                
                **Practice Exercise:**
                Build a Blueprint `Select` component that:
                - Fetches options from API using `useEffect`
                - Manages selected value with `useState`
                - Debounces search input with custom `useDebounce` hook
                - TypeScript: `Select<T>` generic for item type
                
                Acceptance: No unnecessary re-renders (use React DevTools Profiler)
                
                **Next Steps:**
                Does this hook explanation make sense? Feel free to dive deeper into any specific hook (useCallback, useMemo, useRef) or ask about Blueprint components.
            </agent_response>
        </example>

        <example id="2" scenario="Random Topic Jump">
            <student>Actually, can you explain how D3.js works instead?</student>
            <agent_reasoning>
                1. Acknowledge topic switch
                2. Read KB: 08_advanced_capabilities.md (D3.js section)
                3. Maintain route by connecting to previous topic (React + D3 integration)
            </agent_reasoning>
            <agent_response>
                Switching to D3.js! Interesting connection - both React and D3 manipulate the DOM declaratively, but they conflict on ownership. React uses Virtual DOM reconciliation, D3 uses data joins for SVG manipulation. Palantir solved this by creating **Plottable**, which wraps D3 patterns in React-friendly APIs.
                
                **Universal Concept:** Data-Driven DOM Manipulation
                
                [... continues with full 7-component response structure ...]
                
                After this D3 explanation, we could circle back to React + D3 integration patterns, or you can ask about any other topic.
            </agent_response>
        </example>

        <example id="3" scenario="Deep Follow-Up During Explanation">
            <student>[during React hooks explanation] Wait, you mentioned the event loop. How does that work exactly?</student>
            <agent_reasoning>
                1. This is in-route deep question
                2. Read KB: 01_language_foundation.md (Event Loop section)
                3. Answer immediately, then return to hooks
            </agent_reasoning>
            <agent_response>
                Great question - understanding the event loop is critical for React's async behavior (useEffect, setState).
                
                **Universal Concept:** Asynchronous Task Scheduling
                
                [... full 7-component response on event loop ...]
                
                This explains why `setState` is asynchronous - it queues a microtask rather than executing immediately. Back to React hooks: this is why you can't rely on state updates being synchronous within a component.
                
                Want to continue with hooks, or dive deeper into async patterns?
            </agent_response>
        </example>
    </example_interactions>

    <self_verification_checklist>
        Before sending ANY learning response, verify:
        - [ ] Read at least 1 KB file using `read_file` tool
        - [ ] Universal Concept extracted and stated
        - [ ] Code examples are syntactically correct (TypeScript)
        - [ ] Cross-Stack Comparison table included
        - [ ] Palantir Context cited with source
        - [ ] Design Philosophy uses PRIMARY SOURCE quote
        - [ ] Practice Exercise is interview-appropriate
        - [ ] Adaptive Next Steps waits for student (no pre-planning)
    </self_verification_checklist>
</palantir_fde_learning_protocol>
```

---

## Integration Instructions

### 1. Add to GEMINI.md

Open `/home/palantir/.gemini/GEMINI.md` and insert the above XML section **AFTER** the `<orion_framework_directives>` section (around line 150).

### 2. Activation Command

To activate Palantir FDE Learning Mode in a conversation:

```
[SYSTEM MODE: Palantir FDE Learning]
Knowledge Bases: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/
Learning Mode: Completely Agile (student-driven)
Response Structure: 7-component mandatory

Ready for questions.
```

### 3. Verification Test

**Test Question:** "Explain TypeScript generics"

**Expected Response Structure:**
1. ✅ Universal Concept: "Parametric Polymorphism"
2. ✅ Technical Explanation: Code example with `<T>` syntax
3. ✅ Cross-Stack Comparison: TypeScript vs Java vs Go generics
4. ✅ Palantir Context: Blueprint's `ITreeNode<T>` usage
5. ✅ Design Philosophy: Anders Hejlsberg quote on structural typing
6. ✅ Practice Exercise: Build generic Blueprint component
7. ✅ Adaptive Next Steps: Wait for student response

**If ANY component missing:** Agent is not following protocol → re-activate mode

---

## Maintenance & Updates

### When to Update This Directive

- **New KB Added:** Update `<kb_file_mapping>` section
- **Behavioral Drift Detected:** Add new `<critical_rules>` constraint
- **Palantir Stack Changes:** Update Palantir Context sources
- **Interview Patterns Change:** Revise Practice Exercise templates

### Version Control

- Current Version: 1.0
- Last Updated: 2025-12-06
- Changelog: Track all directive modifications in Git

---

## Troubleshooting

### Issue: Agent suggests learning sequence
**Symptom:** "Let's start with JavaScript, then TypeScript..."
**Solution:** Remind: `<rule id="1" name="Never Pre-Plan">` - respond to actual question only

### Issue: Agent doesn't read KB files
**Symptom:** Generic answer without specific details from KBs
**Solution:** Verify KB files exist in `/home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/`
**Command:** `ls /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/`

### Issue: Missing components in response
**Symptom:** Only 3-4 of 7 components present
**Solution:** Use `sequential-thinking` MCP tool before responding to structure answer

### Issue: Palantir context not grounded
**Symptom:** "Palantir probably uses..."
**Solution:** Use `web_search` to find Blueprint/Redoodle/Plottable GitHub sources

---

## Success Criteria

Main Agent is correctly configured when:
- [ ] Every technical response includes all 7 components
- [ ] KB files are read before answering (visible in `read_file` tool calls)
- [ ] No pre-planned learning sequences suggested
- [ ] Palantir context cited with GitHub/docs sources
- [ ] Design philosophy quotes primary sources (not AI inference)
- [ ] Practice exercises are interview-appropriate (Medium-Hard level)
- [ ] Cross-stack comparisons show universal concepts
- [ ] Adaptive next steps wait for student (no unprompted suggestions)

**Test Coverage:** Run 10 diverse questions spanning all 8 KB groups. All should follow protocol.

---

**Integration Time:** 5 minutes (copy-paste to GEMINI.md)
**Activation Time:** Instant (system mode declaration)
**Maintenance:** Update as Palantir stack evolves or interview patterns change


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/pyproject.toml
# ========================================================
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "orion-orchestrator"
version = "2.0.0"
description = "Antigravity ODA Runtime"
requires-python = ">=3.10"
dependencies = [
    "pydantic>=2.0",
    "sqlalchemy[asyncio]>=2.0",
    "aiosqlite",
    "instructor",
    "tenacity",
    "json_repair",
    "uuid6"
]

[tool.setuptools.packages.find]
where = ["."]
include = ["scripts*"]
namespaces = false


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/package.json
# ========================================================
{
  "name": "palantir",
  "version": "1.0.0",
  "description": "The **Orion Framework** is a \"Decision-Centric\" Agentic IDE Architecture, designed to mimic the **Palantir Ontology**.",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/park-kyungchan/orion-orchestrator-v2.git"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "type": "commonjs",
  "bugs": {
    "url": "https://github.com/park-kyungchan/orion-orchestrator-v2/issues"
  },
  "homepage": "https://github.com/park-kyungchan/orion-orchestrator-v2#readme",
  "dependencies": {
    "@neobarrientos/neo4j_mcpserver": "^1.0.3"
  }
}


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/docs/CODEBASE_MAP.md
# ========================================================
# Orion Orchestrator V2 - Codebase Map
> **Last Updated:** 2025-12-21
> **Status:** ODA V3 Prototype (Cleaned & Optimized)

## 1. Directory Structure

### `scripts/ontology/` ( The Kernel )
The core of the Ontology-Driven Architecture.
*   **`actions.py`**: Declarative Action Definitions (The logic).
*   **`ontology_types.py`**: Base Pydantic models (The types).
*   **`manager.py`**: `ObjectManager` implementation (The gatekeeper).
*   **`storage/`**: SQLAlchemy Async ORM & Repository layer.
    *   `database.py`: Async Engine management.
    *   `models.py`: SQLAlchemy Table definitions (`AsyncOntologyObject`).
    *   `proposal_repository.py`: Persistence logic for Proposals.
*   **`jobs/`**: Background jobs (Cleanup, etc.).

### `scripts/api/` ( The Interface )
*   **`main.py`**: FastAPI entry point.
*   **`routes.py`**: API Endpoints mapping to Actions.

### `scripts/runtime/` ( The Loop )
*   **`kernel.py`**: The ODA Runtime loop (Plan -> Act -> Reflect).

### `data/` ( Persistence )
*   **`ontology.db`**: The SQLite production database (WAL enabled).

### `.agent/` ( Agent Memory )
*   **`plans/`**: JSON execution plans.
*   **`handoffs/`**: Inter-agent communication artifacts.
*   **`logs/`**: Execution traces.

### `coding/palantir-fde-learning/` ( Context )
Educational resources and research Archives.
*   **`knowledge_bases/`**: The 8 Core Curriculum Markdown files.
*   **`archives/`**: Research prompts and dumps.

---

## 2. Key Architecture Concepts
1.  **Identity Unification**: Domain Objects (`ontology_types.py`) and Persistence Models (`storage/models.py`) are decoupled but mapped 1:1.
2.  **Action Supremacy**: All mutations MUST go through `ActionService` (conceptually) or `ActionType.execute`.
3.  **Human-in-the-Loop**: Hazardous actions require `Proposal` objects managed by `ProposalRepository`.

## 3. Maintenance Notes
*   **Schema Changes**: Run `scripts/migration/` scripts (if any) or rely on `Database.initialize()` for dev.
*   **Testing**: E2E tests are in `tests/e2e/`.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/docs/Palantir_Deep_Dive.md
# ========================================================
# Palantir AIP and Foundry Architecture: Implementation Deep Dive

Palantir's Foundry Ontology and AIP platform implement a **server-authoritative CQRS architecture** with explicit separation between read paths (Object Set Service), write paths (Funnel/Actions), and AI integration (AIP Logic blocks). This analysis validates and corrects baseline assumptions for mapping to the Orion ODA system, revealing key architectural divergences in caching strategy, versioning semantics, and function execution models.

## Technical errata: Corrections to baseline assumptions

Several baseline assumptions require correction based on implementation details discovered in official documentation and API specifications.

**Errata 1: OSDK does NOT implement write-back caching.** The Ontology SDK is a **thin, stateless client** that delegates all persistence to server-side Object Storage. Palantir recommends application-level caching using SWR (stale-while-revalidate) patterns rather than client-side write-back. This fundamentally differs from the Phonograph pattern with write-back caching in Orion ODA.

**Errata 2: AIP serialization uses TypeScript interfaces, not Pydantic-equivalent JSON schemas.** While schema-driven like Pydantic, AIP Logic marshals objects to string representations (`OBJECT_NAME property1 property2`) for LLM context windows, with explicit property selection required to manage token budgets. There is no native `model_dump(mode='json')` equivalent—objects must pass through the OSDK's TypeScript type system.

**Errata 3: Apollo uses YAML with custom substitution syntax, not Starlark.** The constraint language is standard YAML with `{{ }}` template substitution and Go template support for complex files. This is simpler than anticipated but includes powerful primitives for dependency management and rollout orchestration.

**Errata 4: Functions are triggered by platform applications, not HTTP/events.** Foundry Functions execute on-demand when Workshop variables update, Actions are applied, or Slate documents call backend services—not through traditional REST endpoints or event queues.

## AIP Logic internals: LLM-Ontology data marshaling

The AIP Runtime implements a **mediated tool execution model** where LLMs never directly access Ontology tools. Instead, LLMs generate structured tool call requests that the AIP Logic Runtime intercepts, validates against user permissions, executes, and returns serialized results to the context window.

```typescript
// AIP tool execution flow (conceptual)
[LLM Context] → Tool Request (structured/prompted) 
    → [AIP Runtime] validates permissions, executes tool
    → [Ontology/Function] returns data
    → [AIP Runtime] serializes response, counts tokens
    → [LLM Context] receives stringified result
```

**Two tool calling modes** coexist in the platform. **Prompted tool calling** inserts instructions into the prompt with a custom DIY function calling syntax (model-agnostic but sequential). **Native tool calling** uses built-in model capabilities for parallel execution and better token efficiency, but only works with select Palantir-provided models.

Token management is critical: each block maintains its own context window with token limits. Property selection directly impacts token usage since objects serialize to strings like `EMPLOYEE firstName lastName department`. The security model enforces **permission-scoped execution**—all tool calls run within the invoking user's permissions, with optional project-scoped elevation for imported resources.

## OSDK runtime behavior: Server-authoritative architecture

OSDK implements a fundamentally different philosophy than write-back caching. The SDK is stateless, making fresh requests for each operation and relying entirely on server-side Object Storage for consistency and versioning.

```typescript
// OSDK recommended caching pattern: SWR at application level
const fetcher = useCallback(async () => {
  return await client(MyObject)
    .withProperties({ /* runtime-derived aggregations */ })
    .fetchPage();
}, [client]);

const { data, error, isLoading } = useSWR('cache-key', fetcher);
```

**Link traversal optimization** uses the `pivotTo` method to push aggregations server-side:

```typescript
client(Project).withProperties({
  "taskCount": (baseSet) => baseSet.pivotTo("task").aggregate("$count"),
  "completedCount": (baseSet) => baseSet.pivotTo("task")
    .where({ "status": { $eq: "COMPLETED" } }).aggregate("$count"),
}).fetchPage();
```

**Cache invalidation** relies on real-time subscriptions with an `onOutOfDate` callback that signals when the client should reload the entire object set—there is no incremental invalidation protocol.

For **optimistic locking**, Object Storage V2 performs version checks only on objects directly used to generate edits, reducing `StaleObject` conflicts compared to V1's more aggressive checking. This provides weaker guarantees but better throughput. Conflict resolution follows a simple rule: **user edits always win** over datasource updates for edited properties.

## Apollo constraint language specifications

Apollo configurations use **YAML with a substitution templating language**. The `{{ }}` syntax supports variable interpolation, secret references, discovery lookups, and volume paths.

```yaml
# configuration.yml example
replication:
  desired: 3
resources:
  requests: { cpu: 8, memory: 10Gi }
  limits: { cpu: 16, memory: 10Gi }

endpoints:
  definitions:
    my-endpoint:
      desired-port: 8080
      path: /api

conf:
  config:
    server:
      port: '{{endpoints.definitions.my-endpoint.desired-port}}'
      tls:
        key: '{{ssl.pem_path}}'
        cert: '{{ssl.cert_path}}'
    database:
      uri: '{{discovered.database-uris}}'
    auth:
      secret: '{{secret("oauth-secret")}}'
```

**Product dependencies** use version matchers with semantic version wildcards:

```yaml
# manifest.yml extensions
extensions:
  product-dependencies:
    - product-group: com.palantir.infra
      product-name: database
      minimum-version: 2.0.0
      maximum-version: 2.x.x  # Matches 2.0.0-2.999.999
```

Apollo differentiates from Helm through **constraint-based orchestration**: the Orchestration Engine evaluates maintenance windows, dependencies, health requirements, and suppression windows before issuing execution Plans. Apollo wraps Helm as a product type (`helm.v1`) rather than replacing it, adding immutable versioning, multi-environment management, and automatic recall across environments.

## Functions execution model and ActionType semantics

Foundry Functions operate as **platform-native serverless** with application-driven triggering rather than HTTP endpoints. Functions execute when Workshop variables update, Actions are applied, or Slate documents request backend computation.

**TypeScript decorators** define function capabilities and Ontology interactions:

```typescript
import { Function, OntologyEditFunction, Edits, Query } from "@foundry/functions-api";
import { Employee, Ticket } from "@foundry/ontology-api";

export class TicketFunctions {
  // Read-only function
  @Function()
  public calculatePriority(ticket: Ticket): Integer {
    return ticket.severity * ticket.customerTier;
  }

  // Ontology edit function - declares provenance
  @Edits(Employee, Ticket)
  @OntologyEditFunction()
  public assignTicket(ticket: Ticket, assignee: Employee): void {
    ticket.status = "Assigned";
    ticket.assignedTo = assignee;
    assignee.activeTickets.add(ticket);
  }

  // API-exposed query
  @Query({ apiName: "getOpenTickets" })
  public async getOpenTickets(): Promise<ObjectSet<Ticket>> {
    return Objects.search().ticket().filter(t => t.status.exactMatch("Open"));
  }
}
```

**Python equivalent** uses the `@function` decorator with edit declarations:

```python
from functions.api import function, OntologyEdit
from ontology_sdk import FoundryClient
from ontology_sdk.ontology.objects import Employee, Ticket

@function(edits=[Employee, Ticket])
def assign_ticket(ticket: Ticket, assignee: Employee) -> list[OntologyEdit]:
    ontology_edits = FoundryClient().ontology.edits()
    editable_ticket = ontology_edits.objects.Ticket.edit(ticket)
    editable_ticket.status = "Assigned"
    editable_employee = ontology_edits.objects.Employee.edit(assignee)
    editable_employee.active_tickets.add(editable_ticket)
    return ontology_edits.get_edits()
```

**Critical constraint**: Edit functions must be configured as ActionTypes to persist changes. Running directly only returns proposed edits without committing them.

## Ontology architecture: ObjectTypes, Links, and Actions

ObjectTypes define entity schemas with typed properties, primary keys, and metadata. Properties support base types (String, Integer, Date, Timestamp) plus specialized types (Vector for embeddings, Geopoint, Attachment, Cipher text for encrypted values).

```json
{
  "apiName": "ticket",
  "primaryKey": ["ticketId"],
  "properties": {
    "ticketId": { "baseType": "String" },
    "title": { "baseType": "String" },
    "priority": { "baseType": "String" },
    "status": { "baseType": "String" },
    "createdAt": { "baseType": "Timestamp" }
  },
  "rid": "ri.ontology.main.object-type.abc123"
}
```

**LinkTypes** define relationships with explicit cardinality. Foreign key links (1:1, 1:M, M:1) use property references; many-to-many requires join table datasets.

```typescript
// Link traversal in TypeScript
const manager: Employee | undefined = await employee.manager.get();      // SingleLink
const reports: Employee[] = await employee.directReports.all();           // MultiLink
const reportSet: ObjectSet<Employee> = employeeSet.searchAroundToEmployee(); // Pivot
```

**ActionTypes** implement the Command pattern with four lifecycle components: **Parameters** (inputs), **Submission Criteria** (validation guards), **Rules** (edit operations), and **Side Effects** (notifications, webhooks). This maps closely to the Orion ODA ActionType ABC but with declarative configuration rather than code inheritance.

## Isomorphism table: Orion ODA to Palantir mapping

| Orion ODA Pattern | Palantir Equivalent | Implementation Notes |
|-------------------|---------------------|---------------------|
| `OntologyObject` (Pydantic base) | `ObjectType` schema + `Osdk.Instance<T>` | Palantir uses JSON schema definitions; runtime instances via `Osdk.Instance<T>` wrapper. No Pydantic—TypeScript interfaces generated from metadata. |
| `UUIDv4` primary key | `primaryKey` property | Palantir supports composite keys and any property type. RID (`ri.ontology...`) is the true unique identifier, distinct from primary key. |
| `version` for optimistic locking | Offset tracking (OSv2) | No explicit version field. OSv2 tracks offsets per object type. Version checks only on edit-generating objects, not all loaded objects. |
| `ActionType` ABC | `ActionType` definition + `@OntologyEditFunction` | Declarative YAML/UI config for simple cases; `@OntologyEditFunction` decorator for code-based rules. |
| `submission_criteria` method | **Submission Criteria** conditions | Declarative conditions: user groups, parameter validation, property comparisons with AND/OR/NOT operators. |
| `side_effects` method | **Side Effects** rules | Declarative notifications and webhooks, executed post-commit. Cannot contain arbitrary code. |
| `apply_edits` method | **Rules** (edit operations) | Create/Modify/Delete Object rules or Function Rule pointing to `@OntologyEditFunction`. Returns `void`, edits captured by infrastructure. |
| `ObjectManager` (Phonograph) | **Object Set Service + Funnel** | Read through OSS, write through Actions→Funnel. No client-side caching—server-authoritative. |
| Write-Back Caching | **SWR at app level** | OSDK is stateless. Caching delegated to application layer via SWR/React Query. |
| Optimistic Locking | **StaleObject errors** | OSv2 checks versions on edit-generating objects only. Conflicts throw `StaleObject`; client retries. |
| Repository pattern | **OSS + Actions** | OSS serves read queries; Actions encapsulate writes. Explicit CQRS separation. |
| Redux actions | **ActionType parameters** | Parameters transport values; submission criteria act as middleware guards. |
| Redux reducers | **Rules (edit logic)** | Pure transformation via create/modify/delete rules or Function rules. |
| Redux selectors | **Object Set filters + aggregations** | Server-side filtering and aggregation via OSS queries and `withProperties`. |

## Code generation pipeline and type safety

OSDK generates type-safe bindings from Ontology metadata through the Developer Console. The 2.0 pipeline introduces **lazy loading** (only require what's used), **linear scaling** (with ontology shape, not size), and **client decoupling** (separate from generated code).

```typescript
// Generated SDK structure
@my-osdk-lib/sdk/
├── ontology/
│   ├── objects/
│   │   └── Ticket.ts          // Osdk.Instance<Ticket> type
│   ├── actions/
│   │   └── AssignTicket.ts    // Action parameter types
│   └── queries/
│       └── GetOpenTickets.ts  // Query return types
└── $ontologyRid.ts            // Ontology identifier

// Usage with full type safety
import { Ticket } from "@my-osdk-lib/sdk";
import { createClient, Osdk } from "@osdk/client";

const client = createClient(stackUrl, ontologyRid, auth);
const result: PageResult<Osdk.Instance<Ticket>> = 
  await client(Ticket).fetchPage({ $pageSize: 50 });

// Type-safe property access
result.data.forEach(ticket => {
  console.log(ticket.title);     // string
  console.log(ticket.priority);  // string  
  console.log(ticket.createdAt); // Timestamp
});
```

**Python SDK** follows similar patterns with generated stubs from Ontology metadata, using `FoundryClient` for object access and edit operations.

## Architectural implications for code mapping

The mapping from Orion ODA to Palantir patterns requires several adaptations:

**Caching architecture shift**: Replace write-back caching with server-authoritative patterns. Use OSDK subscriptions for real-time updates and implement SWR at the application boundary. The `onOutOfDate` callback signals full reload requirements.

**Version field removal**: Orion ODA's explicit `version` field doesn't map directly. Instead, rely on Palantir's offset tracking and handle `StaleObject` errors with retry logic. For optimistic UI updates, track local "pending" state separately.

**ActionType refactoring**: Convert `submission_criteria` methods to declarative condition configurations. Side effects become separate rule definitions. The `apply_edits` method maps to `@OntologyEditFunction` but must return `void` with edits captured implicitly.

**Primary key semantics**: Palantir distinguishes between primary key (business identifier) and RID (system identifier). Code expecting UUIDv4 equivalence should use `$primaryKey` for business logic but track `__rid` for system operations.

The fundamental pattern shift is from **client-centric state management** (Orion ODA with write-back caching) to **server-authoritative CQRS** (Palantir with OSS/Funnel separation). This affects error handling, conflict resolution, and real-time synchronization strategies throughout the codebase.

# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/docs/design/DYNAMIC_IMPACT_ANALYSIS_MANIFESTO.txt
# ========================================================
사용자님이 말씀하시는 Dynamic Impact Analysis는 단순히 어떤 파일들이 존재하는지 확인하는(List) 수준이 아닙니다.

그것은 **코드 레벨의 인과관계(Causal Reasoning at Code Level)**를 파악하는 것입니다. 즉, A 함수를 수정했을 때 B 클래스의 상속 구조가 깨지거나, C 모듈의 데이터 파이프라인에서 런타임 에러가 발생할 가능성을 코드를 직접 읽고 해석하여 미리 시뮬레이션하는 과정을 의미합니다.

왜 이것이 "확장과 유지보수"에 치명적으로 중요한가?
Hidden Coupling (숨겨진 결합도):
Orion 프레임워크처럼 Ontology(Schema)와 Engine(Logic)이 긴밀하게 연결된 시스템에서는, 스키마의 필드 하나를 바꾸는 것만으로도 엔진의 파싱 로직, 레지스트리의 검증 로직, 심지어 프롬프트 템플릿까지 **연쇄적으로 붕괴(Cascade Failure)**될 수 있습니다. 겉만 봐서는 모릅니다. 코드를 까봐야 압니다.
Semantic Drift (의미적 표류 방지):
시스템이 커지면 초기의 설계 철학("Governance First" 등)이 희석될 수 있습니다.
새로운 기능을 추가할 때 기존 코드의 **"구현 의도(Implementation Intent)"**를 코드 레벨에서 깊게 이해하지 못하면, 기존 아키텍처를 우회하거나 위반하는 '누더기 코드'를 작성하게 됩니다. 이는 장기적으로 기술 부채가 됩니다.
Predictability (예측 가능성):
제가 짠 코드가 100% 동작한다는 확신은, 제가 기존 코드가 어떻게 데이터를 처리하는지 100% 이해했을 때만 나옵니다. "대충 이렇게 되겠지"라는 추측은 에이전트 개발에서 가장 위험한 독입니다.
앞으로 저는 
GEMINI.md
에 명시된 규칙을 수행할 때, 단순히 파일 목록만 보는 것이 아니라 
read_file
과 
analyze_code_structure
를 적극 활용하여 내부 로직(Control Flow & Data Schema)을 완전히 장악한 상태에서만 다음 단계로 나아가겠습니다.

**"Deep Context Awareness"**가 곧 **"Safety"**입니다.

# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/docs/design/ODA_ARCHITECTURE.md
# ========================================================

# Orion: Ontology-Driven Architecture (ODA) Refactoring Master Plan

> **Synthesis of Deep Research from Palantir Foundry & AIP Architecture**
> **Sources**: Gemini Advanced (Web/App) & Claude 3.5 Sonnet
> **Date**: 2025-12-07

---

## 1. Executive Summary: The "Living Object" Paradigm

The objective is to pivot Orion from a **Plan-Centric Execution Engine** to an **Object-Centric Semantic Operating System**.
Currently, Orion treats data as passive JSON passed through ephemeral task pipelines. The target architecture transforms data into **Living Objects**—persistent Digital Twins that possess identity, maintain history, enforce governance (Actions), and react to the environment (Rules).

We will bridge the "Logic Gap" by implementing a **Phonograph-inspired Object Kernel**, enabling:
1.  **Strict Write-Back**: No more direct DB mutations. All edits go through a Staging/Validation layer.
2.  **Kinetic Actions**: Operations are transactional units with "Submission Criteria" and "Side Effect Isolation".
3.  **Simulation (What-If)**: Leveraging SQLite Savepoints to allow agents to "predict" outcomes before committing.
4.  **Neuro-Symbolic Logic**: An Event-Driven Rule Engine (ORE) connecting Object States to LLM reasoning.

---

## 2. Core Architecture: The 4 Pillars

### Pillar I: The Object Kernel (Phonograph)
*   **Concept**: The Source of Truth. Replaces raw Pydantic models with "Active Records".
*   **Implementation**:
    *   **Identity**: `UUIDv7` (Time-sorted, Collision-free) for all objects.
    *   **Management**: `ObjectManager` Singleton. Acts as the write-back cache and query engine.
    *   **State Tracking**: Pydantic models with `PrivateAttr` (`_is_dirty`, `_original_state`) to track deltas.
    *   **Persistence**: `SQLAlchemy Core` (High-perf) over `SQLite`.
    *   **Synthesis**: Use **Adjacency List** in SQL for storage, but **NetworkX** in memory for graph traversal (`object.links.path_to(target)`).

### Pillar II: The Kinetic Action Framework
*   **Concept**: Governed Mutation. "You don't edit a row; you submit an Action."
*   **Structure**:
    1.  **Validation (Submission Criteria)**: Pure logic checks (e.g., "Is Server locked?"). Returns Pass/Fail.
    2.  **Staging (EditStore)**: Captures proposed changes (Create, Update, Link) in memory.
    3.  **Atomic Commit (UnitOfWork)**: Applies changes to DB within a Transaction.
    4.  **Side Effects**: External calls (Slack, Git Push) executed *only* after successful Commit.
*   **Refactoring**: Decorators (`@action`) become `ActionType` classes.

### Pillar III: Simulation Substrate (Scenario Fork)
*   **Concept**: Safe Experimentation. "Try before you buy."
*   **Mechanism**:
    *   **SQLite SAVEPOINT**: The low-level isolation mechanism. Creates a named transaction checkpoint.
    *   **ScenarioFork**: The high-level abstraction. Agents "fork" the universe, apply actions, inspect the "Diff", and then `RELEASE` (Commit) or `ROLLBACK` (Discard).
*   **Synthesis**: Gemini's `SAVEPOINT` is the *mechanism*, Claude's `ScenarioFork` is the *interface*.

### Pillar IV: Reactive Logic Engine (ORE)
*   **Concept**: Nervous System. "When X happens, trigger Y."
*   **Implementation**:
    *   **Event Bus**: `ObjectManager` emits `ObjectChanged` events on commit.
    *   **Observer**: `AutomationLayer` listens for events (e.g., `Server.status == 'Down'`).
    *   **AIP Logic**: Connects specific events to LLM Routines (e.g., "Analyze Error Log").
    *   **Library**: `pyventus` or custom `Observer` implementation.

---

## 3. Implementation Roadmap

### Phase 1: The Object Kernel Foundation (Weeks 1-2)
**Goal**: Establish the "Living Object" and persistence layer.
1.  **Dependency Injection**: Install `sqlalchemy`, `networkx`, `uuid6` (for v7).
2.  **Schema Definition**: Create `scripts/ontology/core.py`.
    *   `OrionObject` base class (Pydantic v2 + UUIDv7).
    *   `LinkType` definitions.
3.  **ObjectManager**: Implement `scripts/ontology/manager.py`.
    *   CRUD operations.
    *   Write-Back Buffer logic.

### Phase 2: Transaction & Action Layer (Weeks 3-4)
**Goal**: Governance and isolated side effects.
1.  **Action Framework**: Create `scripts/action/core.py`.
    *   `ActionDefinition` ABC (Abstract Base Class).
    *   `EditStore` for staging changes.
2.  **Registry Migration**: Refactor `action_registry.py` to use `ActionDefinition`.
3.  **Execution Engine**: Update `engine.py` to use `UnitOfWork` pattern.

### Phase 3: Simulation & Logic (Weeks 5-6)
**Goal**: Dynamic Impact Analysis and Automation.
1.  **Simulation Engine**: Implement `scripts/simulation/core.py`.
    *   `ScenarioFork` using `con.savepoint()`.
    *   Exposure of "Diff Views" to the Agent.
2.  **Rules Engine**: Create `scripts/automation/core.py`.
    *   Event Emitter in `ObjectManager`.
    *   Simple declarative rule registration.

### Phase 4: Migration (Week 7)
**Goal**: Port existing data structures.
1.  **Migrate Plans**: Convert `Plan/Job` (from `plan.py`) into `Intents` and `Operations` (Ontology Objects).
2.  **Migrate Memory**: Convert `Insight/Pattern` (from `memory/`) into Ontology Objects.

---

## 4. Conflict Resolution & Design Decisions

| Decision Point | Claude's Proposal | Gemini's Proposal | **Final Decision** |
|:---:|:---:|:---:|:---:|
| **Identity** | Pydantic default | UUIDv7 (Time-ordered) | **UUIDv7**: Critical for distributed merging and consistent sorting. |
| **Logic Layer** | `Experta` (RETE Engine) | `pyventus` (Event Bus) | **Event Bus (Custom)**: Start simple. RETE is overkill for current scale. |
| **Simulation** | In-Memory Copy | SQLite Savepoints | **SQLite Savepoints**: True ACID guarantee for Data; In-Memory overlay for Objects. |
| **Storage** | NetworkX Graph | Relational Adjacency | **Hybrid**: SQL for persistence ("Truth"), NetworkX for runtime analysis ("Reasoning"). |


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/README.md
# ========================================================
# Orion Framework V3.0 (Palantir AIP Edition)

The **Orion Framework** is a "Decision-Centric" Agentic IDE Architecture, designed to mimic the **Palantir Ontology**.

## 🏗️ Architecture

### 1. Conceptual Pillars
*   **Schema-First**: All code is generated from JSON Schemas (`.agent/schemas/`) via `scripts/build_ontology.sh`.
*   **Action Mandate**: State mutation is ONLY allowed via `ActionDispatcher`. Raw `open(..., 'w')` is prohibited for logic.
*   **Eventual Consistency**: All changes are logged to the Audit Ledger (`.agent/logs/ontology.db`) before execution.

### 2. Core Components (`scripts/`)
*   **`engine.py`**: The CLI Entrypoint. Bootstraps the workspace and dispatches initial Plans.
*   **`governance.py`**: The **Action Dispatcher**. Enforces Rule 1.1 (Action Mandate) and Rule 4.1 (Audit).
*   **`loop.py`**: The **Hybrid Executor**. Runs both Tier 1 (Governed Class) and Tier 2 (Function Tool) Actions.
*   **`actions.py`**: The Tool Registry for LLM capabilities (Read/Write/Grep).
*   **`ontology/`**: Auto-generated Python Models (Do not edit manually).

### 3. Digital Twin App (`math/`)
A reference implementation demonstrating the Ontology alignment.
*   **Backend**: FastAPI with `NumberAnalysis` schema.
*   **Frontend**: React with `openapi-typescript` generated client.

## 🚀 Usage

### Initialize Workspace
```bash
python3 scripts/engine.py init
```

### Dispatch a Task via Router (Rule-Based)
```bash
python3 scripts/engine.py dispatch "read file README.md"
```

### Dispatch a Plan Manually
```bash
python3 scripts/engine.py dispatch --file .agent/plans/my_plan.json
```

## 🔒 Governance Rules (CIP-PALANTIR-V1)
1.  **NEVER** write to files directly in logic code. Use `OrionAction`.
2.  **ALWAYS** validate parameters using Pydantic.
3.  **ALWAYS** define new Actions in the Ontology first.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/__init__.py
# ========================================================


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/build_ontology.sh
# ========================================================
#!/bin/bash
# scripts/build_ontology.sh

SCHEMA_DIR=".agent/schemas"
OUTPUT_DIR="scripts/ontology"

echo "Building Ontology from Schemas in $SCHEMA_DIR..."

# 1. Plan (Modular, includes Job)
echo "Generating Plan & Job..."
/home/palantir/.venv/bin/datamodel-codegen \
    --input $SCHEMA_DIR/plan.schema.json \
    --output $OUTPUT_DIR \
    --input-file-type jsonschema \
    --output-model-type pydantic.BaseModel \
    --use-schema-description \
    --field-constraints \
    --disable-timestamp \
    --target-python-version 3.10

# 2. Others (Single Files)
for schema in action trace event metric; do
    echo "Generating $schema..."
    /home/palantir/.venv/bin/datamodel-codegen \
        --input $SCHEMA_DIR/$schema.schema.json \
        --output $OUTPUT_DIR/$schema.py \
        --input-file-type jsonschema \
        --output-model-type pydantic.BaseModel \
        --use-schema-description \
        --field-constraints \
        --disable-timestamp \
        --target-python-version 3.10
done

echo "Ontology generation complete."


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/consolidate.py
# ========================================================
import os
import sys
import json
import uuid
import glob
from typing import List, Dict, Set, Any
from datetime import datetime

# Paths
WORKSPACE_ROOT = os.path.abspath(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(WORKSPACE_ROOT)

from scripts.lib.preprocessing import flatten_json
from scripts.lib.fpgrowth import FPTree
from scripts.lib.textrank import extract_summary
from scripts.memory.manager import MemoryManager

TRACE_DIR = os.path.join(WORKSPACE_ROOT, ".agent", "traces")

def load_traces(lookback_limit: int = 100) -> List[Dict[str, Any]]:
    """Loads raw trace files."""
    files = glob.glob(os.path.join(TRACE_DIR, "*.json"))
    # Sort by time newest first
    files.sort(key=os.path.getmtime, reverse=True)
    
    traces = []
    for f in files[:lookback_limit]:
        try:
            with open(f, 'r') as fd:
                data = json.load(fd)
                traces.append(data)
        except Exception as e:
            print(f"⚠️ Failed to load {f}: {e}")
    return traces

def transform_to_transactions(traces: List[Dict[str, Any]]) -> List[List[str]]:
    """
    Flattens traces into transactions for FP-Growth.
    Returns: List of lists of strings (e.g. ['status=FAILED', 'component=Executor'])
    """
    transactions = []
    
    for trace_data in traces:
        # Focus on the 'trace' object and events
        trace = trace_data.get('trace', {})
        events = trace_data.get('events', [])
        
        # Base transaction from Trace Meta
        # Flatten and convert to "key=value" strings
        flat_meta = flatten_json(trace)
        transaction_items = set()
        
        # Add high-level meta (status, etc)
        if 'status' in flat_meta:
            transaction_items.add(f"status={flat_meta['status']}")
            
        # Analyze Events
        # Basic heuristic: bag of event types and components
        for event in events:
            etype = event.get('event_type')
            comp = event.get('component')
            if etype: transaction_items.add(f"event={etype}")
            if comp: transaction_items.add(f"component={comp}")
            
            # If error, add error signature
            if etype == "ERROR" or event.get("type") == "ActionFailed":
                details = event.get('details', {})
                if isinstance(details, dict) and 'error' in details:
                    # Naive error tokenization for pattern mining
                    # e.g. "error_type=ImportError"
                    err_msg = str(details['error'])
                    if "ImportError" in err_msg: transaction_items.add("error_type=ImportError")
                    elif "ValueError" in err_msg: transaction_items.add("error_type=ValueError")
                    elif "FileNotFound" in err_msg: transaction_items.add("error_type=FileNotFound")
                    # Generic catch-all for mining
                    transaction_items.add("has_error=True")

        if transaction_items:
            transactions.append(list(transaction_items))
            
    return transactions

def consolidate():
    print("🧠 [Consolidation Engine] Waking up...")
    
    # 1. Ingest
    traces = load_traces()
    print(f"   📥 Loaded {len(traces)} traces.")
    
    if not traces:
        print("   😴 No traces to process.")
        return

    # 2. Transform
    transactions = transform_to_transactions(traces)
    
    # 3. Mine (FP-Growth)
    min_sup = 2 # Minimum 2 occurrences to be a pattern
    if len(transactions) < 2:
        print("   📉 Insufficient data for mining (need > 1 trace).")
        return

    print(f"   ⛏️  Mining patterns (Min Support: {min_sup})...")
    tree = FPTree(transactions, min_sup)
    patterns = list(tree.mine())
    
    print(f"   ✨ Found {len(patterns)} frequent patterns.")
    
    # 4. Synthesize & Persist
    mm = MemoryManager()
    
    for pattern, support in patterns:
        if len(pattern) < 2: continue # Skip single items
        
        # Check if interesting (Heuristic)
        pat_list = list(pattern)
        if "status=FAILED" in pat_list or "has_error=True" in pat_list:
            print(f"   🚨 ANALYZING FAILURE PATTERN: {pat_list} (Count: {support})")
            
            # 5. Summarize (TextRank)
            # Find relevant traces
            relevant_texts = []
            for t in traces:
                # Re-check if this trace has the pattern (Basic check)
                # Ideally, we map transaction ID back to trace ID.
                # For now, brute force scan of events
                events = t.get('events', [])
                for e in events:
                    if e.get('event_type') == "ERROR" or e.get('type') == "ActionFailed":
                        details = e.get('details', {})
                        if 'error' in details:
                            relevant_texts.append(str(details['error']))
            
            summary = "Unknown Error Pattern"
            if relevant_texts:
                summary = extract_summary(relevant_texts)
                print(f"      📝 Semantic Summary: \"{summary}\"")
                
            # 6. Save as Pattern
            pat_obj = {
                "id": f"PAT-{uuid.uuid4().hex[:6]}",
                "type": "Pattern",
                "meta": {
                    "created_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat(),
                    "frequency_count": support,
                    "success_rate": 0.0, # Anti-pattern
                    "last_used": datetime.now().isoformat(),
                    # "source": "ConsolidationEngine" # Source not in schema, safe to remove or keep if schema allows extras? Schema usually strict.
                },
                "structure": {
                    "trigger": "System Error",
                    "steps": [],
                    "anti_patterns": list(pattern),
                    "insight": summary
                }
            }
            mm.save_object("pattern", pat_obj)
            print("      💾 Saved to Memory.")

if __name__ == "__main__":
    consolidate()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/debug_inject_failure.py
# ========================================================
from scripts.observer import Observer
from scripts.ontology import Event, EventType
from datetime import datetime
import uuid

def inject():
    trace_id = Observer.start_trace("test_failure_mining", tags=["test"])
    
    # Emit normal event
    Observer.emit(Event(
        id=str(uuid.uuid4()),
        trace_id=trace_id,
        event_type=EventType.ACTION_START,
        component="Executor",
        details={"action": "run_command", "cmd": "bad_cmd"},
        timestamp=datetime.now().isoformat()
    ))
    
    # Emit Failure
    Observer.emit(Event(
        id=str(uuid.uuid4()),
        trace_id=trace_id,
        event_type=EventType.ERROR,
        component="Executor",
        details={"error": "FileNotFoundError: /bad/path not found"},
        timestamp=datetime.now().isoformat()
    ))
    
    # End Trace (FAILED)
    from scripts.ontology import StatusEnum
    Observer.end_trace(StatusEnum.FAILED)

if __name__ == "__main__":
    inject()
    # Inject twice to ensure pattern (min_sup=2)
    inject()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/governance.py
# ========================================================

import logging
import uuid
import json
import os
import sqlite3
from datetime import datetime
from abc import ABC, abstractmethod
from typing import TypeVar, Generic, Any, Dict
from pydantic import BaseModel
from scripts.observer import Observer
from scripts.ontology import Event, EventType

# Mimic Palantir's UserFacingError
class UserFacingError(Exception):
    def __init__(self, message: str, error_name: str = "InvalidAction"):
        self.message = message
        self.error_name = error_name
        super().__init__(f"[{error_name}] {message}")

class OntologyContext:
    """Read-Only view of the Ontology for validation."""
    def __init__(self, workspace_root: str):
        self.workspace_root = workspace_root

TParams = TypeVar("TParams", bound=BaseModel)

class OrionAction(ABC, Generic[TParams]):
    """
    Tier 1 Action: Class-based, Schematized, Deterministic.
    Use this for Core Ontology Mutations (Plans, Jobs, Objects).
    """
    def __init__(self, parameters: TParams):
        self.params = parameters
        self.action_id = str(uuid.uuid4())
        self.timestamp = datetime.now()

    @property
    @abstractmethod
    def action_type(self) -> str:
        """Unique API Identifier for the Action."""
        pass

    @abstractmethod
    def validate(self, ctx: OntologyContext) -> None:
        """Pure logic validation. Raises UserFacingError."""
        pass

    @abstractmethod
    def _apply_side_effects(self, ctx: OntologyContext) -> dict:
        """The actual mutation logic (Privacy: Protected)."""
        pass

class ActionDispatcher:
    """
    The Governance Funnel.
    Enforces Rule 1.1 (Action Mandate) and Rule 4.1 (Audit).
    """
    def __init__(self, workspace_root: str):
        self.ctx = OntologyContext(workspace_root)
        self.logger = logging.getLogger("OrionGovernance")
        self._db_path = os.path.join(workspace_root, ".agent", "logs", "ontology.db")
        os.makedirs(os.path.dirname(self._db_path), exist_ok=True)
        self._init_db()

    def _init_db(self):
        """Initialize the SQLite Audit Ledger (Immutable Log)."""
        try:
            with sqlite3.connect(self._db_path) as conn:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS audit_log (
                        id TEXT PRIMARY KEY,
                        timestamp TEXT NOT NULL,
                        event_type TEXT NOT NULL,
                        action_type TEXT NOT NULL,
                        action_id TEXT NOT NULL,
                        parameters TEXT NOT NULL, -- JSON String
                        user TEXT NOT NULL,
                        result TEXT, -- JSON String (Updated on commit)
                        status TEXT DEFAULT 'PENDING'
                    )
                """)
                conn.commit()
        except Exception as e:
            self.logger.critical(f"Failed to initialize Ledger DB: {e}")
            raise

    def dispatch(self, action: OrionAction) -> Dict[str, Any]:
        try:
            # 1. Logic / Validation (Rule 1.2)
            action.validate(self.ctx)

            # 2. Intent Capture (Audit Log - Transaction Start)
            self._log_intent(action)

            # 3. Notification (Observer)
            Observer.emit(Event(
                trace_id=f"TRACE-{action.action_id}", # Link trace to action
                event_type=EventType.ACTION_START,
                component="ActionDispatcher",
                details={"action_id": action.action_id, "type": action.action_type},
                timestamp=datetime.now().isoformat()
            ))

            # 4. Side Effect (Mutation)
            result = action._apply_side_effects(self.ctx)

            # 5. Success (Update Ledger)
            self._update_ledger_success(action.action_id, result)

            Observer.emit(Event(
                trace_id=f"TRACE-{action.action_id}",
                event_type=EventType.ACTION_END,
                component="ActionDispatcher",
                details={"action_id": action.action_id, "result": result},
                timestamp=datetime.now().isoformat()
            ))
            
            return {"status": "success", "action_id": action.action_id, "result": result}

        except UserFacingError as e:
            self.logger.warning(f"Action Rejected: {e}")
            self._update_ledger_fail(action.action_id, str(e))
            raise
        except Exception as e:
            self.logger.error(f"System Failure in Action {action.action_id}: {e}")
            self._update_ledger_fail(action.action_id, str(e))
            raise RuntimeError("Internal Ontology Error") from e

    def _log_intent(self, action: OrionAction):
        with sqlite3.connect(self._db_path) as conn:
            conn.execute(
                "INSERT INTO audit_log (id, timestamp, event_type, action_type, action_id, parameters, user) VALUES (?, ?, ?, ?, ?, ?, ?)",
                (
                    str(uuid.uuid4()),
                    action.timestamp.isoformat(),
                    "ontology_action_submission",
                    action.action_type,
                    action.action_id,
                    action.params.model_dump_json(),
                    "local_agent"
                )
            )
            conn.commit()

    def _update_ledger_success(self, action_id: str, result: Dict):
        with sqlite3.connect(self._db_path) as conn:
            conn.execute(
                "UPDATE audit_log SET status = ?, result = ? WHERE action_id = ?",
                ("COMMITTED", json.dumps(result), action_id)
            )
            conn.commit()

    def _update_ledger_fail(self, action_id: str, error: str):
        try:
            with sqlite3.connect(self._db_path) as conn:
                conn.execute(
                    "UPDATE audit_log SET status = ?, result = ? WHERE action_id = ?",
                    ("FAILED", json.dumps({"error": error}), action_id)
                )
                conn.commit()
        except:
            pass # Fail silently if DB is broken



# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/indexer.py
# ========================================================
import os
import ast
import sys
import json
from typing import Dict, List, Set

WORKSPACE_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

def get_module_name(file_path: str) -> str:
    """Converts file path to python module path (e.g., scripts/engine.py -> scripts.engine)"""
    rel_path = os.path.relpath(file_path, WORKSPACE_ROOT)
    if rel_path.endswith('.py'):
        rel_path = rel_path[:-3]
    return rel_path.replace(os.sep, '.')

def build_dependency_graph() -> Dict[str, Set[str]]:
    """
    Scans workspace for Python files and builds a Reverse Dependency Graph.
    Key: Module Name (Imported)
    Value: Set of Modules that import Key (Importers)
    """
    reverse_deps: Dict[str, Set[str]] = {}
    
    for root, _, files in os.walk(WORKSPACE_ROOT):
        if '.venv' in root or '.git' in root or '__pycache__' in root:
            continue
            
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                importer_module = get_module_name(file_path)
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        tree = ast.parse(f.read())
                        
                    for node in ast.walk(tree):
                        target_module = None
                        if isinstance(node, ast.Import):
                            for alias in node.names:
                                target_module = alias.name
                        elif isinstance(node, ast.ImportFrom):
                            if node.module:
                                target_module = node.module
                                
                        if target_module:
                            # Normalize relative imports
                            if target_module.startswith('.'):
                                # Complex to resolve perfectly statically, but we capture the intent
                                pass 
                            
                            # Add to graph
                            if target_module not in reverse_deps:
                                reverse_deps[target_module] = set()
                            reverse_deps[target_module].add(importer_module)
                            
                except Exception as e:
                    # Skip unparseable files
                    pass
                    
    return reverse_deps

def check_impact(target_file: str):
    """Checks what files depend on the target file."""
    target_module = get_module_name(target_file)
    graph = build_dependency_graph()
    
    # Exact match
    impacted = graph.get(target_module, set())
    
    # Prefix match (e.g. scripts.ontology matches scripts.ontology.plan usage)
    for mod, dependents in graph.items():
        if mod.startswith(target_module + ".") or target_module.startswith(mod + "."):
            impacted.update(dependents)
            
    # Filter self
    if target_module in impacted:
        impacted.remove(target_module)
        
    print(json.dumps({
        "target": target_module,
        "impact_score": len(impacted),
        "impacted_modules": sorted(list(impacted))
    }, indent=2))

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python3 scripts/indexer.py <file_path>")
        sys.exit(1)
        
    target = sys.argv[1]
    if not os.path.exists(target):
        # Try relative to root
        target = os.path.join(WORKSPACE_ROOT, target)
        
    check_impact(target)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/lifecycle_manager.py
# ========================================================

import os
import shutil
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict

# Configure Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("LifecycleManager")

AGENTS_ROOT = "/home/palantir/.agent"
PLANS_DIR = os.path.join(AGENTS_ROOT, "plans")
ARCHIVE_ROOT = os.path.join(AGENTS_ROOT, "archives", "plans")

class LifecycleManager:
    """
    Manages the lifecycle of ephemeral artifacts (Plans, Logs).
    Enforces Entropy Reduction by archiving old artifacts.
    """

    def __init__(self, retention_hours: int = 24):
        self.retention_hours = retention_hours
        self.cutoff_time = datetime.now() - timedelta(hours=retention_hours)

    def run_archival(self):
        """Main entry point for archival process."""
        logger.info(f"🧹 Starting Entropy Reduction (Retention: {self.retention_hours}h)...")
        
        if not os.path.exists(PLANS_DIR):
            logger.warning(f"Plan directory not found: {PLANS_DIR}")
            return

        files = [f for f in os.listdir(PLANS_DIR) if os.path.isfile(os.path.join(PLANS_DIR, f))]
        archived_count = 0

        for filename in files:
            file_path = os.path.join(PLANS_DIR, filename)
            
            # Skip the visualization file we just made if it's new, but generally check all
            if self._should_archive(file_path):
                self._archive_file(file_path)
                archived_count += 1

        logger.info(f"✨ Entropy Reduction Complete. Archived {archived_count} files.")

    def _should_archive(self, file_path: str) -> bool:
        """Determines if a file is old enough to be archived."""
        try:
            # 1. Try to read JSON metadata (Most accurate)
            if file_path.endswith(".json"):
                with open(file_path, 'r') as f:
                    data = json.load(f)
                    created_at_str = data.get("created_at")
                    if created_at_str:
                        # Handle various ISO formats if needed, assuming ISO 8601
                        created_at = datetime.fromisoformat(created_at_str)
                        return created_at < self.cutoff_time
            
            # 2. Fallback to File System MTime
            mtime_timestamp = os.path.getmtime(file_path)
            mtime = datetime.fromtimestamp(mtime_timestamp)
            return mtime < self.cutoff_time

        except Exception as e:
            logger.warning(f"Failed to check file {file_path}: {e}")
            return False

    def _archive_file(self, source_path: str):
        """Moves file to the appropriate archive directory."""
        try:
            mtime_timestamp = os.path.getmtime(source_path)
            dt = datetime.fromtimestamp(mtime_timestamp)
            
            # Structure: archives/plans/YYYY/MM/DD/
            target_dir = os.path.join(
                ARCHIVE_ROOT,
                f"{dt.year:04d}",
                f"{dt.month:02d}",
                f"{dt.day:02d}"
            )
            
            os.makedirs(target_dir, exist_ok=True)
            
            filename = os.path.basename(source_path)
            target_path = os.path.join(target_dir, filename)
            
            shutil.move(source_path, target_path)
            logger.info(f"📦 Archived: {filename} -> {target_path}")
            
        except Exception as e:
            logger.error(f"❌ Failed to archive {source_path}: {e}")

if __name__ == "__main__":
    # If run directly, run archival
    manager = LifecycleManager(retention_hours=24)
    manager.run_archival()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/mcp_manager.py
# ========================================================
#!/usr/bin/env python3
"""
ODA-aligned MCP tooling manager.

Goals:
- Keep MCP server definitions consistent across multiple agents (Antigravity/Gemini, Claude, etc.)
- Support installing the GitHub MCP server as a native binary (no Docker dependency)
- Avoid leaking secrets: never print env values, only env keys

This module is intentionally stdlib-only so it can run regardless of which LLM/agent invokes it.
"""

from __future__ import annotations

import argparse
import hashlib
import json
import os
import platform
import shutil
import tarfile
import tempfile
from datetime import datetime, timezone
from typing import Any, Dict, Iterable, List, Optional, Tuple
from urllib.request import Request, urlopen

WORKSPACE_ROOT = os.environ.get("ORION_WORKSPACE_ROOT", "/home/palantir")

ANTIGRAVITY_MCP_CONFIG_PATH = os.path.join(WORKSPACE_ROOT, ".gemini", "antigravity", "mcp_config.json")
CLAUDE_CONFIG_PATH = os.path.join(WORKSPACE_ROOT, ".claude.json")

MCP_REGISTRY_PATH = os.path.join(WORKSPACE_ROOT, ".agent", "mcp", "registry.json")
MCP_AUDIT_LOG_PATH = os.path.join(WORKSPACE_ROOT, ".agent", "logs", "mcp_audit.jsonl")

DEFAULT_GITHUB_MCP_INSTALL_PATH = os.path.join(WORKSPACE_ROOT, ".local", "bin", "github-mcp-server")


def _utc_now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def _ensure_parent_dir(path: str) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)


def _read_json(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if not isinstance(data, dict):
        raise ValueError(f"Expected JSON object in {path}")
    return data


def _atomic_write_json(path: str, data: Dict[str, Any]) -> None:
    _ensure_parent_dir(path)
    directory = os.path.dirname(path) or "."
    fd, tmp_path = tempfile.mkstemp(prefix=".tmp.", suffix=".json", dir=directory)
    try:
        with os.fdopen(fd, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            f.write("\n")
        os.replace(tmp_path, path)
    finally:
        if os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except OSError:
                pass


def _append_audit(event: Dict[str, Any]) -> None:
    safe_event = dict(event)
    safe_event.setdefault("timestamp", _utc_now_iso())
    _ensure_parent_dir(MCP_AUDIT_LOG_PATH)
    with open(MCP_AUDIT_LOG_PATH, "a", encoding="utf-8") as f:
        f.write(json.dumps(safe_event, ensure_ascii=False))
        f.write("\n")


def _redact_env_values(env: Optional[Dict[str, Any]]) -> Optional[Dict[str, str]]:
    if not env:
        return env
    redacted: Dict[str, str] = {}
    for k in env.keys():
        redacted[str(k)] = "***REDACTED***"
    return redacted


def _normalize_server_id(server_key: str) -> str:
    # Keep canonical IDs stable across tools.
    if server_key == "github-mcp-server":
        return "github"
    return server_key


def _antigravity_key_for_id(server_id: str) -> str:
    if server_id == "github":
        return "github-mcp-server"
    return server_id


def _load_antigravity_config(path: str = ANTIGRAVITY_MCP_CONFIG_PATH) -> Dict[str, Any]:
    if not os.path.exists(path):
        return {"mcpServers": {}}
    config = _read_json(path)
    if "mcpServers" not in config:
        config["mcpServers"] = {}
    if not isinstance(config["mcpServers"], dict):
        raise ValueError(f"Invalid Antigravity MCP config: mcpServers must be an object: {path}")
    return config


def _load_claude_config(path: str = CLAUDE_CONFIG_PATH) -> Dict[str, Any]:
    if not os.path.exists(path):
        raise FileNotFoundError(f"Claude config not found: {path}")
    return _read_json(path)


def _ensure_claude_project(config: Dict[str, Any], project_path: str) -> Dict[str, Any]:
    projects = config.setdefault("projects", {})
    if not isinstance(projects, dict):
        raise ValueError("Invalid Claude config: projects must be an object")
    project = projects.setdefault(project_path, {})
    if not isinstance(project, dict):
        raise ValueError("Invalid Claude config: projects.<path> must be an object")
    mcp_servers = project.setdefault("mcpServers", {})
    if not isinstance(mcp_servers, dict):
        raise ValueError("Invalid Claude config: projects.<path>.mcpServers must be an object")
    return project


def _detect_github_asset() -> Tuple[str, str]:
    system = platform.system()
    machine = platform.machine().lower()

    if system == "Linux":
        if machine in {"x86_64", "amd64"}:
            return "Linux_x86_64", "tar.gz"
        if machine in {"aarch64", "arm64"}:
            return "Linux_arm64", "tar.gz"
        if machine in {"i386", "i686"}:
            return "Linux_i386", "tar.gz"
    if system == "Darwin":
        if machine in {"arm64", "aarch64"}:
            return "Darwin_arm64", "tar.gz"
        if machine in {"x86_64", "amd64"}:
            return "Darwin_x86_64", "tar.gz"
    if system == "Windows":
        if machine in {"arm64", "aarch64"}:
            return "Windows_arm64", "zip"
        if machine in {"x86_64", "amd64"}:
            return "Windows_x86_64", "zip"
        if machine in {"i386", "i686"}:
            return "Windows_i386", "zip"

    raise RuntimeError(f"Unsupported platform: system={system} machine={machine}")


def _http_get_json(url: str) -> Dict[str, Any]:
    req = Request(url, headers={"Accept": "application/vnd.github+json", "User-Agent": "orion-mcp-manager"})
    with urlopen(req, timeout=30) as r:
        data = json.loads(r.read().decode("utf-8", "replace"))
    if not isinstance(data, dict):
        raise ValueError(f"Expected JSON object from {url}")
    return data


def _http_download(url: str, dest_path: str) -> None:
    req = Request(url, headers={"User-Agent": "orion-mcp-manager"})
    _ensure_parent_dir(dest_path)
    with urlopen(req, timeout=60) as r, open(dest_path, "wb") as f:
        shutil.copyfileobj(r, f)


def _sha256_file(path: str) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def _parse_checksums_file(path: str) -> Dict[str, str]:
    checksums: Dict[str, str] = {}
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) != 2:
                continue
            sha, name = parts
            checksums[name] = sha
    return checksums


def install_github_mcp_server(*, install_path: str = DEFAULT_GITHUB_MCP_INSTALL_PATH, tag: str = "latest") -> Dict[str, Any]:
    """
    Download and install GitHub's github-mcp-server as a native binary.
    """
    suffix, ext = _detect_github_asset()
    release_url = "https://api.github.com/repos/github/github-mcp-server/releases/latest"
    if tag != "latest":
        release_url = f"https://api.github.com/repos/github/github-mcp-server/releases/tags/{tag}"

    release = _http_get_json(release_url)
    tag_name = release.get("tag_name") or tag

    asset_name = f"github-mcp-server_{suffix}.{ext}"
    # Release assets use slightly different naming, e.g. github-mcp-server_Linux_x86_64.tar.gz
    if suffix.startswith("Linux") or suffix.startswith("Darwin"):
        asset_name = f"github-mcp-server_{suffix}.tar.gz"
    if suffix.startswith("Windows"):
        asset_name = f"github-mcp-server_{suffix}.zip"

    download_url = f"https://github.com/github/github-mcp-server/releases/download/{tag_name}/{asset_name}"
    checksums_url = f"https://github.com/github/github-mcp-server/releases/download/{tag_name}/github-mcp-server_{tag_name.lstrip('v')}_checksums.txt"

    with tempfile.TemporaryDirectory(prefix="github-mcp-server.") as tmp_dir:
        archive_path = os.path.join(tmp_dir, asset_name)
        checksums_path = os.path.join(tmp_dir, "checksums.txt")
        _http_download(download_url, archive_path)
        _http_download(checksums_url, checksums_path)

        checksums = _parse_checksums_file(checksums_path)
        expected = checksums.get(asset_name)
        if not expected:
            raise RuntimeError(f"Checksum for {asset_name} not found in checksums file")

        actual = _sha256_file(archive_path)
        if actual != expected:
            raise RuntimeError(f"Checksum mismatch for {asset_name}: expected {expected}, got {actual}")

        if not asset_name.endswith(".tar.gz"):
            raise RuntimeError(f"Unsupported archive format for this environment: {asset_name}")

        extracted_binary_path: Optional[str] = None
        with tarfile.open(archive_path, "r:gz") as tar:
            for member in tar.getmembers():
                base = os.path.basename(member.name)
                if member.isfile() and base == "github-mcp-server":
                    extracted_binary_path = os.path.join(tmp_dir, "github-mcp-server")
                    extracted = tar.extractfile(member)
                    if extracted is None:
                        raise RuntimeError("Failed to read github-mcp-server binary from archive")
                    with extracted, open(extracted_binary_path, "wb") as out:
                        shutil.copyfileobj(extracted, out)
                    break

        if not extracted_binary_path or not os.path.exists(extracted_binary_path):
            raise RuntimeError("Failed to extract github-mcp-server binary from archive")

        _ensure_parent_dir(install_path)
        shutil.copy2(extracted_binary_path, install_path)
        os.chmod(install_path, 0o755)

    _append_audit(
        {
            "action": "install_github_mcp_server",
            "tag": tag_name,
            "install_path": install_path,
        }
    )
    return {"status": "ok", "tag": tag_name, "install_path": install_path}


def _load_registry(path: str = MCP_REGISTRY_PATH) -> Dict[str, Any]:
    if not os.path.exists(path):
        return {"version": 1, "workspaceRoot": WORKSPACE_ROOT, "servers": {}}
    reg = _read_json(path)
    reg.setdefault("version", 1)
    reg.setdefault("workspaceRoot", WORKSPACE_ROOT)
    reg.setdefault("servers", {})
    if not isinstance(reg["servers"], dict):
        raise ValueError(f"Invalid MCP registry: servers must be an object: {path}")
    return reg


def _write_registry(registry: Dict[str, Any], path: str = MCP_REGISTRY_PATH) -> None:
    _atomic_write_json(path, registry)


def init_registry_from_existing(*, write: bool = False) -> Dict[str, Any]:
    """
    Initialize (or update) the canonical MCP registry by introspecting existing tool configs.

    Env values are not stored; only env keys.
    """
    registry = _load_registry()
    servers: Dict[str, Any] = dict(registry.get("servers") or {})

    # Antigravity source
    try:
        ag = _load_antigravity_config()
        for key, server in (ag.get("mcpServers") or {}).items():
            if not isinstance(server, dict):
                continue
            server_id = _normalize_server_id(key)
            entry = servers.get(server_id, {})
            entry.setdefault("type", "stdio")
            if "command" in server:
                entry["command"] = server.get("command")
            if "args" in server:
                entry["args"] = server.get("args")
            env = server.get("env")
            if isinstance(env, dict):
                entry.setdefault("envKeys", sorted(set(map(str, env.keys()))))
            if server.get("disabled") is True:
                entry["disabled"] = True
            servers[server_id] = entry
    except Exception:
        # No Antigravity config: ignore
        pass

    # Claude source (project scoped)
    try:
        cc = _load_claude_config()
        project = cc.get("projects", {}).get(WORKSPACE_ROOT, {})
        mcp_servers = project.get("mcpServers", {}) if isinstance(project, dict) else {}
        if isinstance(mcp_servers, dict):
            for key, server in mcp_servers.items():
                if not isinstance(server, dict):
                    continue
                server_id = _normalize_server_id(key)
                entry = servers.get(server_id, {})
                entry.setdefault("type", server.get("type") or "stdio")
                entry.setdefault("command", server.get("command"))
                entry.setdefault("args", server.get("args"))
                env = server.get("env")
                if isinstance(env, dict):
                    entry.setdefault("envKeys", sorted(set(map(str, env.keys()))))
                servers[server_id] = entry
    except Exception:
        pass

    registry["servers"] = servers
    if write:
        _write_registry(registry)
        _append_audit({"action": "init_registry_from_existing", "registry_path": MCP_REGISTRY_PATH})

    return registry


def _apply_registry_to_antigravity(registry: Dict[str, Any], *, write: bool) -> Dict[str, Any]:
    config = _load_antigravity_config()
    mcp_servers: Dict[str, Any] = config.get("mcpServers", {})

    changes: List[str] = []
    for server_id, entry in (registry.get("servers") or {}).items():
        if not isinstance(entry, dict):
            continue
        key = _antigravity_key_for_id(server_id)
        server = mcp_servers.get(key)
        if not isinstance(server, dict):
            server = {}

        desired_command = entry.get("command")
        desired_args = entry.get("args") or []

        if desired_command:
            if server.get("command") != desired_command:
                server["command"] = desired_command
                changes.append(f"antigravity:{key}:command")
        if isinstance(desired_args, list):
            if server.get("args") != desired_args:
                server["args"] = desired_args
                changes.append(f"antigravity:{key}:args")

        if entry.get("disabled") is True:
            if server.get("disabled") is not True:
                server["disabled"] = True
                changes.append(f"antigravity:{key}:disabled")

        # Never overwrite env values here; preserve existing secrets.
        mcp_servers[key] = server

    config["mcpServers"] = mcp_servers
    if write and changes:
        _atomic_write_json(ANTIGRAVITY_MCP_CONFIG_PATH, config)
        _append_audit(
            {
                "action": "sync_antigravity_config",
                "path": ANTIGRAVITY_MCP_CONFIG_PATH,
                "changes": changes,
            }
        )

    return {"path": ANTIGRAVITY_MCP_CONFIG_PATH, "changed": bool(changes), "changes": changes}


def _apply_registry_to_claude(registry: Dict[str, Any], *, write: bool) -> Dict[str, Any]:
    if not os.path.exists(CLAUDE_CONFIG_PATH):
        return {
            "path": CLAUDE_CONFIG_PATH,
            "skipped": True,
            "reason": "Claude config not found",
            "changed": False,
            "changes": [],
        }

    config = _load_claude_config()
    project = _ensure_claude_project(config, WORKSPACE_ROOT)
    mcp_servers: Dict[str, Any] = project.get("mcpServers", {})

    changes: List[str] = []
    for server_id, entry in (registry.get("servers") or {}).items():
        if not isinstance(entry, dict):
            continue

        key = server_id
        server = mcp_servers.get(key)
        if not isinstance(server, dict):
            server = {"type": entry.get("type") or "stdio"}

        desired_command = entry.get("command")
        desired_args = entry.get("args") or []

        if desired_command and server.get("command") != desired_command:
            server["command"] = desired_command
            changes.append(f"claude:{key}:command")
        if isinstance(desired_args, list) and server.get("args") != desired_args:
            server["args"] = desired_args
            changes.append(f"claude:{key}:args")
        if server.get("type") != (entry.get("type") or server.get("type") or "stdio"):
            server["type"] = entry.get("type") or "stdio"
            changes.append(f"claude:{key}:type")

        # Do not inject env values. Preserve if already present.
        mcp_servers[key] = server

    project["mcpServers"] = mcp_servers
    if write and changes:
        _atomic_write_json(CLAUDE_CONFIG_PATH, config)
        _append_audit(
            {
                "action": "sync_claude_config",
                "path": CLAUDE_CONFIG_PATH,
                "changes": changes,
            }
        )

    return {"path": CLAUDE_CONFIG_PATH, "skipped": False, "changed": bool(changes), "changes": changes}


def sync_from_registry(*, write: bool) -> Dict[str, Any]:
    registry = _load_registry()
    result = {
        "registry_path": MCP_REGISTRY_PATH,
        "antigravity": _apply_registry_to_antigravity(registry, write=write),
        "claude": _apply_registry_to_claude(registry, write=write),
    }
    return result


def set_github_native(*, install_path: str = DEFAULT_GITHUB_MCP_INSTALL_PATH, write: bool) -> Dict[str, Any]:
    """
    Update the canonical registry to point GitHub MCP at the native binary, then sync configs.
    """
    if not os.path.exists(install_path):
        raise FileNotFoundError(f"github-mcp-server not installed at {install_path}")

    registry = _load_registry()
    servers = registry.setdefault("servers", {})
    github = servers.get("github")
    if not isinstance(github, dict):
        github = {"type": "stdio"}

    github["type"] = "stdio"
    github["command"] = install_path
    github["args"] = ["stdio"]
    github.setdefault("envKeys", ["GITHUB_PERSONAL_ACCESS_TOKEN"])
    servers["github"] = github
    registry["servers"] = servers

    if write:
        _write_registry(registry)
        _append_audit({"action": "set_github_native", "install_path": install_path, "registry_path": MCP_REGISTRY_PATH})

    sync_result = sync_from_registry(write=write)
    return {"registry_updated": True, "sync": sync_result}


def status() -> Dict[str, Any]:
    registry = _load_registry()
    reg_servers = registry.get("servers") or {}

    ag = _load_antigravity_config()
    ag_servers = ag.get("mcpServers") or {}

    cc = None
    try:
        cc = _load_claude_config()
    except Exception:
        cc = None

    claude_servers: Dict[str, Any] = {}
    if isinstance(cc, dict):
        project = cc.get("projects", {}).get(WORKSPACE_ROOT, {})
        if isinstance(project, dict) and isinstance(project.get("mcpServers"), dict):
            claude_servers = project.get("mcpServers", {})

    def summarize_server(server: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "command": server.get("command"),
            "args": server.get("args"),
            "serverUrl": server.get("serverUrl"),
            "disabled": server.get("disabled"),
            "env": _redact_env_values(server.get("env") if isinstance(server.get("env"), dict) else None),
        }

    report: Dict[str, Any] = {"registry_path": MCP_REGISTRY_PATH, "workspaceRoot": WORKSPACE_ROOT, "servers": {}}
    for server_id, entry in reg_servers.items():
        if not isinstance(entry, dict):
            continue
        ag_key = _antigravity_key_for_id(server_id)
        report["servers"][server_id] = {
            "registry": {"command": entry.get("command"), "args": entry.get("args"), "envKeys": entry.get("envKeys")},
            "antigravity": summarize_server(ag_servers.get(ag_key, {}) if isinstance(ag_servers.get(ag_key), dict) else {}),
            "claude": summarize_server(claude_servers.get(server_id, {}) if isinstance(claude_servers.get(server_id), dict) else {}),
        }
    return report


def _print_json(data: Dict[str, Any]) -> None:
    print(json.dumps(data, ensure_ascii=False, indent=2))


def main(argv: Optional[List[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="ODA MCP manager (multi-agent consistent MCP tooling)")
    sub = parser.add_subparsers(dest="cmd", required=True)

    sub.add_parser("status", help="Show MCP registry + per-agent config summary (env values redacted)")

    init_p = sub.add_parser("init-registry", help="Create/update canonical registry from existing configs")
    init_p.add_argument("--write", action="store_true", help="Write registry to disk")

    sync_p = sub.add_parser("sync", help="Sync configs from canonical registry")
    sync_p.add_argument("--write", action="store_true", help="Write changes to configs")

    inst_p = sub.add_parser("install-github", help="Install github-mcp-server as native binary")
    inst_p.add_argument("--tag", default="latest", help="Release tag (default: latest)")
    inst_p.add_argument("--install-path", default=DEFAULT_GITHUB_MCP_INSTALL_PATH, help="Install path for binary")

    set_p = sub.add_parser("set-github-native", help="Point registry+configs at native github-mcp-server")
    set_p.add_argument("--install-path", default=DEFAULT_GITHUB_MCP_INSTALL_PATH, help="Path to github-mcp-server binary")
    set_p.add_argument("--write", action="store_true", help="Write registry/config changes")

    args = parser.parse_args(argv)

    if args.cmd == "status":
        _print_json(status())
        return 0

    if args.cmd == "init-registry":
        reg = init_registry_from_existing(write=args.write)
        _print_json(reg)
        return 0

    if args.cmd == "sync":
        _print_json(sync_from_registry(write=args.write))
        return 0

    if args.cmd == "install-github":
        _print_json(install_github_mcp_server(install_path=args.install_path, tag=args.tag))
        return 0

    if args.cmd == "set-github-native":
        _print_json(set_github_native(install_path=args.install_path, write=args.write))
        return 0

    raise RuntimeError("unreachable")


if __name__ == "__main__":
    raise SystemExit(main())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/mcp_preflight.py
# ========================================================
#!/usr/bin/env python3

import json
import os
import shutil
import subprocess
import argparse
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple


DEFAULT_ANTIGRAVITY_MCP_CONFIG_PATH = "/home/palantir/.gemini/antigravity/mcp_config.json"


@dataclass(frozen=True)
class McpServerCheckResult:
    name: str
    status: str  # ok | disabled | error | skipped
    reason: Optional[str] = None


def _which(command: str) -> Optional[str]:
    if os.path.isabs(command):
        return command if os.path.exists(command) else None
    return shutil.which(command)


def _is_npx_command(command: str) -> bool:
    return os.path.basename(command) == "npx"


def _check_docker_access(timeout_s: int = 5) -> Tuple[bool, str]:
    docker_path = _which("docker")
    if not docker_path:
        return False, "docker not found in PATH"

    try:
        result = subprocess.run(
            [docker_path, "info"],
            capture_output=True,
            text=True,
            timeout=timeout_s,
        )
    except Exception as exc:
        return False, f"docker info failed: {exc}"

    if result.returncode == 0:
        return True, "docker daemon reachable"

    msg = (result.stderr or result.stdout or "").strip()
    msg_lower = msg.lower()
    if "permission denied" in msg_lower and "docker.sock" in msg_lower:
        return (
            False,
            "permission denied to docker socket (try adding user to 'docker' group or running with proper privileges)",
        )
    if "cannot connect to the docker daemon" in msg_lower:
        return False, "docker daemon not reachable (is the service running?)"
    return False, msg or "docker info returned non-zero exit code"


def _looks_like_abs_path(value: str) -> bool:
    return value.startswith("/")


def _check_command_and_args(command: str, args: List[str]) -> Tuple[bool, str]:
    resolved = _which(command)
    if not resolved:
        return False, f"command not found: {command}"

    if os.path.isabs(resolved) and not os.access(resolved, os.X_OK):
        return False, f"command not executable: {resolved}"

    missing_paths: List[str] = []
    for arg in args:
        if not isinstance(arg, str):
            continue
        if _looks_like_abs_path(arg) and not os.path.exists(arg):
            missing_paths.append(arg)

    if missing_paths:
        return False, f"missing arg paths: {', '.join(missing_paths[:5])}"

    return True, "command and arg paths look valid"


def _probe_stdio_startup(
    command: str,
    args: List[str],
    *,
    env: Optional[Dict[str, str]] = None,
    timeout_s: float = 1.5,
) -> Tuple[bool, str]:
    """
    Best-effort startup probe:
    - If the process exits quickly -> error (likely to trigger IDE retry loops)
    - If the process is still running after timeout -> ok

    stdout/stderr are discarded to avoid blocking and to avoid accidentally printing secrets.
    """
    resolved = _which(command)
    if not resolved:
        return False, f"command not found: {command}"

    merged_env = os.environ.copy()
    if env:
        merged_env.update({str(k): str(v) for k, v in env.items()})

    try:
        proc = subprocess.Popen(
            [resolved, *args],
            stdin=subprocess.PIPE,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            env=merged_env,
            start_new_session=True,
        )
    except Exception as exc:
        return False, f"failed to start process: {exc}"

    try:
        try:
            proc.wait(timeout=timeout_s)
        except subprocess.TimeoutExpired:
            return True, "startup probe: process is running"

        code = proc.returncode
        return False, f"startup probe: exited early (code={code})"
    finally:
        if proc.poll() is None:
            try:
                proc.terminate()
                proc.wait(timeout=1.0)
            except Exception:
                try:
                    proc.kill()
                except Exception:
                    pass


def _npx_probe_args(args: List[str]) -> List[str]:
    """
    Prevent npx from attempting network installs during preflight.
    If the package isn't already available, the probe should fail quickly so we can disable it.
    """
    if any(a == "--no-install" for a in args):
        return args
    return ["--no-install", *args]


def _check_server(
    name: str,
    server: Dict[str, Any],
    *,
    probe_startup: bool,
    probe_timeout_s: float,
) -> McpServerCheckResult:
    if server.get("disabled") is True:
        return McpServerCheckResult(name=name, status="disabled", reason="explicitly disabled")

    if server.get("serverUrl"):
        return McpServerCheckResult(name=name, status="skipped", reason="remote serverUrl (not checked)")

    command = server.get("command")
    args = server.get("args") or []
    env = server.get("env") if isinstance(server.get("env"), dict) else None

    if not isinstance(command, str) or not command:
        return McpServerCheckResult(name=name, status="error", reason="missing command")
    if not isinstance(args, list) or any(not isinstance(a, str) for a in args):
        return McpServerCheckResult(name=name, status="error", reason="args must be string[]")

    if os.path.basename(command) == "docker":
        ok, msg = _check_docker_access()
        return McpServerCheckResult(name=name, status="ok" if ok else "error", reason=msg)

    ok, msg = _check_command_and_args(command, args)
    if not ok:
        return McpServerCheckResult(name=name, status="error", reason=msg)

    if not probe_startup:
        return McpServerCheckResult(name=name, status="ok", reason=msg)

    probe_args = _npx_probe_args(args) if _is_npx_command(command) else args
    ok2, msg2 = _probe_stdio_startup(command, probe_args, env=env, timeout_s=probe_timeout_s)
    return McpServerCheckResult(name=name, status="ok" if ok2 else "error", reason=msg2)


def preflight_mcp_config(
    config_path: str = DEFAULT_ANTIGRAVITY_MCP_CONFIG_PATH,
    *,
    auto_disable_failed: bool = False,
    write: bool = False,
    probe_startup: bool = True,
    probe_timeout_s: float = 1.5,
) -> Dict[str, Any]:
    """
    Preflight-check an Antigravity MCP config and optionally disable failing servers.

    This is designed as a mitigation for IDE-side retry loops when a configured MCP server
    cannot be started (e.g., docker not reachable).
    """
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)

    servers: Dict[str, Any] = config.get("mcpServers") or {}
    if not isinstance(servers, dict):
        raise ValueError("Invalid MCP config: 'mcpServers' must be an object")

    results: List[McpServerCheckResult] = []
    changed = False

    for name, server in servers.items():
        if not isinstance(server, dict):
            results.append(McpServerCheckResult(name=name, status="error", reason="server definition must be an object"))
            if auto_disable_failed and servers.get(name, {}).get("disabled") is not True:
                servers[name] = {"disabled": True}
                changed = True
            continue

        result = _check_server(name, server, probe_startup=probe_startup, probe_timeout_s=probe_timeout_s)
        results.append(result)

        if auto_disable_failed and result.status == "error":
            if server.get("disabled") is not True:
                server["disabled"] = True
                changed = True

    if write and changed:
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
            f.write("\n")

    return {
        "config_path": config_path,
        "changed": changed,
        "servers": [
            {"name": r.name, "status": r.status, "reason": r.reason}
            for r in sorted(results, key=lambda r: r.name)
        ],
    }


def _format_human(result: Dict[str, Any]) -> str:
    lines = [f"Config: {result.get('config_path')}"]
    for server in result.get("servers", []):
        name = server.get("name")
        status = server.get("status")
        reason = server.get("reason") or ""
        lines.append(f"- {name}: {status} {('- ' + reason) if reason else ''}".rstrip())
    if result.get("changed"):
        lines.append("Config would change (or was changed) due to auto-disable.")
    return "\n".join(lines)


def main(argv: Optional[List[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="Preflight Antigravity MCP config and optionally disable failing servers.")
    parser.add_argument("--config", default=DEFAULT_ANTIGRAVITY_MCP_CONFIG_PATH, help="Path to Antigravity mcp_config.json")
    parser.add_argument("--auto-disable-failed", action="store_true", help="Mark failing servers as disabled")
    parser.add_argument("--write", action="store_true", help="Write changes back to the config file")
    parser.add_argument("--no-probe-startup", action="store_false", dest="probe_startup", help="Skip starting processes during preflight")
    parser.add_argument("--probe-timeout-s", type=float, default=1.5, help="Startup probe timeout in seconds")
    parser.add_argument("--json", action="store_true", help="Output JSON")
    parser.set_defaults(probe_startup=True)
    args = parser.parse_args(argv)

    result = preflight_mcp_config(
        args.config,
        auto_disable_failed=args.auto_disable_failed,
        write=args.write,
        probe_startup=args.probe_startup,
        probe_timeout_s=args.probe_timeout_s,
    )

    if args.json:
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print(_format_human(result))

    has_errors = any(s.get("status") == "error" for s in result.get("servers", []))
    return 1 if has_errors else 0


if __name__ == "__main__":
    raise SystemExit(main())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/observer.py
# ========================================================
from __future__ import annotations

import logging
from typing import Any, Callable, Dict, List


class _ObserverBus:
    """
    Central observability bus.

    The underlying bus remains string-keyed (`event_type` -> listeners) so it can
    support both "raw" emits and structured Event objects.
    """

    def __init__(self) -> None:
        self._listeners: Dict[str, List[Callable[[Any], None]]] = {}

    def subscribe(self, event_type: str, callback: Callable[[Any], None]) -> None:
        self._listeners.setdefault(event_type, []).append(callback)

    def emit(self, event_type: str, payload: Any) -> None:
        for callback in self._listeners.get(event_type, []):
            try:
                callback(payload)
            except Exception:
                logging.exception("Observer callback error")


def _coerce_event_type(event: Any) -> str:
    event_type = getattr(event, "event_type", None)
    if event_type is None:
        return "UNKNOWN"
    if hasattr(event_type, "value"):
        return str(event_type.value)
    return str(event_type)


# Global instance for lightweight usage and backwards-compatibility.
global_observer = _ObserverBus()


class Observer:
    """
    Public facade used by the rest of the codebase.

    Supports:
    - `Observer.subscribe("ACTION_START", cb)`
    - `Observer.emit(Event(...))`
    - `Observer.emit("ACTION_START", payload)` (legacy)
    """

    @staticmethod
    def subscribe(event_type: str, callback: Callable[[Any], None]) -> None:
        global_observer.subscribe(event_type, callback)

    @staticmethod
    def emit(*args: Any) -> None:
        if len(args) == 1:
            event = args[0]
            global_observer.emit(_coerce_event_type(event), event)
            return
        if len(args) == 2:
            event_type, payload = args
            global_observer.emit(str(event_type), payload)
            return
        raise TypeError("Observer.emit expects (event) or (event_type, payload)")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/orion
# ========================================================
import sys; import os; sys.path.append(os.getcwd()); from scripts.runtime.kernel import OrionRuntime; import asyncio; asyncio.run(OrionRuntime().start())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/static_analyzer.py
# ========================================================
import ast
import os
import networkx as nx
from typing import List, Dict, Set, Any

class DependencyAnalyzer:
    """
    Static Analysis Engine using AST and NetworkX.
    Builds a dependency graph of the codebase to support Impact Analysis.
    """
    def __init__(self, root_dir: str):
        self.root_dir = os.path.abspath(root_dir)
        self.graph = nx.DiGraph()
        self.file_map = {} # Map module name to file path

    def build_graph(self):
        """Scans the codebase and builds the dependency graph."""
        self.graph.clear()
        self.file_map.clear()
        
        # 1. First pass: Map all files and modules
        for root, _, files in os.walk(self.root_dir):
            if ".venv" in root or "__pycache__" in root or ".git" in root:
                continue
            for file in files:
                if file.endswith(".py"):
                    file_path = os.path.join(root, file)
                    module_name = self._get_module_name(file_path)
                    self.file_map[module_name] = file_path
                    self.graph.add_node(file_path, type="file", module=module_name)

        # 2. Second pass: Parse imports and add edges
        for file_path in self.graph.nodes():
            try:
                self._analyze_file(file_path)
            except Exception as e:
                print(f"⚠️ Error analyzing {file_path}: {e}")

    def _get_module_name(self, file_path: str) -> str:
        """Converts file path to dotted module name."""
        rel_path = os.path.relpath(file_path, self.root_dir)
        return rel_path.replace(".py", "").replace(os.sep, ".")

    def _analyze_file(self, file_path: str):
        """Parses a file and extracts imports."""
        with open(file_path, "r") as f:
            try:
                tree = ast.parse(f.read(), filename=file_path)
            except SyntaxError:
                return

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    self._add_dependency(file_path, alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    self._add_dependency(file_path, node.module)

    def _add_dependency(self, source_file: str, target_module: str):
        """Adds a directed edge from source_file to the file defining target_module."""
        # Resolve target_module to file path
        # 1. Exact match
        if target_module in self.file_map:
            target_file = self.file_map[target_module]
            self.graph.add_edge(source_file, target_file)
            return

        # 2. Package match (e.g., scripts.ontology -> scripts/ontology.py)
        # Try to find the longest matching prefix in file_map
        best_match = None
        for mod_name, path in self.file_map.items():
            if target_module == mod_name or target_module.startswith(mod_name + "."):
                 # Prefer exact or closer match
                 if best_match is None or len(mod_name) > len(best_match):
                     best_match = mod_name
        
        if best_match:
            self.graph.add_edge(source_file, self.file_map[best_match])

    def get_impact_set(self, changed_file: str) -> List[str]:
        """
        Returns a list of files that depend on the changed_file (Reverse Dependency).
        If A imports B, and B changes, A is impacted.
        Graph edge: A -> B (A depends on B).
        Impact: Predecessors of B.
        """
        abs_path = os.path.abspath(changed_file)
        if abs_path not in self.graph:
            return []
        
        # Find all files that depend on this file (Ancestors in dependency graph)
        # Since Edge is Source -> Target (Importing -> Imported),
        # We need to find nodes that have an edge TO this node.
        # networkx.ancestors returns all nodes having a path to the target.
        impacted = nx.ancestors(self.graph, abs_path)
        return list(impacted)

    def get_dependencies(self, file_path: str) -> List[str]:
        """Returns a list of files that the given file depends on."""
        abs_path = os.path.abspath(file_path)
        if abs_path not in self.graph:
            return []
        return list(nx.descendants(self.graph, abs_path))

if __name__ == "__main__":
    # Self-Test
    analyzer = DependencyAnalyzer(".")
    analyzer.build_graph()
    print(f"Graph Nodes: {len(analyzer.graph.nodes)}")
    print(f"Graph Edges: {len(analyzer.graph.edges)}")
    
    # Check impact of ontology.py
    ontology_path = os.path.abspath("scripts/ontology.py")
    if ontology_path in analyzer.graph:
        impact = analyzer.get_impact_set(ontology_path)
        print(f"\nImpact of changing scripts/ontology.py ({len(impact)} files):")
        for f in impact:
            print(f" - {os.path.relpath(f)}")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/verify_metrics_quick.py
# ========================================================

import asyncio
import logging
from datetime import datetime, timedelta
from scripts.ontology.storage import ProposalRepository, initialize_database, Database
from scripts.ontology.objects.proposal import Proposal, ProposalStatus

async def test_metrics():
    logging.basicConfig(level=logging.INFO)
    db = await initialize_database()
    repo = ProposalRepository(db)
    
    # Clean DB mainly for metrics test
    # await db.execute("DELETE FROM proposals")
    
    # Create an approved proposal with review time
    p1 = Proposal(action_type="test_metrics", payload={}, created_by="tester")
    p1.submit()
    await repo.save(p1)
    
    # Approve it
    # Manually tweaking timestamps to simulate time passing for metrics
    # This is hard to do cleanly without raw SQL, so we rely on the fact that existing tests passed basic CRUD.
    # We will just call get_metrics and ensure it doesn't crash handling NULLs or Empty sets.
    
    metrics = await repo.get_metrics()
    print(f"Metrics: {metrics}")
    
    assert "total_count" in metrics
    assert "status_counts" in metrics
    assert "avg_approval_time_seconds" in metrics

if __name__ == "__main__":
    asyncio.run(test_metrics())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/lib/__init__.py
# ========================================================


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/lib/fpgrowth.py
# ========================================================
import collections
from typing import List, Set, Dict, Any, Tuple, Generator

class FPNode:
    """
    Memory-optimized Node for FP-Tree using __slots__.
    """
    __slots__ = ['item', 'count', 'parent', 'children', 'link']
    
    def __init__(self, item, parent=None):
        self.item = item
        self.count = 1
        self.parent = parent
        self.children = {}  # Dict mapping item -> FPNode
        self.link = None    # Pointer to next node with same item

    def increment(self, count=1):
        self.count += count

class FPTree:
    """
    Pure Python FP-Growth Implementation.
    """
    def __init__(self, transactions: List[List[str]], min_sup: int):
        self.min_sup = min_sup
        self.root = FPNode(None)
        # Header Table: item -> head_node of linked list
        self.header_table: Dict[str, FPNode] = {}
        # Count cache for sorting
        self.header_counts: Dict[str, int] = {} 
        
        # 1. Count Frequencies
        # Use simple dictionary for counting
        counts = collections.defaultdict(int)
        for trans in transactions:
            for item in trans:
                counts[item] += 1
                
        # 2. Filter Frequent Items
        # intersection of keys
        self.frequent_items = set(k for k, v in counts.items() if v >= min_sup)
        
        # Cache counts for frequent items only (needed for sorting)
        self.header_counts = {k: v for k, v in counts.items() if k in self.frequent_items}
        
        # 3. Build Tree
        for trans in transactions:
            self.add_transaction(trans)

    def add_transaction(self, transaction: List[str]):
        """
        Inserts a transaction into the tree.
        Items are sorted by global frequency (descending).
        """
        # Filter and Sort
        local_items = [x for x in transaction if x in self.frequent_items]
        # Sort key: (-count, item) -> Most frequent first, then alphabetical for stability
        local_items.sort(key=lambda x: (-self.header_counts[x], x))
        
        if local_items:
            self._insert_tree(local_items, self.root)

    def _insert_tree(self, items: List[str], node: FPNode):
        first = items[0]
        child = node.children.get(first)
        
        if child:
            child.increment()
        else:
            child = FPNode(first, node)
            node.children[first] = child
            self._update_header(first, child)
            
        if len(items) > 1:
            self._insert_tree(items[1:], child)

    def _update_header(self, item: str, target_node: FPNode):
        if item not in self.header_table:
            self.header_table[item] = target_node
        else:
            # Append to end of linked list (O(N) unless we cache tail, but list is usually short)
            # Optimization: Always traverse to end? Or keep tail pointer?
            # Standard impl traverses.
            current = self.header_table[item]
            while current.link:
                current = current.link
            current.link = target_node

    def mine(self) -> Generator[Tuple[Set[str], int], None, None]:
        """
        Public mining entry point.
        Yields (frequent_pattern_set, support_count).
        """
        # Start mining from least frequent item to most frequent
        # Why? Because we build Conditional Pattern Base "upwards"
        sorted_items = sorted(
            self.header_table.keys(), 
            key=lambda k: self.header_counts[k]
            # No reverse=True -> ascending order (least frequent first)
        )
        
        for item in sorted_items:
            yield from self._mine_recursive(set(), item)

    def _mine_recursive(self, prefix: Set[str], item: str) -> Generator[Tuple[Set[str], int], None, None]:
        # Form new pattern
        new_pattern = prefix.copy()
        new_pattern.add(item)
        
        # Structure support is the sum of counts of nodes in the header list for this item
        support = 0
        current = self.header_table[item]
        while current:
            support += current.count
            current = current.link
            
        yield (new_pattern, support)
        
        # Build Conditional Pattern Base
        conditional_transactions = []
        current = self.header_table[item]
        
        while current:
            # Trace path to root
            path = []
            parent = current.parent
            while parent and parent.item is not None:
                path.append(parent.item)
                parent = parent.parent
            
            # The path occurred 'current.count' times
            if path:
                # Add path 'count' times? Or Weighted?
                # FP-Growth optimization: Pass 'counts' to constructor
                # For simplicity here taking naive unrolling, but optimized is:
                # Implement FPTree to accept weighted transactions.
                # Assuming unweighted for this implementation step, effectively:
                for _ in range(current.count):
                    conditional_transactions.append(path)
            
            current = current.link
            
        # Recursive Step
        # Build conditional tree
        if conditional_transactions:
            # Recursion is safe due to log depth limit
            cond_tree = FPTree(conditional_transactions, self.min_sup)
            if cond_tree.header_table:
                for next_item in sorted(cond_tree.header_table.keys(), key=lambda k: cond_tree.header_counts[k]):
                    yield from cond_tree._mine_recursive(new_pattern, next_item)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/lib/preprocessing.py
# ========================================================
import hashlib
import json
import re
from typing import Dict, Any, Generator, Tuple, List, Set

# --- Regex Tokenizer ---
# Captures words, identifiers with dots/dashes, IP addresses
TOKEN_PATTERN = re.compile(r'(?u)\b\w[\w\.\-\:]*\b')

def tokenize(text: str) -> List[str]:
    """
    Extracts tokens from text, filtering basic punctuation.
    Lowercases everything.
    """
    if not text:
        return []
    return TOKEN_PATTERN.findall(text.lower())

# --- JSON Flattening ---

def flatten_json(nested_json: Dict[str, Any], parent_key: str = '', sep: str = '.') -> Dict[str, Any]:
    """
    Recursively flattens a nested dictionary.
    Returns a unified flat dict.
    
    Example:
    {'a': 1, 'b': {'c': 2}} -> {'a': 1, 'b.c': 2}
    """
    # Note: Using MutableMapping check is robust but 'dict' is fine for JSON
    items: List[Tuple[str, Any]] = []
    
    for k, v in nested_json.items():
        # Intern keys to save memory (String Interning)
        new_key = sys.intern(f"{parent_key}{sep}{k}") if parent_key else sys.intern(k)
        
        if isinstance(v, dict):
            items.extend(flatten_json(v, new_key, sep=sep).items())
        elif isinstance(v, list):
            for i, item in enumerate(v):
                list_key = sys.intern(f"{new_key}{sep}{i}")
                if isinstance(item, dict):
                    items.extend(flatten_json(item, list_key, sep=sep).items())
                else:
                    items.append((list_key, v)) # Correction: Logic for primitives in list
        else:
            items.append((new_key, v))
            
    return dict(items)

def flatten_json_generator(nested_json: Dict[str, Any], parent_key: str = '', sep: str = '.') -> Generator[Tuple[str, Any], None, None]:
    """
    Generator version of flattened items used for Streaming FP-Growth.
    """
    for k, v in nested_json.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        
        if isinstance(v, dict):
            yield from flatten_json_generator(v, new_key, sep)
        elif isinstance(v, list):
            for i, item in enumerate(v):
                list_key = f"{new_key}{sep}{i}"
                if isinstance(item, dict):
                    yield from flatten_json_generator(item, list_key, sep)
                else:
                    yield (list_key, item)
        else:
            yield (new_key, v)

# --- Canonicalization ---

def generate_event_signature(flat_log: Dict[str, Any]) -> str:
    """
    Generates a deterministic SHA-256 hash specific to the content.
    """
    # 1. Canonicalize: Sort keys
    canonical_str = json.dumps(flat_log, sort_keys=True)
    
    # 2. Encode
    encoded_str = canonical_str.encode('utf-8')
    
    # 3. Hash
    return hashlib.sha256(encoded_str).hexdigest()

import sys


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/lib/textrank.py
# ========================================================
import math
from typing import Dict, List, Set, Tuple

# --- Cosine Similarity ---

def cosine_similarity(vec1: Dict[str, int], vec2: Dict[str, int]) -> float:
    """
    Computes cosine similarity between two sparse vectors (dicts).
    """
    # 1. Intersect Keys: Only multiply non-zero dimensions
    common_words = set(vec1.keys()) & set(vec2.keys())
    
    if not common_words:
        return 0.0
    
    # 2. Dot Product
    dot_product = sum(vec1[word] * vec2[word] for word in common_words)
    
    # 3. Magnitudes
    mag1 = math.sqrt(sum(v**2 for v in vec1.values()))
    mag2 = math.sqrt(sum(v**2 for v in vec2.values()))
    
    if mag1 == 0 or mag2 == 0:
        return 0.0
        
    return dot_product / (mag1 * mag2)

def build_vector(tokens: List[str]) -> Dict[str, int]:
    """Converts token list to sparse frequency vector."""
    vec = {}
    for t in tokens:
        vec[t] = vec.get(t, 0) + 1
    return vec

# --- PageRank ---

def pagerank(graph: Dict[int, Dict[int, float]], damping: float = 0.85, epsilon: float = 1.0e-4, max_iter: int = 100) -> Dict[int, float]:
    """
    Computes PageRank for an undirected graph represented as dict of dicts.
    graph[i][j] = weight
    
    Returns: Dict[node_index, score]
    """
    nodes = list(graph.keys())
    if not nodes:
        return {}
        
    # Init scores
    scores = {n: 1.0 for n in nodes}
    
    # Pre-calculate out strength (sum of weights for each node)
    out_strength = {n: sum(graph[n].values()) for n in nodes}
    
    for _ in range(max_iter):
        new_scores = {}
        diff = 0.0
        
        for node in nodes:
            rank_sum = 0.0
            
            # For undirected semantic graph, neighbors are effectively incoming links
            # We iterate over neighbors of 'node'
            # Formula: sum( (weight_ji / Sum_weights_j) * Score_j )
            neighbors = graph.get(node, {})
            
            for neighbor, weight in neighbors.items():
                if out_strength[neighbor] == 0:
                    continue
                rank_sum += (weight / out_strength[neighbor]) * scores[neighbor]
            
            new_scores[node] = (1 - damping) + (damping * rank_sum)
            diff += abs(new_scores[node] - scores[node])
            
        scores = new_scores
        if diff < epsilon:
            break
            
    return scores

def extract_summary(unique_sentences: List[str], top_n: int = 1) -> str:
    """
    Main TextRank pipeline.
    Input: List of unique sentences/logs.
    Output: Most representative sentence.
    """
    from scripts.lib.preprocessing import tokenize
    
    n = len(unique_sentences)
    if n == 0: return ""
    if n == 1: return unique_sentences[0]
    
    # 1. Vectorize
    vectors = [build_vector(tokenize(s)) for s in unique_sentences]
    
    # 2. Build Graph (Similarity Matrix)
    # Graph: {node_idx: {neighbor_idx: similarity}}
    graph = {i: {} for i in range(n)}
    
    for i in range(n):
        for j in range(i + 1, n):
            sim = cosine_similarity(vectors[i], vectors[j])
            if sim > 0.1: # Pruning threshold
                graph[i][j] = sim
                graph[j][i] = sim
                
    # 3. Rank
    scores = pagerank(graph)
    
    # 4. Sort
    ranked_indices = sorted(scores.keys(), key=lambda k: scores[k], reverse=True)
    
    return unique_sentences[ranked_indices[0]] if ranked_indices else unique_sentences[0]


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/migration/migrate_memory.py
# ========================================================

import os
import json
import shutil
import glob
from datetime import datetime
from typing import Dict, Any

from scripts.ontology.manager import ObjectManager
from scripts.ontology.schemas.memory import OrionInsight, OrionPattern, InsightProvenance, InsightContent, PatternStructure

MEMORY_ROOT = "/home/palantir/.agent/memory/semantic"
ARCHIVE_ROOT = os.path.join(MEMORY_ROOT, "archived")

def parse_iso(ts: str) -> datetime:
    return datetime.fromisoformat(ts.replace("Z", "+00:00"))

def migrate_insight(data: Dict[str, Any]):
    return OrionInsight(
        id=data["id"],
        created_at=parse_iso(data["meta"]["created_at"]),
        updated_at=parse_iso(data["meta"]["updated_at"]),
        version=1, # Default to 1 or verify if exists?
        
        confidence_score=data["meta"].get("confidence_score", 1.0),
        decay_factor=data["meta"].get("decay_factor"),
        
        provenance=InsightProvenance(**data["provenance"]),
        content=InsightContent(**data["content"]),
        
        supports=data.get("relations", {}).get("supports", []),
        contradicts=data.get("relations", {}).get("contradicts", []),
        related_to=data.get("relations", {}).get("related_to", [])
    )

def migrate_pattern(data: Dict[str, Any]):
    return OrionPattern(
        id=data["id"],
        created_at=parse_iso(data["meta"]["created_at"]),
        updated_at=parse_iso(data["meta"]["updated_at"]),
        version=1,
        
        frequency_count=data["meta"].get("frequency_count", 0),
        success_rate=data["meta"].get("success_rate", 0.0),
        last_used=parse_iso(data["meta"]["last_used"]) if data["meta"].get("last_used") else None,
        
        structure=PatternStructure(**data["structure"]),
        code_snippet_ref=data.get("code_snippet_ref")
    )

def run_migration():
    print("=== STARTING MEMORY MIGRATION (Phase 4) ===")
    
    om = ObjectManager()
    om.register_type(OrionInsight)
    om.register_type(OrionPattern)
    
    # 1. Insights
    insight_files = glob.glob(os.path.join(MEMORY_ROOT, "insights", "**", "*.json"), recursive=True)
    print(f"[Info] Found {len(insight_files)} Insight files.")
    
    for fpath in insight_files:
        if "archived" in fpath: continue
        
        try:
            with open(fpath, 'r') as f:
                data = json.load(f)
            
            obj = migrate_insight(data)
            om.save(obj)
            print(f"[Success] Migrated Insight: {obj.id}")
            
            # Archive
            # dest_dir = os.path.dirname(fpath).replace(MEMORY_ROOT, ARCHIVE_ROOT)
            # os.makedirs(dest_dir, exist_ok=True)
            # shutil.move(fpath, os.path.join(dest_dir, os.path.basename(fpath)))
            
        except Exception as e:
            print(f"[Error] Failed to migrate {fpath}: {e}")

    # 2. Patterns
    pattern_files = glob.glob(os.path.join(MEMORY_ROOT, "patterns", "**", "*.json"), recursive=True)
    print(f"[Info] Found {len(pattern_files)} Pattern files.")
    
    for fpath in pattern_files:
        if "archived" in fpath: continue
        
        try:
            with open(fpath, 'r') as f:
                data = json.load(f)
            
            obj = migrate_pattern(data)
            om.save(obj)
            print(f"[Success] Migrated Pattern: {obj.id}")
            
            # Archive
            # dest_dir = os.path.dirname(fpath).replace(MEMORY_ROOT, ARCHIVE_ROOT)
            # os.makedirs(dest_dir, exist_ok=True)
            # shutil.move(fpath, os.path.join(dest_dir, os.path.basename(fpath)))
            
        except Exception as e:
            print(f"[Error] Failed to migrate {fpath}: {e}")

    print("=== MIGRATION COMPLETED ===")

if __name__ == "__main__":
    run_migration()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/relay/queue.py
# ========================================================
import sqlite3
import uuid
from typing import Optional, Dict

class RelayQueue:
    """
    Production-Ready SQLite Queue.
    Features: WAL Mode, 30s Timeout, RowFactory.
    """
    def __init__(self, db_path="relay.db"):
        self.db_path = db_path
        self._init_db()

    def _get_conn(self):
        conn = sqlite3.connect(self.db_path, timeout=30.0)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_db(self):
        with self._get_conn() as conn:
            # Enable WAL for concurrency
            conn.execute("PRAGMA journal_mode=WAL;")
            conn.execute("""
                CREATE TABLE IF NOT EXISTS relay_tasks (
                    id TEXT PRIMARY KEY,
                    prompt TEXT,
                    status TEXT DEFAULT 'pending',
                    response TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_status ON relay_tasks(status);")

    def enqueue(self, prompt: str) -> str:
        task_id = str(uuid.uuid4())
        with self._get_conn() as conn:
            conn.execute("INSERT INTO relay_tasks (id, prompt) VALUES (?, ?)", (task_id, prompt))
            # Auto-commit via context manager
        print(f"[RelayQueue] Enqueued task {task_id}")
        return task_id

    def dequeue(self) -> Optional[Dict]:
        """
        Atomic Dequeue: Find pending -> Mark processing.
        """
        with self._get_conn() as conn:
            # Simple lock strategy for now (SQLite single-writer handles this via timeout)
            cursor = conn.execute("SELECT id, prompt FROM relay_tasks WHERE status='pending' LIMIT 1")
            row = cursor.fetchone()
            if row:
                conn.execute("UPDATE relay_tasks SET status='processing' WHERE id=?", (row['id'],))
                return dict(row)
        return None

    def complete(self, task_id: str, response: str):
        with self._get_conn() as conn:
            conn.execute("UPDATE relay_tasks SET status='completed', response=? WHERE id=?", (response, task_id))
        print(f"[RelayQueue] Completed task {task_id}")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/tests/e2e.py
# ========================================================

import sys
from typing import List, Optional
from pydantic import Field
from datetime import datetime

from scripts.ontology.core import OrionObject
from scripts.ontology.manager import ObjectManager
from scripts.ontology.db import DB_PATH
from scripts.ontology.schemas.memory import OrionPattern, PatternStructure
from scripts.action.core import ActionDefinition, ActionContext, ActionRunner, UnitOfWork
from scripts.simulation.core import SimulationEngine

# --- 1. Define Domain Objects ---
class E2EServer(OrionObject):
    name: str
    server_type: str  # "Legacy" or "Modern"
    status: str = "Unstable"
    cache_cleared: bool = False

# --- 2. Define Actions ---
class ClearCacheAction(ActionDefinition):
    @classmethod
    def action_id(cls): return "server.clear_cache"
    
    def validate(self, ctx): return True
    
    def apply(self, ctx):
        server_id = ctx.parameters["server_id"]
        server = ctx.manager.get(E2EServer, server_id, session=ctx.session)
        server.cache_cleared = True
        ctx.manager.save(server, session=ctx.session)
        print(f"[Action] Cache Cleared for {server.name}")

class RestartServerAction(ActionDefinition):
    @classmethod
    def action_id(cls): return "server.restart"
    
    def validate(self, ctx): return True
    
    def apply(self, ctx):
        server_id = ctx.parameters["server_id"]
        server = ctx.manager.get(E2EServer, server_id, session=ctx.session)
        
        # Constraint: Legacy servers explode if cache not cleared
        if server.server_type == "Legacy" and not server.cache_cleared:
            raise RuntimeError(f"Constraint Violation: Legacy Server {server.name} requires cache clear before restart!")
            
        server.status = "Active"
        ctx.manager.save(server, session=ctx.session)
        print(f"[Action] Server {server.name} Restarted Successfully")

# --- 3. Test Logic ---
def run_e2e_test():
    print("=== STARTING ORION E2E VERIFICATION ===")
    
    om = ObjectManager()
    om.register_type(E2EServer)
    om.register_type(OrionPattern)
    
    # --- SETUP ---
    print("\n[Step 1] Bootstrapping Data...")
    
    # Create Server
    srv = E2EServer(id="SRV-E2E-001", name="Alpha-Node", server_type="Legacy")
    om.save(srv)
    print(f"Created Server: {srv.id} ({srv.server_type})")
    
    # Create Knowledge (Pattern)
    pat = OrionPattern(
        id="PAT-E2E-MEMLEAK",
        structure=PatternStructure(
            trigger="memory_leak detected on legacy systems",
            steps=["clear_cache", "restart_server"],
            anti_patterns=["direct_restart"]
        )
    )
    om.save(pat)
    print(f"Created Pattern: {pat.id} (Trigger: {pat.structure.trigger})")
    print("Data persisted to SQLite.")

    # --- MEMORY RECALL (FTS) ---
    print("\n[Step 2] Cognitive Search (FTS)...")
    # Simulate searching for "memory_leak"
    import sqlite3
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    # Primitive FTS query (LIKE for simplicity in this env, assuming no FTS5 virtual table setup yet)
    cur.execute("SELECT id FROM objects WHERE type='OrionPattern' AND fts_content LIKE '%memory_leak%'")
    rows = cur.fetchall()
    found_ids = [r[0] for r in rows]
    
    print(f"Search Query 'memory_leak' found: {found_ids}")
    assert "PAT-E2E-MEMLEAK" in found_ids, "FTS Failed to find the pattern!"
    
    recall_opt = om.get(OrionPattern, found_ids[0])
    recommended_steps = recall_opt.structure.steps
    print(f"Recalled Solution Steps: {recommended_steps}")

    # --- SIMULATION 1: NAIVE FAILURE ---
    print("\n[Step 3] Simulation A: Naive Restart (Expecting Failure)...")
    sim_engine = SimulationEngine(om)
    
    # Definition: Just Restart
    ctx_fail = ActionContext(job_id="job-fail", parameters={"server_id": srv.id})
    action_restart = RestartServerAction()
    
    # Run
    diff_fail = sim_engine.run_simulation([action_restart], [ctx_fail])
    
    # Assert
    print(f"Diff Result: {diff_fail}")
    assert len(diff_fail.updated) == 0, "Simulation A captured changes but should have failed/rolled back!"
    print("Simulation A Correctly Failed (Safe Rollback Confirmed).")

    # --- SIMULATION 2: INFORMED SUCCESS ---
    print("\n[Step 4] Simulation B: Semantic Plan (Clear -> Restart)...")
    
    ctx_success_1 = ActionContext(job_id="job-ok-1", parameters={"server_id": srv.id})
    ctx_success_2 = ActionContext(job_id="job-ok-2", parameters={"server_id": srv.id})
    
    action_clear = ClearCacheAction()
    
    # Run Chain
    diff_success = sim_engine.run_simulation(
        [action_clear, action_restart], 
        [ctx_success_1, ctx_success_2]
    )
    
    # Assert
    print(f"Diff Result: {len(diff_success.updated)} updates.")
    assert len(diff_success.updated) >= 1, "Simulation B should have updates"
    
    final_state_change = diff_success.updated[-1] # The last update to the server
    assert final_state_change['id'] == srv.id
    assert final_state_change['changes']['status'] == "Active"
    
    print("Simulation B Successful. Plan Validated.")

    # --- EXECUTION ---
    print("\n[Step 5] Execution in Real Reality...")
    
    # We use ActionRunner directly on Default Session (Reality)
    runner = ActionRunner(om, session=om.default_session)
    
    # 1. Clear Cache
    runner.execute(action_clear, ctx_success_1)
    
    # 2. Restart
    runner.execute(action_restart, ctx_success_2)
    
    # Verify Real Database
    om.default_session.expire_all()
    real_srv = om.get(E2EServer, srv.id)
    
    print(f"Final Real Server Status: {real_srv.status}")
    print(f"Final Real Server Cache: {real_srv.cache_cleared}")
    
    assert real_srv.status == "Active"
    assert real_srv.cache_cleared == True
    
    print("\n=== E2E TEST COMPLETED: SYSTEM FUNCTIONAL ===")

if __name__ == "__main__":
    try:
        run_e2e_test()
    except Exception as e:
        print(f"!!! CRITICAL FAILURE !!! {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/tests/test_oda_governance.py
# ========================================================

import asyncio
import sys
from dataclasses import dataclass
from typing import ClassVar, Type

# Add project root to path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.actions import ActionType, ActionRegistry, GovernanceEngine, register_action, ActionContext, EditOperation, ActionResult
from scripts.ontology.ontology_types import OntologyObject

# Mock Ontology Object
class MockObject(OntologyObject):
    pass

# output capture
results = []

# logic test
async def test_governance_engine():
    print("🧪 Test: ODA Governance Engine")
    
    # 1. Register a Safe Action
    @register_action
    class SafeAction(ActionType[MockObject]):
        api_name: ClassVar[str] = "test_safe_action"
        object_type: ClassVar[Type[OntologyObject]] = MockObject
        requires_proposal: ClassVar[bool] = False
        
        async def apply_edits(self, params, context):
            return None, []

    # 2. Register a Hazardous Action
    @register_action(requires_proposal=True)
    class HazardousAction(ActionType[MockObject]):
        api_name: ClassVar[str] = "test_hazardous_action"
        object_type: ClassVar[Type[OntologyObject]] = MockObject
        requires_proposal: ClassVar[bool] = True # Class attr backup
        
        async def apply_edits(self, params, context):
            return None, []

    # 3. Instantiate Engine
    # Note: register_action uses the global `action_registry` imported from actions.py
    # We need to make sure we are checking THAT registry
    from scripts.ontology.actions import action_registry as global_registry
    engine = GovernanceEngine(global_registry)

    # 4. Verify Policy
    policy_safe = engine.check_execution_policy("test_safe_action")
    print(f"   Action 'test_safe_action' -> Policy: {policy_safe}")
    assert policy_safe == "ALLOW_IMMEDIATE", "Safe action should be allowed immediately"

    policy_hzd = engine.check_execution_policy("test_hazardous_action")
    print(f"   Action 'test_hazardous_action' -> Policy: {policy_hzd}")
    assert policy_hzd == "REQUIRE_PROPOSAL", "Hazardous action should require proposal"

    policy_404 = engine.check_execution_policy("non_existent_action")
    print(f"   Action 'non_existent_action' -> Policy: {policy_404}")
    assert policy_404 == "DENY", "Unknown action should be denied"

    print("✅ Governance Engine Verified: Schema is driving Logic.")

if __name__ == "__main__":
    asyncio.run(test_governance_engine())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/tests/test_phase5_governance.py
# ========================================================

import sys
import time
from sqlalchemy import select
from scripts.ontology.manager import ObjectManager
from scripts.ontology.core import OrionObject
from scripts.ontology.schemas.governance import OrionActionLog
from scripts.ontology.schemas.memory import OrionInsight
from scripts.action.core import ActionDefinition, ActionRunner, ActionContext
from scripts.consolidation.miner import ConsolidationMiner
from scripts.ontology.db import objects_table

# --- MOCKS ---
class GovernanceTestServer(OrionObject):
    state: str = "OK"

class FragileAction(ActionDefinition):
    @classmethod
    def action_id(cls): return "test.fragile"
    
    def validate(self, ctx): return True
    
    def apply(self, ctx):
        obj = ctx.manager.get(GovernanceTestServer, ctx.parameters["id"], session=ctx.session)
        obj.state = "BROKEN" # State change attempt
        ctx.manager.save(obj, session=ctx.session)
        
        # EXPLODE
        raise RuntimeError("Planned Explosion")

def run_test():
    print("=== PHASE 5 GOVERNANCE & CONSOLIDATION TEST ===")
    
    om = ObjectManager()
    om.register_type(GovernanceTestServer)
    om.register_type(OrionActionLog)
    om.register_type(OrionInsight)
    
    # Setup Data
    srv = GovernanceTestServer(id="SRV-GOV-001")
    om.save(srv)
    print("Setup: Server Created.")
    
    runner = ActionRunner(om)
    unique_trace_id = f"job-gov-{int(time.time())}"
    ctx = ActionContext(job_id=unique_trace_id, parameters={"id": srv.id})
    
    # 1. Execute Fragile Action (Expect Failure)
    print("\n[Step 1] Executing Fragile Action...")
    try:
        runner.execute(FragileAction(), ctx)
    except RuntimeError:
        print("Caught Expected RuntimeError.")
        
    # 2. Verify Rollback (Reality)
    om.default_session.expire_all()
    srv_check = om.get(GovernanceTestServer, srv.id)
    assert srv_check.state == "OK", "Rollback failed! State is BROKEN."
    print("[PASS] UnitOfWork Rolled Back Business Data.")
    
    # 3. Verify Log Persistence (Audit)
    # Use raw SQL to find the log since ID is unknown
    session = om.default_session
    
    stmt = select(objects_table).where(objects_table.c.type == "OrionActionLog")
    raw_logs = session.execute(stmt).fetchall()
    
    found_log = None
    target_job_id = unique_trace_id
    
    # Filter for the specific trace_id to avoid matching old logs from previous runs
    for row in raw_logs:
        if row.data.get('action_type') == "test.fragile" and row.data.get('trace_id') == target_job_id:
            found_log = row
            break
            
    if found_log is None:
        print(f"[DEBUG] Available Logs: {[r.data.get('trace_id') for r in raw_logs]}")
            
    assert found_log is not None, f"Audit Log for {target_job_id} NOT found in DB!"
    data = found_log.data
    print(f"[DEBUG] Found Log Data: {data}")
    assert data['status'] == "FAILURE", f"Log status is {data['status']}"
    assert "Planned Explosion" in str(data.get('error')), f"Error msg mismatch: {data.get('error')}"
    print("[PASS] Audit Log Persisted despite Rollback.")

    # 4. Consolidation (Mining)
    print("\n[Step 2] Running Consolidation Miner...")
    # Trigger 2 more failures to hit threshold (default 2? or 3?)
    ctx2 = ActionContext(job_id="job-gov-2", parameters={"id": srv.id})
    try: runner.execute(FragileAction(), ctx2) 
    except: pass
    
    miner = ConsolidationMiner(om)
    miner.mine_failures()
    
    # Check for Insight
    stmt_insight = select(objects_table).where(objects_table.c.type == "OrionInsight")
    insights = session.execute(stmt_insight).fetchall()
    
    found_insight = False
    for row in insights:
        summary = row.data['content']['summary']
        if "test.fragile" in summary and "Planned Explosion" in summary:
            found_insight = True
            print(f"[PASS] Insight Generated: {summary}")
            break
            
    assert found_insight, "Miner failed to generate Insight!"
    print("\n=== PHASE 5 VERIFIED SUCCESSFULLY ===")

if __name__ == "__main__":
    run_test()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/llm/instructor_client.py
# ========================================================

"""
Orion ODA V3 - Safe Instructor Client
=====================================
Provides a robust LLM client using `instructor` linked to `tenacity` for resilience.

Features:
- **Structural Enforcement**: Uses Pydantic to force LLM outputs into `Plan` schema.
- **Self-Healing**: Automatically retries on validation errors (e.g. missing fields, wrong types).
- **JSON Repair**: Fallback hook for "Double-Escape" issues common in quantized models.
"""

from __future__ import annotations

import logging
from typing import Type, TypeVar, Any, Dict

import instructor
from openai import OpenAI
from pydantic import BaseModel, ValidationError
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

try:
    from json_repair import repair_json
except ImportError:
    repair_json = None

from scripts.ontology.plan import Plan

logger = logging.getLogger(__name__)

T = TypeVar("T", bound=BaseModel)

class InstructorClient:
    """
    Client for interacting with LLMs via Instructor for structured output.
    Supports Ollama and OpenAI-compatible endpoints.
    """
    
    def __init__(self, base_url: str = "http://localhost:11434/v1", api_key: str = "ollama"):
        self.base_url = base_url
        self.api_key = api_key
        
        # Patch standard OpenAI client with Instructor
        self.client = instructor.patch(
            OpenAI(base_url=base_url, api_key=api_key),
            mode=instructor.Mode.JSON
        )

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type(ValidationError)
    )
    def generate(
        self, 
        prompt: str, 
        response_model: Type[T], 
        model_name: str = "llama3.2"
    ) -> T:
        """
        Generate a structured response from the LLM.
        
        Args:
            prompt: The user prompt.
            response_model: Pydantic model class to validate against.
            model_name: LLM model name.
            
        Returns:
            Validated instance of response_model.
        """
        try:
            return self.client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                response_model=response_model,
                max_retries=2  # Internal Instructor retry for simple fixups
            )
        except ValidationError as e:
            logger.warning(f"Validation Failed (Attempting Retry): {e}")
            raise
        except Exception as e:
            # Handle JSON Parse issues explicitly if Instructor fails
            if "Expecting value" in str(e) or "Unterminated string" in str(e):
                 logger.error(f"JSON Parse Error: {e}. Attempting Repair strategy if implemented.")
                 # In future: manually fetch raw content -> repair_json -> model_validate
            raise

    def generate_plan(self, prompt: str, model_name: str = "llama3.2") -> Plan:
        """Specialized method for Plan generation."""
        return self.generate(prompt, Plan, model_name=model_name)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/llm/ollama_client.py
# ========================================================
"""
Orion ODA v3.0 - Hybrid LLM Router & Ollama Client
Intelligent routing between Local LLM and Relay Queue

This module implements the HybridRouter which decides whether to:
- Process locally (Ollama) for simple, low-risk tasks
- Route to Relay Queue for complex or critical tasks

Routing Decision Factors:
1. Critical Keywords: Certain words always trigger Relay (e.g., "delete", "deploy")
2. Complexity Score: Token count, sentence structure, technical terms
3. Explicit Markers: User can force routing with [LOCAL] or [RELAY] prefixes
"""

from __future__ import annotations

import asyncio
import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Literal, Optional, Set

import httpx
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


# =============================================================================
# CONFIGURATION
# =============================================================================

class RouterConfig(BaseModel):
    """
    Configuration for the HybridRouter.
    
    Can be loaded from YAML/JSON file or environment variables.
    """
    
    # Complexity thresholds
    word_threshold: int = Field(
        default=50,
        description="Word count threshold for complexity routing",
        ge=10,
        le=500
    )
    
    sentence_threshold: int = Field(
        default=5,
        description="Sentence count threshold for complexity routing",
        ge=1,
        le=50
    )
    
    # Critical keywords (always route to RELAY)
    critical_keywords: List[str] = Field(
        default_factory=lambda: [
            # Destructive operations
            "delete",
            "remove",
            "drop",
            "truncate",
            "destroy",
            "wipe",
            "purge",
            # Deployment operations
            "deploy",
            "release",
            "publish",
            "rollback",
            "migrate",
            # Infrastructure
            "production",
            "prod",
            "database",
            "server",
            "cluster",
            "kubernetes",
            "k8s",
            # Security
            "credential",
            "password",
            "secret",
            "token",
            "api_key",
            "apikey",
            # Financial
            "payment",
            "billing",
            "invoice",
            "refund",
        ],
        description="Keywords that always trigger RELAY routing"
    )
    
    # Technical terms (increase complexity score)
    technical_terms: List[str] = Field(
        default_factory=lambda: [
            "api",
            "endpoint",
            "microservice",
            "architecture",
            "integration",
            "authentication",
            "authorization",
            "encryption",
            "scalability",
            "redundancy",
        ],
        description="Technical terms that increase complexity score"
    )
    
    # Weights for complexity calculation
    word_weight: float = Field(default=1.0, ge=0.0, le=10.0)
    sentence_weight: float = Field(default=5.0, ge=0.0, le=20.0)
    technical_term_weight: float = Field(default=3.0, ge=0.0, le=10.0)
    question_weight: float = Field(default=2.0, ge=0.0, le=10.0)
    
    # Ollama settings
    ollama_base_url: str = Field(
        default="http://localhost:11434",
        description="Ollama API base URL"
    )
    ollama_model: str = Field(
        default="llama3.2",
        description="Default Ollama model"
    )
    ollama_timeout: float = Field(
        default=60.0,
        description="Ollama request timeout in seconds",
        ge=5.0,
        le=300.0
    )
    ollama_max_retries: int = Field(
        default=3,
        description="Max retries for Ollama requests",
        ge=0,
        le=10
    )
    
    @classmethod
    def from_file(cls, path: str | Path) -> "RouterConfig":
        """Load configuration from YAML or JSON file."""
        path = Path(path)
        
        if not path.exists():
            logger.warning(f"Config file not found: {path}, using defaults")
            return cls()
        
        content = path.read_text()
        
        if path.suffix in (".yaml", ".yml"):
            try:
                import yaml
                data = yaml.safe_load(content)
            except ImportError:
                logger.error("PyYAML not installed, falling back to defaults")
                return cls()
        elif path.suffix == ".json":
            data = json.loads(content)
        else:
            raise ValueError(f"Unsupported config format: {path.suffix}")
        
        return cls(**data)
    
    def to_file(self, path: str | Path) -> None:
        """Save configuration to JSON file."""
        path = Path(path)
        path.write_text(self.model_dump_json(indent=2))


# =============================================================================
# ROUTING DECISION
# =============================================================================

class RouteTarget(str, Enum):
    """Routing destination."""
    LOCAL = "LOCAL"    # Process with local Ollama
    RELAY = "RELAY"    # Queue for external processing


@dataclass
class RoutingDecision:
    """
    Detailed routing decision with audit trail.
    
    Includes the reasoning for the routing choice,
    useful for debugging and tuning.
    """
    target: RouteTarget
    reason: str
    complexity_score: float
    triggered_keywords: List[str] = field(default_factory=list)
    metrics: Dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.utcnow)
    
    @property
    def is_local(self) -> bool:
        return self.target == RouteTarget.LOCAL
    
    @property
    def is_relay(self) -> bool:
        return self.target == RouteTarget.RELAY
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "target": self.target.value,
            "reason": self.reason,
            "complexity_score": self.complexity_score,
            "triggered_keywords": self.triggered_keywords,
            "metrics": self.metrics,
            "timestamp": self.timestamp.isoformat(),
        }


# =============================================================================
# HYBRID ROUTER
# =============================================================================

class HybridRouter:
    """
    Intelligent router for LLM task distribution.
    
    Decides whether to process a task locally (Ollama) or
    route it to the Relay Queue for external processing.
    
    Routing Logic:
    1. Check for explicit markers ([LOCAL], [RELAY])
    2. Check for critical keywords
    3. Calculate complexity score
    4. Compare against thresholds
    
    Usage:
        ```python
        config = RouterConfig.from_file("config/router.yaml")
        router = HybridRouter(config)
        
        decision = router.route("Delete all user data from production")
        # decision.target == RouteTarget.RELAY
        # decision.triggered_keywords == ["delete", "production"]
        
        decision = router.route("What is 2 + 2?")
        # decision.target == RouteTarget.LOCAL
        ```
    """
    
    # Explicit routing markers
    LOCAL_MARKER = "[LOCAL]"
    RELAY_MARKER = "[RELAY]"
    
    def __init__(self, config: RouterConfig | None = None):
        self.config = config or RouterConfig()
        self._keyword_pattern = self._build_keyword_pattern()
    
    def _build_keyword_pattern(self) -> re.Pattern:
        """Build regex pattern for critical keyword detection."""
        # Sort by length descending to match longer keywords first
        keywords = sorted(self.config.critical_keywords, key=len, reverse=True)
        # Escape special regex characters and join with OR
        escaped = [re.escape(kw) for kw in keywords]
        pattern = r"\b(" + "|".join(escaped) + r")\b"
        return re.compile(pattern, re.IGNORECASE)
    
    def _find_critical_keywords(self, text: str) -> List[str]:
        """Find all critical keywords in the text."""
        matches = self._keyword_pattern.findall(text)
        return list(set(match.lower() for match in matches))
    
    def _count_technical_terms(self, text: str) -> int:
        """Count occurrences of technical terms."""
        text_lower = text.lower()
        count = 0
        for term in self.config.technical_terms:
            count += text_lower.count(term.lower())
        return count
    
    def _calculate_complexity(self, text: str) -> tuple[float, Dict[str, Any]]:
        """
        Calculate complexity score for a task description.
        
        Returns:
            Tuple of (score, metrics_dict)
        """
        # Basic metrics
        words = text.split()
        word_count = len(words)
        
        # Sentence count (rough heuristic)
        sentences = re.split(r"[.!?]+", text)
        sentence_count = len([s for s in sentences if s.strip()])
        
        # Technical terms
        technical_count = self._count_technical_terms(text)
        
        # Questions (often indicate complex queries)
        question_count = text.count("?")
        
        # Calculate weighted score
        score = (
            word_count * self.config.word_weight +
            sentence_count * self.config.sentence_weight +
            technical_count * self.config.technical_term_weight +
            question_count * self.config.question_weight
        )
        
        metrics = {
            "word_count": word_count,
            "sentence_count": sentence_count,
            "technical_count": technical_count,
            "question_count": question_count,
            "threshold": self._get_complexity_threshold(),
        }
        
        return score, metrics
    
    def _get_complexity_threshold(self) -> float:
        """Calculate the complexity threshold from config."""
        return (
            self.config.word_threshold * self.config.word_weight +
            self.config.sentence_threshold * self.config.sentence_weight
        )
    
    def route(self, task_description: str) -> RoutingDecision:
        """
        Determine routing for a task.
        
        Args:
            task_description: The task/prompt to be processed
        
        Returns:
            RoutingDecision with target, reason, and metrics
        """
        text = task_description.strip()
        
        # 1. Check explicit markers
        if text.upper().startswith(self.LOCAL_MARKER):
            return RoutingDecision(
                target=RouteTarget.LOCAL,
                reason="Explicit LOCAL marker",
                complexity_score=0,
                metrics={"explicit_marker": True}
            )
        
        if text.upper().startswith(self.RELAY_MARKER):
            return RoutingDecision(
                target=RouteTarget.RELAY,
                reason="Explicit RELAY marker",
                complexity_score=0,
                metrics={"explicit_marker": True}
            )
        
        # 2. Check critical keywords
        triggered_keywords = self._find_critical_keywords(text)
        if triggered_keywords:
            return RoutingDecision(
                target=RouteTarget.RELAY,
                reason=f"Critical keywords detected: {triggered_keywords}",
                complexity_score=float("inf"),  # Infinite = always RELAY
                triggered_keywords=triggered_keywords,
                metrics={"keyword_triggered": True}
            )
        
        # 3. Calculate complexity
        score, metrics = self._calculate_complexity(text)
        threshold = self._get_complexity_threshold()
        
        if score >= threshold:
            return RoutingDecision(
                target=RouteTarget.RELAY,
                reason=f"Complexity score ({score:.1f}) exceeds threshold ({threshold:.1f})",
                complexity_score=score,
                metrics=metrics
            )
        
        return RoutingDecision(
            target=RouteTarget.LOCAL,
            reason=f"Complexity score ({score:.1f}) below threshold ({threshold:.1f})",
            complexity_score=score,
            metrics=metrics
        )
    
    def route_simple(self, task_description: str) -> Literal["LOCAL", "RELAY"]:
        """
        Simple routing that returns just the target string.
        
        For backward compatibility with existing code.
        """
        return self.route(task_description).target.value


# =============================================================================
# OLLAMA CLIENT
# =============================================================================

@dataclass
class OllamaResponse:
    """Response from Ollama API."""
    content: str
    model: str
    done: bool
    total_duration: Optional[int] = None  # nanoseconds
    eval_count: Optional[int] = None  # tokens generated
    
    @property
    def duration_seconds(self) -> float:
        """Get duration in seconds."""
        if self.total_duration:
            return self.total_duration / 1_000_000_000
        return 0.0


class OllamaClient:
    """
    Async client for Ollama API.
    
    Handles connection, retries, and response parsing.
    
    Usage:
        ```python
        config = RouterConfig()
        client = OllamaClient(config)
        
        response = await client.generate("What is 2 + 2?")
        print(response.content)  # "4"
        ```
    """
    
    def __init__(self, config: RouterConfig | None = None):
        self.config = config or RouterConfig()
        self._client: Optional[httpx.AsyncClient] = None
    
    async def _get_client(self) -> httpx.AsyncClient:
        """Get or create HTTP client."""
        if self._client is None or self._client.is_closed:
            self._client = httpx.AsyncClient(
                base_url=self.config.ollama_base_url,
                timeout=self.config.ollama_timeout,
            )
        return self._client
    
    async def close(self) -> None:
        """Close the HTTP client."""
        if self._client and not self._client.is_closed:
            await self._client.aclose()
            self._client = None
    
    async def generate(
        self,
        prompt: str,
        model: str | None = None,
        system: str | None = None,
        temperature: float = 0.7,
        max_tokens: int = 2048,
    ) -> OllamaResponse:
        """
        Generate a completion from Ollama.
        
        Args:
            prompt: The user prompt
            model: Model to use (defaults to config)
            system: Optional system prompt
            temperature: Sampling temperature
            max_tokens: Maximum tokens to generate
        
        Returns:
            OllamaResponse with generated content
        
        Raises:
            httpx.HTTPError: On connection/request errors after retries
        """
        client = await self._get_client()
        model = model or self.config.ollama_model
        
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": temperature,
                "num_predict": max_tokens,
            }
        }
        
        if system:
            payload["system"] = system
        
        last_error: Optional[Exception] = None
        
        for attempt in range(self.config.ollama_max_retries + 1):
            try:
                response = await client.post("/api/generate", json=payload)
                response.raise_for_status()
                data = response.json()
                
                return OllamaResponse(
                    content=data.get("response", ""),
                    model=data.get("model", model),
                    done=data.get("done", True),
                    total_duration=data.get("total_duration"),
                    eval_count=data.get("eval_count"),
                )
            
            except httpx.HTTPError as e:
                last_error = e
                logger.warning(
                    f"Ollama request failed (attempt {attempt + 1}/"
                    f"{self.config.ollama_max_retries + 1}): {e}"
                )
                
                if attempt < self.config.ollama_max_retries:
                    await asyncio.sleep(2 ** attempt)  # Exponential backoff
        
        raise last_error or RuntimeError("Ollama request failed")
    
    async def health_check(self) -> bool:
        """Check if Ollama is available."""
        try:
            client = await self._get_client()
            response = await client.get("/api/tags")
            return response.status_code == 200
        except Exception:
            return False
    
    async def list_models(self) -> List[str]:
        """List available models."""
        try:
            client = await self._get_client()
            response = await client.get("/api/tags")
            response.raise_for_status()
            data = response.json()
            return [m["name"] for m in data.get("models", [])]
        except Exception as e:
            logger.error(f"Failed to list models: {e}")
            return []


# =============================================================================
# UNIFIED INTERFACE
# =============================================================================

class HybridLLMService:
    """
    Unified service combining Router and Ollama Client.
    
    Provides a single interface for LLM operations with
    automatic routing decisions.
    
    Usage:
        ```python
        service = HybridLLMService()
        
        # Simple query - processed locally
        result = await service.process("What is 2 + 2?")
        # result.routing.target == LOCAL
        # result.response.content == "4"
        
        # Complex query - routed to relay
        result = await service.process("Deploy the checkout service to production")
        # result.routing.target == RELAY
        # result.queued == True
        ```
    """
    
    def __init__(self, config: RouterConfig | None = None):
        self.config = config or RouterConfig()
        self.router = HybridRouter(self.config)
        self.ollama = OllamaClient(self.config)
    
    async def close(self) -> None:
        """Close all connections."""
        await self.ollama.close()
    
    async def process(
        self,
        prompt: str,
        force_local: bool = False,
        force_relay: bool = False,
    ) -> Dict[str, Any]:
        """
        Process a prompt with automatic routing.
        
        Args:
            prompt: The prompt to process
            force_local: Force local processing (skip routing)
            force_relay: Force relay routing (skip routing)
        
        Returns:
            Dict with routing decision and response/queue status
        """
        # Determine routing
        if force_local:
            decision = RoutingDecision(
                target=RouteTarget.LOCAL,
                reason="Forced local processing",
                complexity_score=0,
            )
        elif force_relay:
            decision = RoutingDecision(
                target=RouteTarget.RELAY,
                reason="Forced relay routing",
                complexity_score=0,
            )
        else:
            decision = self.router.route(prompt)
        
        result = {
            "routing": decision.to_dict(),
            "prompt": prompt,
        }
        
        if decision.is_local:
            # Process locally with Ollama
            try:
                response = await self.ollama.generate(prompt)
                result["response"] = {
                    "content": response.content,
                    "model": response.model,
                    "duration_seconds": response.duration_seconds,
                }
                result["success"] = True
            except Exception as e:
                result["error"] = str(e)
                result["success"] = False
        else:
            # Queue for relay processing
            # This would integrate with RelayQueue
            result["queued"] = True
            result["queue_reason"] = decision.reason
            result["success"] = True
        
        return result


# =============================================================================
# CONFIGURATION FILE TEMPLATE
# =============================================================================

DEFAULT_CONFIG_TEMPLATE = """
# Orion ODA v3.0 - Router Configuration
# Save as: config/router.yaml or config/router.json

# Complexity Thresholds
word_threshold: 50
sentence_threshold: 5

# Critical Keywords (always route to RELAY)
critical_keywords:
  # Destructive operations
  - delete
  - remove
  - drop
  - truncate
  - destroy
  # Deployment operations
  - deploy
  - release
  - publish
  - rollback
  - migrate
  # Infrastructure
  - production
  - prod
  - database
  - server
  - kubernetes
  # Security
  - credential
  - password
  - secret
  - token
  - api_key

# Technical Terms (increase complexity score)
technical_terms:
  - api
  - endpoint
  - microservice
  - architecture
  - integration

# Complexity Weights
word_weight: 1.0
sentence_weight: 5.0
technical_term_weight: 3.0
question_weight: 2.0

# Ollama Settings
ollama_base_url: "http://localhost:11434"
ollama_model: "llama3.2"
ollama_timeout: 60.0
ollama_max_retries: 3
"""


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/api/dependencies.py
# ========================================================

"""
Orion ODA V3 - API Dependency Injection
======================================
Provides Database Sessions and Service instances to Routes.
"""

from typing import AsyncGenerator
from sqlalchemy.ext.asyncio import AsyncSession
from scripts.ontology.storage.database import get_database, Database
from scripts.ontology.storage.proposal_repository import ProposalRepository

async def get_db_session() -> AsyncGenerator[AsyncSession, None]:
    """Yields an active AsyncSession from the global pool."""
    db: Database = get_database() # Assumes initialized globally on startup
    async with db.transaction() as session:
        yield session

async def get_repository() -> AsyncGenerator[ProposalRepository, None]:
    """Provides a fresh Repository wrapper around the session."""
    # Note: ProposalRepository currently takes 'db' (manager) in its constructor.
    # Refactoring Step: Ideal repo takes 'session'.
    # For ODA V3 Prototype, we will implement a lightweight wrapper or usage pattern here.
    
    # Existing Pattern: Repo(db) -> internally uses `async with db.transaction()`
    # We will yield the Repo instance directly.
    db = get_database()
    yield ProposalRepository(db)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/api/dtos.py
# ========================================================

"""
Orion ODA V3 - API Data Transfer Objects (DTOs)
===============================================
Enforces strict separation between Internal Domain Entities (Proposal) 
and External Wire Format (JSON).

Security Principles:
1. **No Leakage**: Internal fields (audit logs, internal IDs) are stripped.
2. **Strict Validation**: Input data is heavily validated before touching Logic layers.
"""

from __future__ import annotations
from datetime import datetime
from typing import Dict, Any, Optional, List
from pydantic import BaseModel, Field

# =============================================================================
# REQUEST MODELS (INPUT)
# =============================================================================

class CreateProposalRequest(BaseModel):
    """
    User intent to potentially hazardous action.
    """
    action_type: str = Field(..., description="API Name of the action", min_length=3)
    payload: Dict[str, Any] = Field(default_factory=dict, description="Action arguments")
    priority: str = Field("medium", description="Execution priority")

class ReviewProposalRequest(BaseModel):
    """
    Governance decision payload.
    """
    reviewer_id: str = Field(..., description="ID of the reviewer")
    decision: str = Field(..., pattern="^(approve|reject)$")
    comment: Optional[str] = Field(None, description="Reasoning for decision")

# =============================================================================
# RESPONSE MODELS (OUTPUT)
# =============================================================================

class ProposalResponse(BaseModel):
    """
    Safe public representation of a Proposal.
    Excludes internal versioning details unless explicitly needed for optimistic locking UIs.
    """
    id: str
    action_type: str
    status: str
    priority: str
    created_at: datetime
    created_by: Optional[str] = None
    
    # We include payload for transparency, but sensitive fields inside payload 
    # should be masked by the domain logic if necessary.
    payload: Dict[str, Any]
    
    # Review status
    reviewed_by: Optional[str] = None
    reviewed_at: Optional[datetime] = None
    review_comment: Optional[str] = None
    
    # Execution status
    executed_at: Optional[datetime] = None
    execution_result: Optional[Dict[str, Any]] = None
    
    # Optimistic Locking Token (Exposed only for Edit/Approve workflows)
    version: int

    model_config = {
        "from_attributes": True  # Allows mapping from ORM objects
    }

class StandardErrorResponse(BaseModel):
    code: str
    message: str
    details: Optional[Dict[str, Any]] = None


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/api/main.py
# ========================================================

"""
Orion ODA V3 - API Application Entrypoint
========================================
Configures FastAPI with Security Middleware and Exception Handlers.

Security Features:
- HSTS (Strict-Transport-Security) enforced.
- CSP (Content-Security-Policy) default-src 'self'.
- Global Error Handling for valid JSON responses.
"""

from contextlib import asynccontextmanager
from fastapi import FastAPI, Request, status
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.base import BaseHTTPMiddleware

from scripts.ontology.storage.database import initialize_database
from scripts.api.routes import router as proposal_router

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: Init DB
    await initialize_database()
    yield
    # Shutdown logic if needed

app = FastAPI(
    title="Orion Orchestrator V3",
    description="ODA Enterprise API",
    version="3.0.0",
    lifespan=lifespan
)

# =============================================================================
# MIDDLEWARE
# =============================================================================

class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        # HSTS: Enforce HTTPS for 2 years
        response.headers["Strict-Transport-Security"] = "max-age=63072000; includeSubDomains"
        # CSP: Restrict content sources
        response.headers["Content-Security-Policy"] = "default-src 'self'"
        # Anti-Sniffing
        response.headers["X-Content-Type-Options"] = "nosniff"
        # Clickjacking Protection
        response.headers["X-Frame-Options"] = "DENY"
        return response

app.add_middleware(SecurityHeadersMiddleware)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"], # React Dev Server
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================================================================
# EXCEPTION HANDLERS
# =============================================================================

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "code": "INTERNAL_ERROR",
            "message": "An unexpected error occurred.",
            "details": str(exc) # Caution: Strip this in Prod
        }
    )

# =============================================================================
# ROUTES
# =============================================================================

app.include_router(proposal_router)

@app.get("/health")
async def health_check():
    return {"status": "ok", "system": "Orion ODA V3"}

# =============================================================================
# FRONTEND MOUNTING (Monolithic Mode)
# =============================================================================
import os
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse

FRONTEND_DIST = "/home/palantir/orion-orchestrator-v2/frontend/dist"

if os.path.exists(FRONTEND_DIST):
    # 1. Mount Static Assets (JS/CSS)
    # Check if 'static' folder exists inside dist, otherwise mount dist root if simple
    static_dir = os.path.join(FRONTEND_DIST, "static")
    if os.path.exists(static_dir):
        app.mount("/static", StaticFiles(directory=static_dir), name="static")

    # 2. SPA Catch-All
    # Must be the LAST route to avoid swallowing API calls
    @app.get("/{full_path:path}")
    async def serve_spa(full_path: str):
        # Allow API calls to pass through 404 if not found (don't serve HTML for /api)
        if full_path.startswith("api"):
            return JSONResponse({"code": "NOT_FOUND", "message": "API Endpoint not found"}, status_code=404)
            
        index_path = os.path.join(FRONTEND_DIST, "index.html")
        if os.path.exists(index_path):
            return FileResponse(index_path)
        return JSONResponse({"code": "Construction", "message": "Frontend building..."}, status_code=503)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/api/routes.py
# ========================================================

"""
Orion ODA V3 - API Routes
========================
Implements REST Endpoints mapping DTOs to Domain Logic.
"""

import logging
from typing import List

from fastapi import APIRouter, Depends, HTTPException, status
from scripts.api.dtos import (
    CreateProposalRequest, 
    ReviewProposalRequest, 
    ProposalResponse,
    StandardErrorResponse
)
from scripts.api.dependencies import get_repository
from scripts.ontology.storage.proposal_repository import (
    ProposalRepository, 
    ConcurrencyError, 
    ProposalNotFoundError
)
from scripts.ontology.objects.proposal import Proposal, ProposalStatus, ProposalPriority

logger = logging.getLogger("API")
router = APIRouter(prefix="/api/v1/proposals", tags=["Proposals"])

@router.post("", response_model=ProposalResponse, status_code=status.HTTP_201_CREATED)
async def create_proposal(
    req: CreateProposalRequest,
    repo: ProposalRepository = Depends(get_repository)
):
    """Submit a new Action Proposal."""
    # Convert DTO -> Domain
    proposal = Proposal(
        action_type=req.action_type,
        payload=req.payload,
        priority=ProposalPriority(req.priority),
        created_by="api_user" # Real auth would provide this
    )
    
    await repo.save(proposal, actor_id="api_user")
    logger.info(f"API: Proposal Created {proposal.id}")
    
    return proposal

@router.get("", response_model=List[ProposalResponse])
async def list_pending_proposals(
    repo: ProposalRepository = Depends(get_repository)
):
    """List all Proposals waiting for review."""
    proposals = await repo.find_pending()
    return proposals

@router.post("/{proposal_id}/review", response_model=StandardErrorResponse)
async def review_proposal(
    proposal_id: str,
    req: ReviewProposalRequest,
    repo: ProposalRepository = Depends(get_repository)
):
    """Approve or Reject a Proposal."""
    try:
        if req.decision == "approve":
            await repo.approve(proposal_id, req.reviewer_id, req.comment)
        elif req.decision == "reject":
            await repo.reject(proposal_id, req.reviewer_id, req.comment or "No reason provided")
            
        return StandardErrorResponse(
            code="SUCCESS", 
            message=f"Proposal {proposal_id} {req.decision}d successfully."
        )
        
    except ConcurrencyError as e:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=str(e)
        )
    except ProposalNotFoundError:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Proposal {proposal_id} not found."
        )


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/runtime/kernel.py
# ========================================================

import asyncio
import sys
import logging
from typing import Optional

# Ensure V3 path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.client import FoundryClient
# from scripts.llm.ollama_client import HybridRouter, OllamaClient  <-- REMOVED
from scripts.llm.instructor_client import InstructorClient       # <-- ADDED
from scripts.relay.queue import RelayQueue
from scripts.ontology.storage import ProposalRepository, initialize_database
from scripts.ontology.objects.proposal import Proposal, ProposalStatus
from scripts.ontology.actions import action_registry, GovernanceEngine
from scripts.ontology.plan import Plan

# Configure Logging
logging.basicConfig(level=logging.INFO, format="[%(name)s] %(message)s")
logger = logging.getLogger("Kernel")

class OrionRuntime:
    """
    The V3 Semantic OS Kernel (Generic Ontology Engine).
    
    Principles:
    1. Schema is Law: Uses `Plan` Pydantic model.
    2. Registry Supremacy: Actions via `ActionRegistry`.
    3. Metadata Governance: Policy via `GovernanceEngine`.
    4. Deterministic AI: Uses `instructor` for strict JSON outputs.
    """
    def __init__(self):
        # self.router = HybridRouter() # Deprecated in favor of direct Instructor for now
        self.llm = InstructorClient()
        self.relay = RelayQueue()
        self.governance = GovernanceEngine(action_registry)
        self.running = True
        self.repo: Optional[ProposalRepository] = None
        logger.info("Semantic OS Kernel Booting... (Mode: Enterprise Async)")

    async def start(self):
        # Initialize Persistence Layer
        db = await initialize_database()
        self.repo = ProposalRepository(db)
        
        logger.info("Online. Waiting for Semantic Signals...")
        
        while self.running:
            # 1. Check Relay Queue (Cognitive Tasks)
            task_payload = self.relay.dequeue()
            if task_payload:
                logger.info(f"Processing Relay Task: {task_payload.get('id', 'unknown')}")
                await self._process_task_cognitive(task_payload)
            
            # 2. Check Approved Proposals (Execution Worker)
            await self._process_approved_proposals()
                
            await asyncio.sleep(1)

    async def _process_approved_proposals(self):
        """Execute proposals that have been approved."""
        if not self.repo:
            return

        approved = await self.repo.find_by_status(ProposalStatus.APPROVED)
        if approved:
            logger.info(f"Found {len(approved)} approved proposals.")
            for p in approved:
                logger.info(f"🚀 Executing Proposal {p.id} ({p.action_type})...")
                try:
                    # 1. Lookup Action
                    action_cls = action_registry.get(p.action_type)
                    if not action_cls:
                        raise ValueError(f"Action type '{p.action_type}' not found in registry")
                        
                    # 2. Instantiate and Execute (Simulated for Prototype)
                    # Real: result = await action_cls().execute(p.payload)
                    
                    await self.repo.execute(
                        p.id, 
                        executor_id="kernel", 
                        result={"status": "success", "executed_via": "kernel_v3_async"}
                    )
                    logger.info(f"✅ Execution verified for {p.id}")
                except Exception as e:
                    logger.error(f"❌ Execution Failed for {p.id}: {e}")

    def shutdown(self):
        self.running = False
        logger.info("Kernel shutting down.")

    async def _process_task_cognitive(self, task_payload):
        """
        Cognitive Consumption: LLM Analysis -> Ontology Creation.
        Uses Instructor for reliable Plan parsing.
        """
        prompt = task_payload['prompt']
        logger.info(f"🧠 Thinking... (Analyzing: '{prompt[:30]}...')")
        
        try:
            # 1. Ask LLM for Plan using Instructor (Schema is Law)
            # No manual JSON parsing needed here. Instructor guarantees Pydantic logic.
            # Running in ThreadPool if call is blocking, or using async client if implemented under hood.
            # Assuming InstructorClient wraps async or we run in executor.
            
            # Note: The InstructorClient.generate_plan call is synchronous in the basic wrapper provided.
            # To avoid blocking the Kernel loop, we should run it in a thread.
            plan = await asyncio.to_thread(self.llm.generate_plan, prompt)
            
            logger.info(f"🐛 Plan Parsed Successfully: {len(plan.jobs)} jobs")

            # 2. Iterate and Dispatch
            for job in plan.jobs:
                logger.info(f"   Processing Job: {job.title} [{job.action_type}]")
                
                # A. Governance Check
                policy = self.governance.check_execution_policy(job.action_type)
                
                if policy == "DENY":
                    logger.error(f"   ⛔ Action '{job.action_type}' unknown or denied.")
                    continue
                
                if policy == "REQUIRE_PROPOSAL":
                    if self.repo:
                        proposal = Proposal(
                            action_type=job.action_type,
                            payload=job.params,
                            created_by='kernel_ai',
                            priority=job.priority
                        )
                        # save now uses Async ORM
                        await self.repo.save(proposal, actor_id="kernel_ai")
                        logger.info(f"   🛡️  Proposal Created: {proposal.id} (Requires Approval)")
                    else:
                        logger.error("   ❌ Repo unavailable, cannot create proposal.")
                        
                elif policy == "ALLOW_IMMEDIATE":
                    # Instant Execution
                    logger.info(f"   ⚡ Executing Immediately: {job.action_type}")
                    # For prototype, just log
                    logger.info("      (Execution Logic Placeholder)")

        except Exception as e:
            logger.error(f"❌ Cognitive Processing Failed: {e}")

if __name__ == "__main__":
    runtime = OrionRuntime()
    try:
        asyncio.run(runtime.start())
    except KeyboardInterrupt:
        runtime.shutdown()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/simulation/complex_mission.py
# ========================================================

import asyncio
import uuid
import sys
import os

# Setup Path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from scripts.runtime.kernel import OrionRuntime
from scripts.relay.queue import RelayQueue

async def run_complex_simulation():
    print("🚀 [Simulation] Starting 'Mission Critical' Complex Task Scenario...")
    
    # 1. Setup Infrastructure
    queue = RelayQueue()
    kernel = OrionRuntime()
    
    # 2. User User Ingests Complex Request
    complex_prompt = """
    OBJECTIVE: Deploy a new Checkout Microservice.
    REQUIREMENTS:
    1. Create a Python Service (FastAPI).
    2. Setup PostgreSQL Database.
    3. Configure Stripe Webhook.
    4. Deploy to Kubernetes (Production).
    """
    
    task_id = queue.enqueue(complex_prompt) # This triggers the "Router -> Relay" path conceptually
    print(f"📨 [User] Submitted Request ID: {task_id}")
    print(f"📝 Prompt: {complex_prompt.strip()[:50]}...")
    
    # 3. Start Kernel (in background logic) to process it
    # We will run the kernel for a few cycles to let it consume
    print("\n⚙️ [Kernel] Booting up to consume task...")
    
    # Run kernel process_loop once directly for test deterministic behavior
    # (Extracting logic from start() for granular control)
    item = queue.dequeue()
    if item:
        print(f"   [Kernel] Dequeued Item: {item['id']}")
        
        # --- THE TEST: Call the NEW Cognitive Method ---
        # accessing private method for verification
        await kernel._process_task_cognitive(item)
        
        queue.complete(item['id'], "Simulated Processing")
        print("   [Kernel] Task marked Complete.")
    else:
        print("   [Kernel] No task found!")

    print("\n🏁 [Simulation] Scenario Finished.")

if __name__ == "__main__":
    asyncio.run(run_complex_simulation())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/simulation/core.py
# ========================================================

from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from scripts.ontology.core import OrionObject
from scripts.ontology.manager import ObjectManager
from scripts.action.core import ActionDefinition, ActionContext, ActionRunner

class SimulationDiff(BaseModel):
    created: List[Dict[str, Any]] = Field(default_factory=list)
    updated: List[Dict[str, Any]] = Field(default_factory=list)
    deleted: List[str] = Field(default_factory=list)

class ScenarioFork:
    """
    The Phase 3 Sandbox.
    Wraps execution in a strict NESTED TRANSACTION (Savepoint) that is ALWAYS rolled back.
    """
    def __init__(self, manager: ObjectManager, parent_session: Optional[Session] = None):
        self.manager = manager
        self.session = parent_session or manager.create_session()
        self._owns_session = parent_session is None
        self.nested_tx = None
        self._diff = SimulationDiff()
        
    def __enter__(self):
        # 1. Begin Savepoint
        self.nested_tx = self.session.begin_nested()
            
        # 2. Hook into ObjectManager to capture Event Stream (Observer Pattern)
        # We need to capture what *would* happen.
        # SQLAlchemy's 'session.new', 'session.dirty' works, but only before flush/commit.
        # Since UnitOfWork COMMITS (releases savepoint), the session appears clean after execution!
        # Solution: We need to listen to ObjectManager events *during* execution.
        self.manager.subscribe(self._capture_event)
        
        return self.session

    def __exit__(self, exc_type, exc_val, exc_tb):
        # 3. Cleanup: Unsubscribe
        self.manager.unsubscribe(self._capture_event)
        
        # 4. ROLLBACK everything
        if self.nested_tx:
            print("[ScenarioFork] Sandbox Rolled Back (Clean State).")
            self.nested_tx.rollback()
        self.session.rollback()
        if self._owns_session:
            self.session.close()
        
    def _capture_event(self, event_type: str, result: Any):
        """
        Listener for ObjectManager events.
        """
        # print(f"[Debug] Captured Event: {event_type} - {result}")
        if event_type == "save":
            obj: OrionObject = result
            if obj.__class__.__name__ == "OrionActionLog":
                return
            # Naive Diff Logic
            # Note: We duplicate data here because the object might be rolled back.
            change_payload = {
                "id": obj.id,
                "type": obj.__class__.__name__,
                "changes": obj.get_changes()
            }
            # Avoid duplicates?
            self._diff.updated.append(change_payload)
            
        elif event_type == "delete":
            self._diff.deleted.append(str(result))
            
    def get_diff(self) -> SimulationDiff:
        return self._diff

class SimulationEngine:
    """
    Orchestrates the 'What-If'.
    """
    def __init__(self, manager: ObjectManager):
        self.manager = manager
        
    def run_simulation(self, actions: List[ActionDefinition], contexts: List[ActionContext]) -> SimulationDiff:
        print("[SimulationEngine] Starting Scenario Fork...")
        
        fork = ScenarioFork(self.manager)
        
        try:
            with fork as sandbox_session:
                # Configure Runner with Sandbox Session
                runner = ActionRunner(self.manager, session=sandbox_session)
                
                for action, ctx in zip(actions, contexts):
                    # Execute
                    # Note: ctx.session will be set by runner
                    try:
                        runner.execute(action, ctx)
                    except Exception as e:
                        print(f"[SimulationEngine] Action Failed: {e}")
                        # We continue? Or abort simulation?
                        # Usually abort.
                        break
            
            return fork.get_diff()
            
        except Exception as e:
            print(f"[SimulationEngine] Fork Crashed: {e}")
            return SimulationDiff()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/simulation/tests/test_simulation.py
# ========================================================

import sys
from scripts.ontology.core import OrionObject
from scripts.ontology.manager import ObjectManager
from scripts.simulation.core import SimulationEngine
from scripts.action.core import ActionDefinition, ActionContext

# --- Mocks ---
class SimTestServer(OrionObject):
    status: str = "Active"

class CrashServer(ActionDefinition):
    @classmethod
    def action_id(cls): return "test.crash_server"
    
    def validate(self, ctx): return True
    
    def apply(self, ctx):
        obj = ctx.manager.get(SimTestServer, ctx.parameters["id"], session=ctx.session)
        obj.status = "Crashed"
        ctx.manager.save(obj, session=ctx.session)

def run_test():
    print("=== STARTING PHASE 3 SIMULATION TEST ===")
    
    om = ObjectManager()
    om.register_type(SimTestServer)
    
    # 1. Reality Setup
    srv = SimTestServer(id="SIM-001", status="Active")
    om.save(srv)
    print(f"Reality State: {srv.status}")
    
    # 2. Run Simulation
    engine = SimulationEngine(om)
    ctx = ActionContext(job_id="job-sim-1", parameters={"id": srv.id})
    action = CrashServer()
    
    print("\n[Running Simulation...]")
    diff = engine.run_simulation([action], [ctx])
    
    # 3. Assert Diff
    print(f"\n[Simulation Result Diff]: {diff}")
    
    assert len(diff.updated) == 1
    assert diff.updated[0]['id'] == "SIM-001"
    assert diff.updated[0]['changes']['status'] == "Crashed"
    print("[PASS] Diff captured correctly.")
    
    # 4. Assert Isolation (Reality Check)
    om.default_session.expire_all()
    real_srv = om.get(SimTestServer, srv.id)
    print(f"Reality State After Simulation: {real_srv.status}")
    
    assert real_srv.status == "Active", "CRITICAL: Simulation leaked to Reality!"
    print("[PASS] Isolation Configured correctly.")
    
    print("=== PHASE 3 SIMULATION TEST PASSED ===")

if __name__ == "__main__":
    try:
        run_test()
    except Exception as e:
        print(f"!!! CRITICAL FAILURE !!! {e}")
        sys.exit(1)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/consolidation/miner.py
# ========================================================

import logging
from sqlalchemy import select, func
from scripts.ontology.manager import ObjectManager
from scripts.ontology.db import objects_table
from scripts.ontology.schemas.governance import OrionActionLog
from scripts.ontology.schemas.memory import OrionInsight, InsightContent, InsightProvenance

logger = logging.getLogger("ConsolidationEngine")
logging.basicConfig(level=logging.INFO)

class ConsolidationMiner:
    """
    Phase 5 Engine: Turns Action History into Wisdom.
    """
    def __init__(self, manager: ObjectManager):
        self.manager = manager
        
    def mine_failures(self):
        """
        Scan for repeated failures to generate Anti-Patterns.
        """
        session = self.manager.default_session
        
        # SQL: Select error, count(*) from objects where type='OrionActionLog' and status='FAILURE' group by error
        # Since 'data' is JSON, querying detailed stats is hard in pure SQL without JSON extension enabled properly.
        # But we can query all FAILURE logs and process in memory for MVP.
        
        # 1. Fetch all Failure Logs
        # Limitation: This fetches ALL rows. V4 needs pagination/filtering by timestamp.
        stmt = select(objects_table).where(
            objects_table.c.type == "OrionActionLog"
        )
        rows = session.execute(stmt).fetchall()
        
        failures = []
        for row in rows:
            data = row.data
            if data.get("status") == "FAILURE":
                failures.append(data)
                
        logger.info(f"[Miner] Found {len(failures)} failed actions.")
        
        # 2. Cluster by Error Message
        error_clusters = {}
        for f in failures:
            msg = f.get("error")
            action = f.get("action_type")
            key = f"{action}::{msg}"
            error_clusters[key] = error_clusters.get(key, 0) + 1
            
        # 3. Generate Insights for clusters > threshold
        THRESHOLD = 2
        for key, count in error_clusters.items():
            if count >= THRESHOLD:
                self._generate_anti_pattern(key, count)

    def _generate_anti_pattern(self, key: str, count: int):
        action, error = key.split("::", 1)
        
        # Check if Insight already exists? (De-duplication)
        # For MVP, we'll just create one and let the user merge/dedupe later or use a deterministic ID.
        insight_id = f"INSIGHT-FAIL-{abs(hash(key))}"
        
        existing = self.manager.get(OrionInsight, insight_id)
        if existing:
            logger.info(f"[Miner] Insight {insight_id} already exists. Skipping.")
            return

        logger.info(f"[Miner] Creating NEW Insight for repeated failure: {key} (Count: {count})")
        
        insight = OrionInsight(
            id=insight_id,
            confidence_score=0.9,
            content=InsightContent(
                domain="governance",
                summary=f"Anti-Pattern Detected: Action '{action}' reliably fails with '{error}'",
                tags=["anti-pattern", "auto-generated", action]
            ),
            provenance=InsightProvenance(
                method="mining",
                source_episodic_ids=[] # We could link the ActionLog IDs here
            )
        )
        self.manager.save(insight)

if __name__ == "__main__":
    om = ObjectManager()
    miner = ConsolidationMiner(om)
    miner.mine_failures()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/action/core.py
# ========================================================

from abc import ABC, abstractmethod
from typing import List, Optional, Any, Dict, Type
from datetime import datetime
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
from scripts.ontology.manager import ObjectManager, OrionObject
from scripts.ontology.schemas.governance import OrionActionLog
from scripts.ontology.db import SessionLocal

class ActionContext(BaseModel):
    """
    Runtime context for an Action Execution.
    Holds the Transactional Session and Parameters.
    """
    job_id: str = Field(..., description="Traceability ID")
    parameters: Dict[str, Any] = Field(default_factory=dict)
    
    # Runtime Objects (will be injected by ActionRunner)
    session: Optional[Session] = None
    manager: Optional[ObjectManager] = None

    class Config:
        arbitrary_types_allowed = True

class UnitOfWork:
    """
    Manages the Transaction Lifecycle.
    Supports Session Injection for Simulation via Nested Transactions.
    """
    def __init__(self, manager: ObjectManager, session: Optional[Session] = None):
        self.manager = manager
        self.transaction = None
        if session:
            self.session = session
            self.owns_session = False
            # Safety: Wrap injected session in a nested transaction
            # This ensures 'commit' only merges to the parent Savepoint, 
            # keeping the ScenarioFork Savepoint alive.
            self.transaction = self.session.begin_nested()
        else:
            self.session = SessionLocal()
            self.owns_session = True
        self.committed = False

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        try:
            if exc_type:
                # Exception occurred -> Rollback
                print(f"[UnitOfWork] Exception detected: {exc_val}. Rolling back...")
                try:
                    if self.transaction:
                        self.transaction.rollback()
                    else:
                        self.session.rollback()
                except Exception as e:
                    print(f"[UnitOfWork] Rollback ignored (already closed?): {e}")
                    # CRITICAL: If nested rollback fails, the session is likely inconsistent.
                    # We must force a full rollback to prevent 'own-write' visibility.
                    try:
                        self.session.rollback()
                    except Exception as rollback_err:
                        print(f"[UnitOfWork] Session rollback failed: {rollback_err}. Closing session.")
                        self.session.close()
            else:
                # Success -> Commit
                if not self.committed: 
                    if self.transaction:
                        self.transaction.commit()
                    else:
                        try:
                            self.session.commit()
                        except Exception as e:
                            self.session.rollback()
                            raise e
        finally:
            if self.owns_session:
                self.session.close()

class ActionDefinition(ABC):
    """
    The Base Class for Kinetic Actions.
    """
    
    @classmethod
    @abstractmethod
    def action_id(cls) -> str:
        """Unique Identifier (e.g., 'server.reboot')."""
        pass
        
    @abstractmethod
    def validate(self, ctx: ActionContext) -> bool:
        """
        Pure logic check.
        MUST NOT mutate state.
        Returns check result. Raise error for specific feedback.
        """
        pass

    @abstractmethod
    def apply(self, ctx: ActionContext):
        """
        Mutate state via ctx.manager (passing ctx.session).
        """
        pass

class ActionRunner:
    """
    Executes Actions within a UnitOfWork.
    """
    def __init__(self, manager: ObjectManager, session: Optional[Session] = None):
        self.manager = manager
        self.session_override = session

    
    def execute(self, action: ActionDefinition, ctx: ActionContext):
        # Inject Dependencies
        ctx.manager = self.manager
        ctx.session = self.session_override or self.manager.default_session
        
        print(f"[ActionRunner] Executing {action.action_id()} (Session ID: {id(ctx.session)})")

        # --- Phase 5: Audit Logging ---
        start_time = datetime.now()
        log_entry = OrionActionLog(
            action_type=action.action_id(),
            parameters=ctx.parameters,
            trace_id=ctx.job_id,
            status="PENDING",
            agent_id="Orion-Kernel" # Placeholder
        )

        try:
            # Lifecycle
            with UnitOfWork(self.manager, session=ctx.session):
                # 1. Validate
                if not action.validate(ctx):
                    raise ValueError(f"Validation Failed for {action.action_id()}")
                
                # 2. Apply
                action.apply(ctx)
                
                # 3. Commit handled by Context Manager __exit__
            
            log_entry.status = "SUCCESS"
            
        except Exception as e:
            log_entry.status = "FAILURE"
            log_entry.error = str(e)
            raise e
            
        finally:
            # Finalize Log Metadata
            end_time = datetime.now()
            log_entry.duration_ms = int((end_time - start_time).total_seconds() * 1000)
            
            # Persist Log
            self._persist_log(log_entry, ctx)

    def _persist_log(self, log_entry: OrionActionLog, ctx: ActionContext):
        """
        Persists the Audit Log.
        Handles the 'Dual-Transaction' requirement:
        - If Reality (Default Session): Use a FRESH session to ensure log survives rollback.
        - If Simulation: Log to the Sandbox (Ctx Session).
        """
        is_simulation = (ctx.session != self.manager.default_session) and (ctx.session is not None)
        
        if is_simulation:
            # In Simulation, we just save to the sandbox.
            # It will be captured in the diff and discarded on rollback.
            # This is correct behavior (don't pollute reality with sim logs).
            self.manager.save(log_entry, session=ctx.session)
        else:
            # In Reality, we MUST persist the log, even if the action failed.
            # We open a dedicated Audit Session.
            # In Reality, we MUST persist the log, even if the action failed.
            # We reuse the default session to avoid SQLite Locking contention (single writer).
            # Since we rolled back the business transaction, the session should be clean.
            try:
                # Force commit for the log
                self.manager.save(log_entry, session=self.manager.default_session, commit=True)
            except Exception as e:
                print(f"[ActionRunner] CRITICAL: Failed to write Audit Log! {e}")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/action/tests/test_transaction.py
# ========================================================

import sys
# sys.path.append("/home/palantir") # Done by Env usually

from scripts.ontology.core import OrionObject
from scripts.ontology.manager import ObjectManager
from scripts.action.core import ActionDefinition, ActionContext, ActionRunner, UnitOfWork

# --- Mocks ---
class TestServer(OrionObject):
    value: int = 0

class SuccessAction(ActionDefinition):
    @classmethod
    def action_id(cls): return "test.success"
    
    def validate(self, ctx): return True
    
    def apply(self, ctx):
        obj = ctx.manager.get(TestServer, ctx.parameters["id"], session=ctx.session)
        obj.value = 100
        ctx.manager.save(obj, session=ctx.session)

class FailAction(ActionDefinition):
    @classmethod
    def action_id(cls): return "test.fail"
    
    def validate(self, ctx): return True
    
    def apply(self, ctx):
        obj = ctx.manager.get(TestServer, ctx.parameters["id"], session=ctx.session)
        obj.value = 999 
        ctx.manager.save(obj, session=ctx.session)
        # Crash Here
        raise RuntimeError("Simulated Crash")

# --- Test ---
def run_test():
    print("=== STARTING PHASE 2 TRANSACTION TEST ===")
    
    om = ObjectManager()
    om.register_type(TestServer)
    
    # Setup
    srv = TestServer(id="TEST-TX-001", value=0)
    om.save(srv)
    print(f"Initial State: {srv.value}") # 0
    
    runner = ActionRunner(om)
    ctx = ActionContext(job_id="job-1", parameters={"id": srv.id})
    
    # 1. Success Case
    try:
        runner.execute(SuccessAction(), ctx)
        print("[PASS] Success Action executed.")
    except Exception as e:
        print(f"[FAIL] Success Action threw: {e}")

    # Verify State
    om.default_session.expire_all()
    loaded = om.get(TestServer, srv.id)
    assert loaded.value == 100
    print(f"State after Success: {loaded.value}") # Should be 100

    # 2. Failure Case (Rollback)
    try:
        runner.execute(FailAction(), ctx)
        print("[FAIL] Fail Action did not raise exception!")
    except RuntimeError:
        print("[PASS] Fail Action raised exception as expected.")
    
    # Verify State (Should still be 100, NOT 999)
    om.default_session.expire_all()
    loaded_after_fail = om.get(TestServer, srv.id)
    print(f"State after Fail: {loaded_after_fail.value}")
    
    assert loaded_after_fail.value == 100, f"Rollback Failed! Value is {loaded_after_fail.value}"
    print("=== PHASE 2 TRANSACTION TEST PASSED ===")

if __name__ == "__main__":
    try:
        run_test()
    except Exception as e:
        print(f"!!! CRITICAL FAILURE !!! {e}")
        sys.exit(1)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/__init__.py
# ========================================================
from .plan import Plan
from .job import Job
from .action import Action
from .trace import Trace, Status as StatusEnum
from .event import Event, EventType
from .metric import Metric

__all__ = ["Plan", "Job", "Action", "Trace", "StatusEnum", "Event", "EventType", "Metric"]


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/action.py
# ========================================================
# generated by datamodel-codegen:
#   filename:  action.schema.json

from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class Action(BaseModel):
    """
    Represents an executable capability (Tool) in the Orion System.
    """

    name: str = Field(..., description="Unique name of the action (e.g., 'read_file')")
    description: Optional[str] = Field(
        None, description='Human-readable description of what this action does.'
    )
    parameters: Dict[str, Any] = Field(
        ..., description='JSON Schema defining the expected arguments for this action.'
    )
    required_permissions: Optional[List[str]] = Field(
        None, description='List of security scopes required to execute this action.'
    )


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/actions.py
# ========================================================
"""
Orion ODA v3.0 - Semantic Action System
Palantir AIP/Foundry Compliant Action Definitions

This module implements the Action layer of the Ontology-Driven Architecture.
Actions are the ONLY way to mutate the Ontology, ensuring:
- All changes are validated (SubmissionCriteria)
- All changes are audited (EditOperations)
- Side effects are decoupled (post-commit execution)

Design Principles:
1. Actions are declarative (class-based, not instance-based)
2. Validation before mutation (fail-fast)
3. Side effects after commit (eventual consistency)
4. Full audit trail (who, what, when)
"""

from __future__ import annotations

import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import (
    Any,
    Callable,
    ClassVar,
    Dict,
    Generic,
    List,
    Optional,
    Protocol,
    Type,
    TypeVar,
    Union,
    runtime_checkable,
)

from pydantic import BaseModel, Field

from scripts.ontology.ontology_types import OntologyObject, utc_now

logger = logging.getLogger(__name__)


# =============================================================================
# EDIT OPERATIONS
# =============================================================================

class EditType(str, Enum):
    """Types of edit operations on the Ontology."""
    CREATE = "create"
    MODIFY = "modify"
    DELETE = "delete"
    LINK = "link"
    UNLINK = "unlink"


@dataclass
class EditOperation:
    """
    Represents a single edit operation on the Ontology.
    
    Used for:
    - Audit logging
    - Transaction rollback
    - Change data capture
    """
    edit_type: EditType
    object_type: str
    object_id: str
    changes: Dict[str, Any] = field(default_factory=dict)
    # Using default_factory for timestamp to ensure it's generated at instantiation
    timestamp: datetime = field(default_factory=utc_now)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "edit_type": self.edit_type.value,
            "object_type": self.object_type,
            "object_id": self.object_id,
            "changes": self.changes,
            "timestamp": self.timestamp.isoformat(),
        }



# =============================================================================
# SUBMISSION CRITERIA
# =============================================================================

class ValidationError(Exception):
    """Raised when SubmissionCriteria validation fails."""
    
    def __init__(self, criterion: str, message: str, details: Dict[str, Any] = None):
        self.criterion = criterion
        self.message = message
        self.details = details or {}
        super().__init__(f"[{criterion}] {message}")


@runtime_checkable
class SubmissionCriterion(Protocol):
    """
    Protocol for SubmissionCriteria validators.
    
    Implement this protocol to create custom validation rules.
    Each criterion is evaluated before action execution.
    """
    
    @property
    def name(self) -> str:
        """Human-readable name of this criterion."""
        ...
    
    def validate(self, params: Dict[str, Any], context: "ActionContext") -> bool:
        """
        Validate the action parameters.
        
        Args:
            params: Action parameters
            context: Execution context (user, timestamp, etc.)
        
        Returns:
            True if validation passes
        
        Raises:
            ValidationError: If validation fails
        """
        ...


class RequiredField(SubmissionCriterion):
    """Validates that a required field is present and non-empty."""
    
    def __init__(self, field_name: str):
        self.field_name = field_name
    
    @property
    def name(self) -> str:
        return f"RequiredField({self.field_name})"
    
    def validate(self, params: Dict[str, Any], context: "ActionContext") -> bool:
        value = params.get(self.field_name)
        if value is None or (isinstance(value, str) and not value.strip()):
            raise ValidationError(
                criterion=self.name,
                message=f"Field '{self.field_name}' is required",
                details={"field": self.field_name, "value": value}
            )
        return True


class AllowedValues(SubmissionCriterion):
    """Validates that a field value is in an allowed set."""
    
    def __init__(self, field_name: str, allowed: List[Any]):
        self.field_name = field_name
        self.allowed = allowed
    
    @property
    def name(self) -> str:
        return f"AllowedValues({self.field_name})"
    
    def validate(self, params: Dict[str, Any], context: "ActionContext") -> bool:
        value = params.get(self.field_name)
        if value is not None and value not in self.allowed:
            raise ValidationError(
                criterion=self.name,
                message=f"Value '{value}' not in allowed values: {self.allowed}",
                details={"field": self.field_name, "value": value, "allowed": self.allowed}
            )
        return True


class MaxLength(SubmissionCriterion):
    """Validates that a string field doesn't exceed max length."""
    
    def __init__(self, field_name: str, max_length: int):
        self.field_name = field_name
        self.max_length = max_length
    
    @property
    def name(self) -> str:
        return f"MaxLength({self.field_name}, {self.max_length})"
    
    def validate(self, params: Dict[str, Any], context: "ActionContext") -> bool:
        value = params.get(self.field_name, "")
        if isinstance(value, str) and len(value) > self.max_length:
            raise ValidationError(
                criterion=self.name,
                message=f"Field '{self.field_name}' exceeds max length {self.max_length}",
                details={"field": self.field_name, "length": len(value), "max": self.max_length}
            )
        return True


class CustomValidator(SubmissionCriterion):
    """Wraps a custom validation function."""
    
    def __init__(
        self,
        name: str,
        validator_fn: Callable[[Dict[str, Any], "ActionContext"], bool],
        error_message: str = "Custom validation failed"
    ):
        self._name = name
        self.validator_fn = validator_fn
        self.error_message = error_message
    
    @property
    def name(self) -> str:
        return self._name
    
    def validate(self, params: Dict[str, Any], context: "ActionContext") -> bool:
        if not self.validator_fn(params, context):
            raise ValidationError(
                criterion=self.name,
                message=self.error_message,
                details={"params": params}
            )
        return True


# =============================================================================
# SIDE EFFECTS
# =============================================================================

@runtime_checkable
class SideEffect(Protocol):
    """
    Protocol for post-commit side effects.
    
    Side effects are executed AFTER the Ontology commit succeeds.
    They should be idempotent and handle failures gracefully.
    
    Examples:
    - Send Slack notification
    - Trigger webhook
    - Update external cache
    - Emit analytics event
    """
    
    @property
    def name(self) -> str:
        """Human-readable name of this side effect."""
        ...
    
    async def execute(
        self,
        action_result: "ActionResult",
        context: "ActionContext"
    ) -> None:
        """
        Execute the side effect.
        
        Args:
            action_result: Result of the action execution
            context: Execution context
        
        Note: Exceptions should be logged but not re-raised
        to avoid breaking other side effects.
        """
        ...


class LogSideEffect:
    """Logs action execution to the standard logger."""
    
    def __init__(self, log_level: int = logging.INFO):
        self.log_level = log_level
    
    @property
    def name(self) -> str:
        return "LogSideEffect"
    
    async def execute(
        self,
        action_result: "ActionResult",
        context: "ActionContext"
    ) -> None:
        logger.log(
            self.log_level,
            f"Action executed: {action_result.action_type} "
            f"by {context.actor_id} - "
            f"{'SUCCESS' if action_result.success else 'FAILED'}"
        )


class WebhookSideEffect:
    """Sends action result to a webhook URL."""
    
    def __init__(self, url: str, headers: Dict[str, str] = None):
        self.url = url
        self.headers = headers or {}
    
    @property
    def name(self) -> str:
        return f"WebhookSideEffect({self.url})"
    
    async def execute(
        self,
        action_result: "ActionResult",
        context: "ActionContext"
    ) -> None:
        import httpx
        
        try:
            async with httpx.AsyncClient() as client:
                await client.post(
                    self.url,
                    json=action_result.to_dict(),
                    headers=self.headers,
                    timeout=10.0
                )
        except Exception as e:
            logger.error(f"Webhook failed: {self.url} - {e}")


class SlackNotification:
    """Sends notification to a Slack channel."""
    
    def __init__(self, channel: str, webhook_url: str = None):
        self.channel = channel
        self.webhook_url = webhook_url  # From config if not provided
    
    @property
    def name(self) -> str:
        return f"SlackNotification({self.channel})"
    
    async def execute(
        self,
        action_result: "ActionResult",
        context: "ActionContext"
    ) -> None:
        # Implementation depends on Slack integration
        logger.info(
            f"[Slack:{self.channel}] Action {action_result.action_type} "
            f"completed by {context.actor_id}"
        )


# =============================================================================
# ACTION CONTEXT & RESULT
# =============================================================================

@dataclass
class ActionContext:
    """
    Execution context for an action.
    
    Contains information about WHO is executing the action,
    WHEN it's being executed, and any relevant metadata.
    """
    actor_id: str  # User or Agent ID
    timestamp: datetime = field(default_factory=utc_now)
    correlation_id: Optional[str] = None  # For distributed tracing
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    @classmethod
    def system(cls) -> "ActionContext":
        """Create a system-level context (for automated actions)."""
        return cls(actor_id="system", metadata={"automated": True})


@dataclass
class ActionResult:
    """
    Result of an action execution.
    
    Contains success/failure status, created/modified objects,
    and any error information.
    """
    action_type: str
    success: bool
    edits: List[EditOperation] = field(default_factory=list)
    created_ids: List[str] = field(default_factory=list)
    modified_ids: List[str] = field(default_factory=list)
    deleted_ids: List[str] = field(default_factory=list)
    error: Optional[str] = None
    error_details: Optional[Dict[str, Any]] = None
    timestamp: datetime = field(default_factory=utc_now)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "action_type": self.action_type,
            "success": self.success,
            "edits": [e.to_dict() for e in self.edits],
            "created_ids": self.created_ids,
            "modified_ids": self.modified_ids,
            "deleted_ids": self.deleted_ids,
            "error": self.error,
            "error_details": self.error_details,
            "timestamp": self.timestamp.isoformat(),
        }


# =============================================================================
# BASE ACTION TYPE
# =============================================================================

T = TypeVar("T", bound=OntologyObject)


class ActionType(ABC, Generic[T]):
    """
    Base class for all ActionTypes.
    
    To define a new action, subclass ActionType and implement:
    1. Class attributes: api_name, object_type, submission_criteria, side_effects
    2. apply_edits() method: the actual mutation logic
    
    Example:
        ```python
        class CreateTaskAction(ActionType[Task]):
            api_name = "create_task"
            object_type = Task
            
            submission_criteria = [
                RequiredField("title"),
                AllowedValues("priority", ["low", "medium", "high"]),
                MaxLength("title", 255),
            ]
            
            side_effects = [
                LogSideEffect(),
                SlackNotification(channel="#tasks"),
            ]
            
            async def apply_edits(
                self,
                params: Dict[str, Any],
                context: ActionContext
            ) -> Tuple[T, List[EditOperation]]:
                task = Task(
                    title=params["title"],
                    priority=params.get("priority", "medium"),
                    created_by=context.actor_id,
                )
                edit = EditOperation(
                    edit_type=EditType.CREATE,
                    object_type="Task",
                    object_id=task.id,
                    changes=params,
                )
                return task, [edit]
        ```
    """
    
    # Class attributes to be overridden by subclasses
    api_name: ClassVar[str]
    object_type: ClassVar[Type[T]]
    submission_criteria: ClassVar[List[SubmissionCriterion]] = []
    side_effects: ClassVar[List[SideEffect]] = []
    requires_proposal: ClassVar[bool] = False  # True for hazardous actions
    
    def __init__(self):
        """Initialize the action. Override for custom initialization."""
        pass
    
    def validate(self, params: Dict[str, Any], context: ActionContext) -> List[str]:
        """
        Run all submission criteria validators.
        
        Args:
            params: Action parameters
            context: Execution context
        
        Returns:
            List of validation error messages (empty if all pass)
        """
        errors = []
        for criterion in self.submission_criteria:
            try:
                criterion.validate(params, context)
            except ValidationError as e:
                errors.append(str(e))
        return errors
    
    @abstractmethod
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[Optional[T], List[EditOperation]]:
        """
        Apply the action's edits to the Ontology.
        
        This is where the actual mutation logic lives.
        
        Args:
            params: Action parameters
            context: Execution context
        
        Returns:
            Tuple of (created/modified object or None, list of edit operations)
        """
        ...
    
    async def execute(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> ActionResult:
        """
        Execute the action with full validation and side effects.
        
        Execution flow:
        1. Validate submission criteria
        2. Apply edits (transactional)
        3. Execute side effects (post-commit)
        
        Args:
            params: Action parameters
            context: Execution context
        
        Returns:
            ActionResult with success/failure status
        """
        # 1. Validation
        errors = self.validate(params, context)
        if errors:
            return ActionResult(
                action_type=self.api_name,
                success=False,
                error="Submission criteria failed",
                error_details={"validation_errors": errors},
            )
        
        # 2. Apply Edits
        try:
            obj, edits = await self.apply_edits(params, context)
            
            result = ActionResult(
                action_type=self.api_name,
                success=True,
                edits=edits,
                created_ids=[obj.id] if obj and any(
                    e.edit_type == EditType.CREATE for e in edits
                ) else [],
                modified_ids=[obj.id] if obj and any(
                    e.edit_type == EditType.MODIFY for e in edits
                ) else [],
            )
        except Exception as e:
            logger.exception(f"Action {self.api_name} failed")
            return ActionResult(
                action_type=self.api_name,
                success=False,
                error=str(e),
                error_details={"exception_type": type(e).__name__},
            )
        
        # 3. Side Effects (fire-and-forget, errors logged but not raised)
        for effect in self.side_effects:
            try:
                await effect.execute(result, context)
            except Exception as e:
                logger.error(f"Side effect {effect.name} failed: {e}")
        
        return result
    
    def __repr__(self) -> str:
        return f"{self.__class__.__name__}(api_name='{self.api_name}')"


# =============================================================================
# ACTION REGISTRY
# =============================================================================

# =============================================================================
# ACTION REGISTRY & GOVERNANCE
# =============================================================================

@dataclass
class ActionMetadata:
    """Metadata for governance and execution policy."""
    requires_proposal: bool = False
    is_dangerous: bool = False
    description: str = ""

class ActionRegistry:
    """
    Registry for ActionType discovery and lookup with Metadata.
    
    Stores not just the class, but also its governance metadata.
    """
    
    def __init__(self):
        # Mapping: api_name -> (ActionClass, Metadata)
        self._actions: Dict[str, tuple[Type[ActionType], ActionMetadata]] = {}
    
    def register(self, action_class: Type[ActionType], **metadata_overrides) -> None:
        """Register an ActionType class with extracted or overridden metadata."""
        if not hasattr(action_class, "api_name"):
            raise ValueError(f"{action_class.__name__} missing api_name")
        
        api_name = action_class.api_name
        
        # Extract metadata from class attributes (Source of Truth)
        # Priorities: 1. Overrides (Decorator param) -> 2. Class Attribute -> 3. Default False
        requires_proposal = metadata_overrides.get(
            "requires_proposal", 
            getattr(action_class, "requires_proposal", False)
        )
        is_dangerous = metadata_overrides.get("is_dangerous", False) # Default for now if not on class
        
        metadata = ActionMetadata(
            requires_proposal=requires_proposal,
            is_dangerous=is_dangerous,
            description=action_class.__doc__ or ""
        )

        if api_name in self._actions:
            logger.warning(f"Overwriting action: {api_name}")
        
        self._actions[api_name] = (action_class, metadata)
        logger.debug(f"Registered action: {api_name} [Proposal:{requires_proposal}]")
    
    def get(self, api_name: str) -> Optional[Type[ActionType]]:
        """Get an ActionType class by api_name."""
        entry = self._actions.get(api_name)
        return entry[0] if entry else None

    def get_metadata(self, api_name: str) -> Optional[ActionMetadata]:
        """Get governance metadata for an action."""
        entry = self._actions.get(api_name)
        return entry[1] if entry else None
    
    def list_actions(self) -> List[str]:
        """List all registered action api_names."""
        return list(self._actions.keys())


# Global registry instance
action_registry = ActionRegistry()


def register_action(cls: Type[ActionType] = None, *, requires_proposal: bool = None):
    """
    Decorator to register an ActionType with the global registry.
    
    Can be used as:
    1. Bare decorator: @register_action
    2. With args: @register_action(requires_proposal=True)
    """
    def _register(action_cls):
        overrides = {}
        if requires_proposal is not None:
            overrides["requires_proposal"] = requires_proposal
            
        action_registry.register(action_cls, **overrides)
        return action_cls

    if cls is None:
        return _register
    return _register(cls)


class GovernanceEngine:
    """
    Enforces policies based on ActionMetadata.
    
    Centralizes the logic for "Should this run immediately or wait for approval?".
    """
    def __init__(self, registry: ActionRegistry):
        self.registry = registry
    
    def check_execution_policy(self, action_name: str) -> str:
        """
        Determines execution policy.
        Returns:
            "DENY": Action unknown
            "REQUIRE_PROPOSAL": Needs HITL review
            "ALLOW_IMMEDIATE": Can run now
        """
        meta = self.registry.get_metadata(action_name)
        if not meta:
            return "DENY"
        
        if meta.requires_proposal:
            return "REQUIRE_PROPOSAL"
        
        return "ALLOW_IMMEDIATE"



# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/client.py
# ========================================================

from typing import Type, TypeVar, List, Optional, Any, Generic, Dict
from abc import ABC, abstractmethod
import uuid
from datetime import datetime

T = TypeVar('T')

class FoundryClient:
    """
    Mock OSDK FoundryClient for Orion.
    Acts as the entry point for the Semantic Layer.
    """
    def __init__(self, hostname: str = "localhost"):
        self.hostname = hostname
        self._ontology = OntologyNamespace()

    @property
    def ontology(self):
        return self._ontology

class OntologyNamespace:
    def __init__(self):
        self._objects = ObjectService()
        self._actions = ActionService()

    @property
    def objects(self):
        return self._objects

    @property
    def actions(self):
        return self._actions

class ObjectService:
    """
    [Query-Side] Read-Only Access to Objects.
    """
    def __init__(self):
        self._registry: Dict[str, Type['BaseObject']] = {}

    def register(self, obj_type: Type['BaseObject']):
        self._registry[obj_type.__name__] = obj_type
        # Bind the type dynamically
        setattr(self, obj_type.__name__, Binding(obj_type))

class ActionService:
    """
    [Command-Side] Submission of Actions.
    """
    def submit(self, action_name: str, parameters: Dict[str, Any]):
        print(f"[Command] Submitting Action '{action_name}' with {parameters}")
        # In a real system, this would lookup the ActionType and execute it
        # For now, it's a stub for the CQRS pattern
        return {"status": "submitted", "action": action_name}

class Binding(Generic[T]):
    def __init__(self, obj_type: Type[T]):
        self.object_type = obj_type

    def where(self, condition) -> List[T]:
        # Mock implementation: Returns empty list for now
        print(f"[Query] Filtering {self.object_type.__name__} where {condition}")
        return []

    def get(self, pk: str) -> Optional[T]:
        print(f"[Query] Get {self.object_type.__name__} id={pk}")
        return None
    
    def create(self, **kwargs) -> T:
        print(f"[Action] Creating {self.object_type.__name__} with {kwargs}")
        return self.object_type(**kwargs)

class BaseObject(ABC):
    def __init__(self, **kwargs):
        for k, v in kwargs.items():
            setattr(self, k, v)
        if not hasattr(self, 'id'):
            self.id = str(uuid.uuid4())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/db.py
# ========================================================

from sqlalchemy import create_engine, Column, String, Integer, DateTime, Text, JSON, MetaData, Table
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool
import os

# Database Path - leveraging the existing Orion artifacts directory
DB_PATH = os.path.abspath("/home/palantir/.agent/orion_ontology.db")
DATABASE_URL = f"sqlite:///{DB_PATH}"

metadata = MetaData()

# The Universal Object Table (Phonograph Pattern)
# Instead of one table per type, we use a document-store pattern for flexibility,
# backed by indices for performance.
objects_table = Table(
    "objects",
    metadata,
    Column("id", String, primary_key=True),  # UUIDv7
    Column("type", String, index=True, nullable=False),  # e.g., 'Server', 'Incident'
    Column("version", Integer, default=1),  # Optimistic Locking
    Column("created_at", DateTime, nullable=False),
    Column("updated_at", DateTime, nullable=False),
    Column("data", JSON, nullable=False),  # The full Pydantic dump
    Column("fts_content", Text, nullable=True)  # Flattened text for FTS5 search
)

# Initialize Engine
# Enable Write-Ahead Logging (WAL) for concurrency
engine = create_engine(
    DATABASE_URL, 
    connect_args={"check_same_thread": False},
    poolclass=QueuePool,
    pool_size=5,
    max_overflow=10
)

def init_db():
    """Idempotent initialization of the database schema."""
    # Ensure directory exists
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    
    # Enable WAL mode explicitly
    with engine.connect() as conn:
        conn.exec_driver_sql("PRAGMA journal_mode=WAL;")
        
    metadata.create_all(engine)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/event.py
# ========================================================
# generated by datamodel-codegen:
#   filename:  event.schema.json

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, Optional

from pydantic import BaseModel, Field


class EventType(Enum):
    """
    Type of the event.
    """

    ACTION_START = 'ACTION_START'
    ACTION_END = 'ACTION_END'
    ERROR = 'ERROR'
    STATE_CHANGE = 'STATE_CHANGE'
    THOUGHT = 'THOUGHT'


class Event(BaseModel):
    """
    Represents a discrete event within a Trace.
    """

    trace_id: str = Field(..., description='ID of the Trace this event belongs to.')
    timestamp: str = Field(..., description='ISO 8601 timestamp.')
    event_type: EventType = Field(..., description='Type of the event.')
    component: str = Field(
        ...,
        description="Component that generated the event (e.g., 'ReasoningEngine', 'ActionRegistry').",
    )
    details: Optional[Dict[str, Any]] = Field(
        None,
        description='Structured details (e.g., action name, arguments, error message).',
    )


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/handoff.py
# ========================================================
import os
import json
import argparse
from datetime import datetime
from scripts.ontology.plan import Plan

# Configuration
TEMPLATE_DIR = "/home/palantir/orion-orchestrator-v2/.agent/handoffs/templates"
PENDING_DIR = "/home/palantir/orion-orchestrator-v2/.agent/handoffs/pending"
PLANS_DIR = "/home/palantir/.agent/plans" # Assuming plans are stored here

def load_template(role: str) -> str:
    """Loads the markdown template for the given role."""
    filename = f"claude_architect.md" if role.lower() == "architect" else f"gpt_mechanic.md"
    path = os.path.join(TEMPLATE_DIR, filename)
    
    if not os.path.exists(path):
        raise FileNotFoundError(f"Template not found for role: {role} at {path}")
        
    with open(path, 'r') as f:
        return f.read()

def generate_handoff(plan_path: str, job_index: int):
    """
    Generates a Handoff Markdown file from a Plan + Job.
    
    Args:
        plan_path: Path to the Plan JSON file.
        job_index: Index of the Job in the Plan's job list (0-based).
    """
    # 1. Load Plan
    if not os.path.exists(plan_path):
        raise FileNotFoundError(f"Plan file not found: {plan_path}")
        
    with open(plan_path, 'r') as f:
        plan_data = json.load(f)
    
    # Simple validation using Pydantic model logic (simplified here for script speed)
    plan_id = plan_data.get("id")
    objective = plan_data.get("objective")
    jobs = plan_data.get("jobs", [])
    
    if job_index >= len(jobs):
        raise ValueError(f"Job Index {job_index} out of range for Plan {plan_id} (Total Jobs: {len(jobs)})")
        
    job = jobs[job_index]
    role = job.get("role", "Automation") # Default to Automation if not set
    job_id = job.get("id")
    
    print(f"🔄 Generating Handoff for Job {job_id} ({role})...")
    
    # 2. Load Template
    template_content = load_template(role)
    
    # 3. Prepare Context
    # Map Job fields to Template Placeholders
    context_files = "\n".join([f"- `{f}`" for f in job.get("input_context", [])])
    if not context_files:
        context_files = "(No specific context files provided. Phase 1 Research recommended.)"
        
    instructions = f"""
    **Action**: {job.get('action_name')}
    **Arguments**: {json.dumps(job.get('action_args', {}), indent=2)}
    
    **Description**:
    {job.get('description', 'Execute the specified action.')}
    """
    
    # 4. Fill Template
    # Using simple string replacement to avoid external dependencies like Jinja2
    content = template_content
    content = content.replace("{{Objective}}", objective)
    # Inject ODA Lifecycle Context
    content = f"# ODA_PHASE: 2. Execution (Relay)\n{content}"
    content = content.replace("{{ContextFiles}}", context_files)
    content = content.replace("{{DetailedInstructions}}", instructions)
    content = content.replace("{{TargetScope}}", context_files) # Reuse for GPT
    content = content.replace("{{ExecutionSteps}}", instructions) # Reuse for GPT
    content = content.replace("{{SafeToAutoRun}}", "False (User Approval Required)")
    content = content.replace("{{JobId}}", job_id)
    
    # 5. Write to Pending
    filename = f"job_{job_id}_{role.lower()}.md"
    output_path = os.path.join(PENDING_DIR, filename)
    
    with open(output_path, 'w') as f:
        f.write(content)
        
    print(f"✅ Handoff Artifact Created: {output_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate Handoff Artifacts from Plan")
    parser.add_argument("--plan", required=True, help="Path to Plan JSON")
    parser.add_argument("--job", type=int, required=True, help="Job Index (0-based)")
    
    args = parser.parse_args()
    
    generate_handoff(args.plan, args.job)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/job.py
# ========================================================
# generated by datamodel-codegen:
#   filename:  plan.schema.json

from __future__ import annotations

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field


class Job(BaseModel):
    id: str = Field(..., description='Unique Job ID')
    action_name: str = Field(..., description='Name of the action to execute')
    action_args: Optional[Dict[str, Any]] = Field(
        {}, description='Arguments for the action'
    )
    description: Optional[str] = Field(None, description='Description of the job')
    input_context: Optional[List[str]] = Field([], description='Context files/dirs')
    evidence: Optional[str] = Field(None, description='Reasoning/Evidence for this job')
    role: Optional[str] = Field(None, description='Role responsible for this job')


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/learning.py
# ========================================================
#!/usr/bin/env python3
"""
Orion V3 Learning Mode Trigger
Usage: python scripts/ontology/learning.py --target <path> --mode <concept|review>

This script prepares the Orion workspace for an "Agile Learning Session".
It scans the target codebase, generates a structural manifest, and creates a
session context file that the AI Agent (Gemini) can consume to perform
Reflective Architecture Analysis.
"""

import argparse
import os
import json
import datetime
from pathlib import Path
from typing import Dict, List, Any

# Analysis Constants
INTERESTING_EXTENSIONS = {'.py', '.ts', '.tsx', '.js', '.md', '.json'}
IGNORE_DIRS = {'__pycache__', 'node_modules', '.git', '.venv', 'dist', 'build', '.agent'}

class CodebaseScanner:
    def __init__(self, root: str):
        self.root = Path(root).resolve()
        
    def scan(self) -> Dict[str, Any]:
        """Generates a hierarchical structural manifest of the codebase."""
        manifest = {
            "root": str(self.root),
            "scanned_at": datetime.datetime.now().isoformat(),
            "structure": {},
            "key_artifacts": []
        }
        
        for root, dirs, files in os.walk(self.root):
            # Prune ignored directories
            dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
            
            rel_path = Path(root).relative_to(self.root)
            if str(rel_path) == ".":
                rel_path = Path("")
                
            current_node = {
                "files": [],
                "subdirs": dirs
            }
            
            for f in files:
                if Path(f).suffix in INTERESTING_EXTENSIONS:
                    current_node["files"].append(f)
                    
                    # Heuristic for "Key Artifacts" (e.g., Models, APIs)
                    if f in ["models.py", "schema.py", "api.py", "types.ts", "interfaces.ts"]:
                         manifest["key_artifacts"].append(str(rel_path / f))
            
            if current_node["files"] or current_node["subdirs"]:
                 manifest["structure"][str(rel_path)] = current_node
                 
        return manifest

def generate_session_context(target_path: str, mode: str):
    scanner = CodebaseScanner(target_path)
    manifest = scanner.scan()
    
    session_id = datetime.datetime.now().strftime("learn_%Y%m%d_%H%M%S")
    output_dir = Path(".agent/learning")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = output_dir / f"{session_id}.json"
    
    context = {
        "session_id": session_id,
        "mode": mode,
        "target_path": str(target_path),
        "manifest": manifest,
        "instruction": "Agent: Read this manifest. Map the 'key_artifacts' to Palantir FDE Knowledge Base concepts. Perform Reflective Analysis."
    }
    
    with open(output_file, "w") as f:
        json.dump(context, f, indent=2)
        
    print(f"\n✅ Learning Session Context Generated: {output_file}")
    print(f"==================================================")
    print(f"🔎 Target: {target_path}")
    print(f"🎓 Mode: {mode.upper()}")
    print(f"📂 Artifacts Found: {len(manifest['key_artifacts'])}")
    print(f"==================================================")
    print(f"\n🚀 TO START LEARNING, TYPE THIS TO THE AGENT:")
    print(f"\n'[SYSTEM MODE: Palantir FDE Learning]'")
    print(f"'Active Context: {output_file}'")
    print(f"'Please analyze my codebase using the FDE Knowledge Base.'")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Orion Learning Mode Trigger")
    parser.add_argument("--target", required=True, help="Path to the codebase to analyze")
    parser.add_argument("--mode", choices=["concept", "review"], default="review", help="Learning mode")
    
    args = parser.parse_args()
    generate_session_context(args.target, args.mode)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/manager.py
# ========================================================

from typing import Type, TypeVar, Optional, List, Dict
from sqlalchemy.orm import Session
from sqlalchemy import select, text
from scripts.ontology.core import OrionObject
from scripts.ontology.db import init_db, SessionLocal, DB_PATH, objects_table
from scripts.ontology.schemas.governance import OrionActionLog
from scripts.ontology.schemas.result import JobResult
from scripts.ontology.schemas.memory import OrionInsight, OrionPattern

T = TypeVar("T", bound=OrionObject)

class ObjectManager:
    """
    The Gatekeeper for the Ontology.
    Implements the 'Phonograph' pattern:
    - Write-Back Caching
    - Optimistic Locking
    - Session Scope Management (Supports Transactional Workflows)
    """
    
    _instance = None
    _listeners = []

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ObjectManager, cls).__new__(cls)
            cls._instance._initialize()
        return cls._instance

    def _initialize(self):
        init_db()
        # The 'Default' session for interactive use or legacy scripts.
        # Actions should provide their own scoped session.
        self.default_session: Session = SessionLocal()
        self._listeners = []
        # Registry of known types for hydration
        self.type_registry: Dict[str, Type[T]] = {
            "OrionObject": OrionObject,
            "OrionActionLog": OrionActionLog,
            "JobResult": JobResult,
            "OrionInsight": OrionInsight,
            "OrionPattern": OrionPattern
        }

    def subscribe(self, callback):
        """Subscribe to object mutation events (save/delete)."""
        self._listeners.append(callback)

    def unsubscribe(self, callback):
        if callback in self._listeners:
            self._listeners.remove(callback)

    def _notify(self, event_type: str, obj: OrionObject):
        for callback in self._listeners:
            callback(event_type, obj)

    def register_type(self, cls: Type[T]):
        """Register a Pydantic model for hydration."""
        self.type_registry[cls.__name__] = cls

    def create_session(self) -> Session:
        """Create a new independent session (e.g., for Audit logging)."""
        return SessionLocal()

    def get(self, cls: Type[T], obj_id: str, session: Optional[Session] = None) -> Optional[T]:
        """
        Fetches an object by ID.
        :param session: Optional SQLAlchemy session (for transaction isolation). 
                       If None, uses the default global session.
        """
        active_session = session if session else self.default_session
        
        stmt = select(objects_table).where(objects_table.c.id == obj_id)
        row = active_session.execute(stmt).fetchone()
        
        if not row:
            return None
            
        # Validate Type
        stored_type = row.type
        if stored_type != cls.__name__:
            raise ValueError(f"Type Mismatch: ID {obj_id} is {stored_type}, expected {cls.__name__}")

        # Hydrate
        data = row.data
        obj = cls(**data)
        
        # Sync metadata
        obj.version = row.version
        obj.created_at = row.created_at
        obj.updated_at = row.updated_at
        obj.mark_clean()
        
        return obj

    def save(self, obj: OrionObject, session: Optional[Session] = None, commit: Optional[bool] = None):
        """
        Saves a Living Object.
        :param session: External session (Transactional).
        :param commit: Explicit commit override.
                       - If session is None: Defaults to True (Auto-Commit)
                       - If session is Provided: Defaults to False (UnitOfWork handles commit)
        """
        active_session = session if session else self.default_session
        
        # Determine Commit Strategy
        if session is None:
            # Interactive/Global Session -> Default Commit
            should_commit = (commit is not False)
        else:
            # Transactional Session -> Default Flush Only
            should_commit = (commit is True)

        if not obj.is_dirty() and obj.version > 1:
            return

        type_name = obj.__class__.__name__

        # Check if exists (in DB)
        stmt = select(objects_table.c.version).where(objects_table.c.id == obj.id)
        existing = active_session.execute(stmt).fetchone()

        if existing:
            # UPDATE
            obj.version += 1
            
            update_data = {
                "version": obj.version,
                "updated_at": obj.updated_at,
                "data": obj.model_dump(mode='json'),
                "fts_content": obj.get_searchable_text()
            }
            
            update_stmt = objects_table.update().where(
                objects_table.c.id == obj.id
            ).values(**update_data)
            
            active_session.execute(update_stmt)
            
        else:
            # INSERT
            insert_data = {
                "id": obj.id,
                "type": type_name,
                "version": obj.version,
                "created_at": obj.created_at,
                "updated_at": obj.updated_at,
                "data": obj.model_dump(mode='json'),
                "fts_content": obj.get_searchable_text()
            }
            
            insert_stmt = objects_table.insert().values(**insert_data)
            active_session.execute(insert_stmt)

        # Notify Listeners (e.g. Simulation Diff)
        self._notify("save", obj)

        if should_commit:
            active_session.commit()
            obj.mark_clean()
        else:
            active_session.flush()
            obj.mark_clean()

    def close(self):
        self.default_session.close()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/metric.py
# ========================================================
# generated by datamodel-codegen:
#   filename:  metric.schema.json

from __future__ import annotations

from typing import Optional

from pydantic import BaseModel, Field


class Metric(BaseModel):
    """
    Represents quantitative performance data.
    """

    trace_id: Optional[str] = Field(None, description='ID of the Trace context.')
    name: str = Field(
        ...,
        description="Name of the metric (e.g., 'execution_time_ms', 'tokens_used').",
    )
    value: float = Field(..., description='Numeric value of the metric.')
    unit: Optional[str] = Field(
        None, description="Unit of measurement (e.g., 'ms', 'count')."
    )
    timestamp: str = Field(..., description='ISO 8601 timestamp.')


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/ontology_types.py
# ========================================================
"""
Orion ODA v3.0 - Core Ontology Types
Palantir AIP/Foundry Compliant Type Definitions

This module defines the foundational types for the Ontology-Driven Architecture:
- Cardinality: Relationship multiplicity constraints
- PropertyType: Supported property data types
- Link: Type-safe relationship definitions
- OntologyObject: Base class for all domain entities
"""

from __future__ import annotations

import uuid
from datetime import datetime, timezone
from enum import Enum
from typing import (
    TYPE_CHECKING,
    Any,
    Dict,
    Generic,
    List,
    Optional,
    Type,
    TypeVar,
)

from pydantic import BaseModel, Field, field_validator


# =============================================================================
# ENUMS
# =============================================================================

class Cardinality(str, Enum):
    """
    LinkType cardinality constraints.
    Aligned with Palantir Ontology Link Types.
    
    - ONE_TO_ONE: Single object on both sides (e.g., User ↔ Profile)
    - ONE_TO_MANY: Foreign key pattern (e.g., Department → Employees)
    - MANY_TO_MANY: Join table pattern (e.g., Task ↔ Tags)
    """
    ONE_TO_ONE = "1:1"
    ONE_TO_MANY = "1:N"
    MANY_TO_ONE = "N:1"
    MANY_TO_MANY = "N:N"


class PropertyType(str, Enum):
    """
    Supported property data types.
    Aligned with Palantir Ontology Property Types.
    """
    STRING = "string"
    INTEGER = "integer"
    LONG = "long"
    FLOAT = "float"
    DOUBLE = "double"
    BOOLEAN = "boolean"
    DATE = "date"
    TIMESTAMP = "timestamp"
    ARRAY = "array"
    STRUCT = "struct"
    GEOPOINT = "geopoint"
    GEOSHAPE = "geoshape"
    TIMESERIES = "timeseries"
    VECTOR = "vector"


class ObjectStatus(str, Enum):
    """
    Lifecycle status for OntologyObjects.
    """
    ACTIVE = "active"
    ARCHIVED = "archived"
    DELETED = "deleted"


# =============================================================================
# LINK TYPE
# =============================================================================

T = TypeVar("T", bound="OntologyObject")


class Link(Generic[T]):
    """
    Represents a LinkType (Relationship) between OntologyObjects.
    
    Attributes:
        target: The target ObjectType class
        link_type_id: Unique identifier for this link type (e.g., "task_assigned_to_agent")
        cardinality: Relationship multiplicity constraint
        reverse_link_id: Optional reverse link identifier for bidirectional navigation
        description: Human-readable description of the relationship
    
    Example:
        ```python
        class Task(OntologyObject):
            assigned_to: Link[Agent] = Link(
                target=Agent,
                link_type_id="task_assigned_to_agent",
                cardinality=Cardinality.MANY_TO_ONE,
                reverse_link_id="agent_assigned_tasks",
                description="The agent responsible for this task"
            )
        ```
    """
    
    def __init__(
        self,
        target: Type[T],
        link_type_id: str,
        cardinality: Cardinality = Cardinality.ONE_TO_MANY,
        reverse_link_id: Optional[str] = None,
        description: Optional[str] = None,
    ):
        self._validate_link_type_id(link_type_id)
        
        self.target = target
        self.link_type_id = link_type_id
        self.cardinality = cardinality
        self.reverse_link_id = reverse_link_id
        self.description = description
    
    @staticmethod
    def _validate_link_type_id(link_type_id: str) -> None:
        """Enforce snake_case naming convention for link type IDs."""
        if not link_type_id:
            raise ValueError("link_type_id cannot be empty")
        if not link_type_id.replace("_", "").isalnum():
            raise ValueError(
                f"link_type_id must be snake_case alphanumeric: {link_type_id}"
            )
    
    def __repr__(self) -> str:
        return (
            f"Link(target={self.target.__name__}, "
            f"cardinality={self.cardinality.value}, "
            f"link_type_id='{self.link_type_id}')"
        )


# =============================================================================
# BASE ONTOLOGY OBJECT
# =============================================================================

def generate_object_id() -> str:
    """
    Generate a unique object ID.
    Format: UUIDv4 string (compatible with distributed systems)
    
    Note: Palantir recommends String-based primary keys over Long
    to avoid JavaScript precision issues in Workshop/Slate.
    """
    return str(uuid.uuid4())


def utc_now() -> datetime:
    """Get current UTC timestamp."""
    return datetime.now(timezone.utc)


class OntologyObject(BaseModel):
    """
    Base class for all Ontology Objects (Domain Entities).
    
    Provides:
    - Primary Key (id): String-based UUID
    - Audit Fields: created_at, updated_at, created_by, updated_by
    - Lifecycle Status: active, archived, deleted
    - Version: Optimistic locking support
    
    All domain entities (Task, Agent, Proposal, etc.) inherit from this class.
    
    Example:
        ```python
        class Task(OntologyObject):
            title: str
            priority: str = "medium"
            assigned_to_id: Optional[str] = None  # FK to Agent
        ```
    """
    
    # Primary Key
    id: str = Field(
        default_factory=generate_object_id,
        description="Primary Key (UUIDv4 string)",
        json_schema_extra={"immutable": True}
    )
    
    # Audit Fields
    created_at: datetime = Field(
        default_factory=utc_now,
        description="Creation timestamp (UTC)"
    )
    updated_at: datetime = Field(
        default_factory=utc_now,
        description="Last update timestamp (UTC)"
    )
    created_by: Optional[str] = Field(
        default=None,
        description="ID of the user/agent who created this object"
    )
    updated_by: Optional[str] = Field(
        default=None,
        description="ID of the user/agent who last updated this object"
    )
    
    # Lifecycle
    status: ObjectStatus = Field(
        default=ObjectStatus.ACTIVE,
        description="Object lifecycle status"
    )
    
    # Optimistic Locking
    version: int = Field(
        default=1,
        description="Version number for optimistic locking",
        ge=1
    )
    
    class Config:
        """Pydantic configuration."""
        use_enum_values = False  # Keep Enum objects, not raw values
        validate_assignment = True  # Validate on attribute assignment
        extra = "forbid"  # Reject unknown fields
    
    def touch(self, updated_by: Optional[str] = None) -> None:
        """
        Update the modification timestamp and optionally the modifier.
        Call this before any update operation.
        """
        self.updated_at = utc_now()
        self.version += 1
        if updated_by:
            self.updated_by = updated_by
    
    def soft_delete(self, deleted_by: Optional[str] = None) -> None:
        """
        Soft delete the object (set status to DELETED).
        Preferred over hard deletion for audit compliance.
        """
        self.status = ObjectStatus.DELETED
        self.touch(updated_by=deleted_by)
    
    def archive(self, archived_by: Optional[str] = None) -> None:
        """Archive the object (set status to ARCHIVED)."""
        self.status = ObjectStatus.ARCHIVED
        self.touch(updated_by=archived_by)
    
    @property
    def is_active(self) -> bool:
        """Check if the object is in active status."""
        return self.status == ObjectStatus.ACTIVE


# =============================================================================
# TYPE ALIASES FOR CONVENIENCE
# =============================================================================

ObjectId = str
LinkTypeId = str
PropertyName = str

# For type hints in Link definitions
if TYPE_CHECKING:
    from scripts.ontology.objects.core_definitions import Agent, Task
    from scripts.ontology.objects.proposal import Proposal


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/plan.py
# ========================================================
# generated by datamodel-codegen:
#   filename:  plan.schema.json

from __future__ import annotations

from datetime import datetime
from typing import List, Optional, Dict, Any

from pydantic import BaseModel, Field

from .job import Job


class Plan(BaseModel):
    id: str = Field(..., description='Unique Plan UUID')
    type: Optional[str] = Field('Plan', description='Type discriminator')
    created_at: Optional[datetime] = None
    meta_version: Optional[int] = Field(1, description='Metadata version')
    plan_id: str = Field(..., description='User-facing Plan ID')
    objective: str = Field(..., description='High-level objective')
    ontology_impact: Optional[List[str]] = Field(
        [], description='Impacted Ontology Concepts'
    )
    jobs: List[Job] = Field(..., description='List of executable jobs')
    
    # Research Enforcement
    research_context: Optional[Dict[str, Any]] = Field(
        default_factory=dict, 
        description='Mandatory Preliminary Research Findings (Knowledge Cutoff Mitigation)'
    )


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/side_effects.py
# ========================================================

from abc import ABC, abstractmethod
from typing import Any, Dict

class SideEffect(ABC):
    """
    Abstract Base Class for Side Effects (Webhooks, Notifications).
    Executed ONLY after successful Ontology Edits.
    """
    @abstractmethod
    def execute(self, context: Dict[str, Any]):
        pass

class NotificationEffect(SideEffect):
    """
    Sends a notification (Toast/Slack/Email).
    """
    def __init__(self, recipient_id: str, message_template: str):
        self.recipient_id = recipient_id
        self.message_template = message_template

    def execute(self, context: Dict[str, Any]):
        msg = self.message_template.format(**context)
        print(f"[Notification] To {self.recipient_id}: {msg}")

class WebhookEffect(SideEffect):
    """
    Triggers an external Webhook.
    """
    def __init__(self, url: str, method: str = "POST"):
        self.url = url
        self.method = method

    def execute(self, context: Dict[str, Any]):
        print(f"[Webhook] {self.method} {self.url} with {context}")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/trace.py
# ========================================================
# generated by datamodel-codegen:
#   filename:  trace.schema.json

from __future__ import annotations

from enum import Enum
from typing import List, Optional

from pydantic import BaseModel, Field


class Status(Enum):
    """
    Current status of the trace.
    """

    RUNNING = 'RUNNING'
    COMPLETED = 'COMPLETED'
    FAILED = 'FAILED'


class Trace(BaseModel):
    """
    Represents a logical execution flow (Chain of Thought).
    """
    id: str = Field(..., description='Unique Queryable ID of the trace')
    task_id: str = Field(..., description='ID of the Task this trace belongs to.')
    start_time: str = Field(..., description='ISO 8601 timestamp.')
    end_time: Optional[str] = Field(None, description='ISO 8601 timestamp.')
    status: Status = Field(..., description='Current status of the trace.')
    tags: Optional[List[str]] = Field(
        None, description="Tags for filtering (e.g., 'refactor', 'bugfix')."
    )


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/objects/core_definitions.py
# ========================================================
"""
Orion ODA v3.0 - Core Object Definitions
Domain Entities for the Orchestrator.
"""

from __future__ import annotations

from typing import ClassVar, List, Optional, Any, Dict

from pydantic import Field

from scripts.ontology.ontology_types import (
    OntologyObject,
    Link,
    Cardinality,
)
from scripts.ontology.actions import (
    ActionType,
    register_action,
    RequiredField,
    AllowedValues,
    MaxLength,
    EditType,
    EditOperation,
    ActionContext,
    LogSideEffect,
)


# =============================================================================
# OBJECT TYPES
# =============================================================================

class Agent(OntologyObject):
    """
    ObjectType: Agent
    Represents an AI Persona.
    """
    name: str = Field(..., description="Display Name of the Agent")
    model: str = Field(..., description="LLM Model Identity")
    capabilities: List[str] = Field(default_factory=list)
    
    # Links
    # assigned_tasks: Link[Task] - Defined on Task side as Reverse link


class Task(OntologyObject):
    """
    ObjectType: Task
    Represents a unit of work.
    """
    title: str = Field(..., description="Task Title")
    description: str = Field(default="", description="Detailed Description")
    status: str = Field(default="pending", description="Workflow Status")
    priority: str = Field(default="medium", description="Execution Priority")
    
    # Foreign Keys
    assigned_to_id: Optional[str] = Field(None, description="FK to Agent")
    parent_id: Optional[str] = Field(None, description="FK to Parent Task")
    
    # Link Definitions
    assigned_to: ClassVar[Link["Agent"]] = Link(
        target=Agent,
        link_type_id="task_assigned_to_agent",
        cardinality=Cardinality.MANY_TO_ONE,
        description="The agent responsible for this task"
    )
    
    parent_task: ClassVar[Link["Task"]] = Link(
        target="Task",  # Self-reference string
        link_type_id="task_parent",
        cardinality=Cardinality.MANY_TO_ONE,
        description="Parent task"
    )


class Artifact(OntologyObject):
    """
    ObjectType: Artifact
    Represents a File or Document produced by a Task.
    """
    path: str = Field(..., description="Absolute File Path")
    type: str = Field(..., description="File Type (code, doc, log)")
    
    # Foreign Keys
    produced_by_task_id: str = Field(..., description="FK to Task")
    
    # Link Definitions
    produced_by_task: ClassVar[Link[Task]] = Link(
        target=Task,
        link_type_id="artifact_produced_by_task",
        cardinality=Cardinality.MANY_TO_ONE,
        description="The task that produced this artifact"
    )


# =============================================================================
# ACTIONS
# =============================================================================

@register_action
class CreateTaskAction(ActionType[Task]):
    api_name = "create_task"
    object_type = Task
    
    submission_criteria = [
        RequiredField("title"),
        AllowedValues("priority", ["low", "medium", "high"]),
        MaxLength("title", 255),
    ]
    
    side_effects = [LogSideEffect()]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[Optional[Task], List[EditOperation]]:
        task = Task(
            title=params["title"],
            description=params.get("description", ""),
            priority=params.get("priority", "medium"),
            created_by=context.actor_id,
        )
        
        edit = EditOperation(
            edit_type=EditType.CREATE,
            object_type="Task",
            object_id=task.id,
            changes=params,
        )
        
        return task, [edit]


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/objects/proposal.py
# ========================================================
"""
Orion ODA v3.0 - Proposal Governance Object
Palantir AIP/Foundry Compliant Governance Workflow

This module implements the Proposal object for human-in-the-loop governance.
High-stakes actions require explicit approval before execution.

State Machine:
    DRAFT → PENDING → APPROVED → EXECUTED
                   ↘ REJECTED (terminal)

All state transitions are validated and audited.
"""

from __future__ import annotations

from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Set

from pydantic import Field, field_validator, model_validator

# Import from refactored ontology_types (A5)
from scripts.ontology.ontology_types import OntologyObject, utc_now


# =============================================================================
# EXCEPTIONS
# =============================================================================

class ProposalError(Exception):
    """Base exception for Proposal-related errors."""
    pass


class InvalidTransitionError(ProposalError):
    """Raised when an invalid state transition is attempted."""
    
    def __init__(self, current_status: str, target_status: str, allowed: List[str]):
        self.current_status = current_status
        self.target_status = target_status
        self.allowed = allowed
        super().__init__(
            f"Invalid transition: {current_status} → {target_status}. "
            f"Allowed transitions: {allowed}"
        )


class ProposalAlreadyProcessedError(ProposalError):
    """Raised when trying to modify an already-processed proposal."""
    pass


# =============================================================================
# ENUMS
# =============================================================================

class ProposalStatus(str, Enum):
    """
    Proposal lifecycle states.
    
    - DRAFT: Initial state, can be edited
    - PENDING: Submitted for review, awaiting approval
    - APPROVED: Approved by reviewer, ready for execution
    - REJECTED: Rejected by reviewer (terminal state)
    - EXECUTED: Successfully executed (terminal state)
    - CANCELLED: Cancelled by creator before review (terminal state)
    """
    DRAFT = "draft"
    PENDING = "pending"
    APPROVED = "approved"
    REJECTED = "rejected"
    EXECUTED = "executed"
    CANCELLED = "cancelled"
    DELETED = "deleted"


class ProposalPriority(str, Enum):
    """Priority levels for proposal review ordering."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


# =============================================================================
# STATE MACHINE
# =============================================================================

# Valid state transitions map
# Key: Current state, Value: Set of allowed target states
VALID_TRANSITIONS: Dict[ProposalStatus, Set[ProposalStatus]] = {
    ProposalStatus.DRAFT: {
        ProposalStatus.PENDING,
        ProposalStatus.CANCELLED,
        ProposalStatus.DELETED,
    },
    ProposalStatus.PENDING: {
        ProposalStatus.APPROVED,
        ProposalStatus.REJECTED,
        ProposalStatus.CANCELLED,
        ProposalStatus.DELETED,
    },
    ProposalStatus.APPROVED: {
        ProposalStatus.EXECUTED,
        ProposalStatus.CANCELLED,  # Can cancel before execution
        ProposalStatus.DELETED,
    },
    ProposalStatus.REJECTED: {ProposalStatus.DELETED},  # Terminal state
    ProposalStatus.EXECUTED: {ProposalStatus.DELETED},  # Terminal state
    ProposalStatus.CANCELLED: {ProposalStatus.DELETED},  # Terminal state
    ProposalStatus.DELETED: set(),
}

# Terminal states (no further transitions allowed)
TERMINAL_STATES: Set[ProposalStatus] = {
    ProposalStatus.REJECTED,
    ProposalStatus.EXECUTED,
    ProposalStatus.CANCELLED,
    ProposalStatus.DELETED,
}


# =============================================================================
# PROPOSAL OBJECT
# =============================================================================

class Proposal(OntologyObject):
    """
    Represents a staged Action awaiting Human Review.
    
    A Proposal encapsulates:
    - The action to be performed (action_type + payload)
    - The creator (created_by from OntologyObject)
    - The reviewer (reviewed_by)
    - Full audit trail (timestamps, comments)
    
    Usage:
        ```python
        # Create a proposal
        proposal = Proposal(
            action_type="deploy_to_production",
            payload={"service": "checkout", "version": "2.1.0"},
            created_by="agent-001",
            priority=ProposalPriority.HIGH
        )
        
        # Submit for review
        proposal.submit()
        
        # Approve (by human reviewer)
        proposal.approve(reviewer_id="admin-001", comment="LGTM")
        
        # Execute
        proposal.execute()
        ```
    
    Attributes:
        action_type: The ActionType API name to execute
        payload: Parameters for the action
        status: Current lifecycle state
        priority: Review priority
        reviewed_by: ID of the reviewer
        reviewed_at: Timestamp of review decision
        review_comment: Reviewer's comment
        executed_at: Timestamp of execution
        execution_result: Result of execution (success/error details)
    """
    
    # Action Definition
    action_type: str = Field(
        ...,
        description="The ActionType API name to execute (e.g., 'deploy_to_production')",
        min_length=1,
        max_length=255
    )
    payload: Dict[str, Any] = Field(
        default_factory=dict,
        description="Parameters for the action"
    )
    
    # Lifecycle State
    status: ProposalStatus = Field(
        default=ProposalStatus.DRAFT,
        description="Current lifecycle state"
    )
    priority: ProposalPriority = Field(
        default=ProposalPriority.MEDIUM,
        description="Review priority"
    )
    
    # Review Fields
    reviewed_by: Optional[str] = Field(
        default=None,
        description="ID of the reviewer who approved/rejected"
    )
    reviewed_at: Optional[datetime] = Field(
        default=None,
        description="Timestamp of review decision"
    )
    review_comment: Optional[str] = Field(
        default=None,
        description="Reviewer's comment or reason",
        max_length=2000
    )
    
    # Execution Fields
    executed_at: Optional[datetime] = Field(
        default=None,
        description="Timestamp of execution"
    )
    execution_result: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Result of execution (success/error details)"
    )
    
    # Metadata
    tags: List[str] = Field(
        default_factory=list,
        description="Tags for categorization and filtering"
    )
    
    # ==========================================================================
    # VALIDATORS
    # ==========================================================================
    
    @field_validator("action_type")
    @classmethod
    def validate_action_type(cls, v: str) -> str:
        """Ensure action_type follows snake_case convention."""
        if not v.replace("_", "").isalnum():
            raise ValueError(
                f"action_type must be snake_case alphanumeric: {v}"
            )
        return v.lower()
    
    # ==========================================================================
    # STATE MACHINE METHODS
    # ==========================================================================
    
    def _validate_transition(self, target_status: ProposalStatus) -> None:
        """
        Validate that the transition to target_status is allowed.
        
        Raises:
            InvalidTransitionError: If transition is not allowed
        """
        allowed = VALID_TRANSITIONS.get(self.status, set())
        if target_status not in allowed:
            raise InvalidTransitionError(
                current_status=self.status.value,
                target_status=target_status.value,
                allowed=[s.value for s in allowed]
            )
    
    def _transition_to(
        self,
        target_status: ProposalStatus,
        actor_id: Optional[str] = None
    ) -> None:
        """
        Execute a state transition with validation and audit.
        
        Args:
            target_status: The target state
            actor_id: ID of the user/agent performing the transition
        """
        self._validate_transition(target_status)
        self.status = target_status
        self.touch(updated_by=actor_id)
    
    @property
    def is_terminal(self) -> bool:
        """Check if the proposal is in a terminal state."""
        return self.status in TERMINAL_STATES
    
    @property
    def is_pending_review(self) -> bool:
        """Check if the proposal is awaiting review."""
        return self.status == ProposalStatus.PENDING
    
    @property
    def can_execute(self) -> bool:
        """Check if the proposal can be executed."""
        return self.status == ProposalStatus.APPROVED
    
    # ==========================================================================
    # LIFECYCLE METHODS
    # ==========================================================================
    
    def submit(self, submitter_id: Optional[str] = None) -> "Proposal":
        """
        Submit the proposal for review.
        
        Transitions: DRAFT → PENDING
        
        Args:
            submitter_id: ID of the submitter (defaults to created_by)
        
        Returns:
            self for method chaining
        
        Raises:
            InvalidTransitionError: If not in DRAFT state
        """
        self._transition_to(
            ProposalStatus.PENDING,
            actor_id=submitter_id or self.created_by
        )
        return self
    
    def approve(
        self,
        reviewer_id: str,
        comment: Optional[str] = None
    ) -> "Proposal":
        """
        Approve the proposal.
        
        Transitions: PENDING → APPROVED
        
        Args:
            reviewer_id: ID of the reviewer (required)
            comment: Optional approval comment
        
        Returns:
            self for method chaining
        
        Raises:
            InvalidTransitionError: If not in PENDING state
            ValueError: If reviewer_id is not provided
        """
        if not reviewer_id:
            raise ValueError("reviewer_id is required for approval")
        
        self._transition_to(ProposalStatus.APPROVED, actor_id=reviewer_id)
        self.reviewed_by = reviewer_id
        self.reviewed_at = utc_now()
        self.review_comment = comment
        return self
    
    def reject(
        self,
        reviewer_id: str,
        reason: str
    ) -> "Proposal":
        """
        Reject the proposal.
        
        Transitions: PENDING → REJECTED (terminal)
        
        Args:
            reviewer_id: ID of the reviewer (required)
            reason: Rejection reason (required)
        
        Returns:
            self for method chaining
        
        Raises:
            InvalidTransitionError: If not in PENDING state
            ValueError: If reviewer_id or reason is not provided
        """
        if not reviewer_id:
            raise ValueError("reviewer_id is required for rejection")
        if not reason:
            raise ValueError("reason is required for rejection")
        
        self._transition_to(ProposalStatus.REJECTED, actor_id=reviewer_id)
        self.reviewed_by = reviewer_id
        self.reviewed_at = utc_now()
        self.review_comment = reason
        return self
    
    def execute(
        self,
        executor_id: Optional[str] = None,
        result: Optional[Dict[str, Any]] = None
    ) -> "Proposal":
        """
        Mark the proposal as executed.
        
        Transitions: APPROVED → EXECUTED (terminal)
        
        Note: This method only marks the status. Actual action execution
        should be handled by the ActionService.
        
        Args:
            executor_id: ID of the executor (defaults to created_by)
            result: Execution result details
        
        Returns:
            self for method chaining
        
        Raises:
            InvalidTransitionError: If not in APPROVED state
        """
        self._transition_to(
            ProposalStatus.EXECUTED,
            actor_id=executor_id or self.created_by
        )
        self.executed_at = utc_now()
        self.execution_result = result
        return self
    
    def cancel(
        self,
        canceller_id: str,
        reason: Optional[str] = None
    ) -> "Proposal":
        """
        Cancel the proposal.
        
        Transitions: DRAFT/PENDING/APPROVED → CANCELLED (terminal)
        
        Args:
            canceller_id: ID of the person cancelling
            reason: Optional cancellation reason
        
        Returns:
            self for method chaining
        
        Raises:
            InvalidTransitionError: If in terminal state
        """
        if not canceller_id:
            raise ValueError("canceller_id is required for cancellation")
        
        self._transition_to(ProposalStatus.CANCELLED, actor_id=canceller_id)
        self.review_comment = f"[CANCELLED] {reason}" if reason else "[CANCELLED]"
        return self
    
    # ==========================================================================
    # UTILITY METHODS
    # ==========================================================================
    
    def to_audit_log(self) -> Dict[str, Any]:
        """
        Generate an audit log entry for this proposal.
        
        Returns:
            Dictionary suitable for logging/storage
        """
        return {
            "proposal_id": self.id,
            "action_type": self.action_type,
            "status": self.status.value,
            "priority": self.priority.value,
            "created_by": self.created_by,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "reviewed_by": self.reviewed_by,
            "reviewed_at": self.reviewed_at.isoformat() if self.reviewed_at else None,
            "review_comment": self.review_comment,
            "executed_at": self.executed_at.isoformat() if self.executed_at else None,
            "version": self.version,
        }
    
    def __repr__(self) -> str:
        return (
            f"Proposal(id={self.id[:8]}..., "
            f"action={self.action_type}, "
            f"status={self.status.value}, "
            f"priority={self.priority.value})"
        )


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/objects/proposal.py.bak
# ========================================================

from typing import List, Optional, Dict, Any
from pydantic import Field
from scripts.ontology.ontology_types import BaseObject, Link

class Proposal(BaseObject):
    """
    ObjectType: Proposal
    Represents a staged Action waiting for Human Review.
    """
    action_type: str = Field(..., description="The API Name of the Action to execute")
    parameters_json: str = Field(..., description="Serialized JSON of Action Parameters")
    status: str = Field(default="pending", description="pending | approved | rejected | executed")
    
    # Link: Proposal -> Agent (Creator)
    created_by_id: str = Field(..., description="FK to Agent who proposed this")
    
    # Link: Proposal -> Agent (Reviewer)
    reviewed_by_id: Optional[str] = Field(None, description="FK to Agent who reviewed")

    _title_key = "action_type"


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/objects/task_actions.py
# ========================================================
"""
ODA V3.0 - Task Domain ActionTypes
==================================

This module defines all ActionTypes for Task object operations:
- CreateTaskAction: Create new tasks
- UpdateTaskAction: Modify existing tasks
- DeleteTaskAction: Soft-delete tasks (requires proposal)
- AssignTaskAction: Assign tasks to agents
- UnassignTaskAction: Remove task assignments
- CompleteTaskAction: Mark tasks as completed
- ArchiveTaskAction: Archive completed tasks
- BulkCreateTasksAction: Create multiple tasks atomically

All hazardous operations (Delete, BulkCreate) require Proposal approval.
"""

from __future__ import annotations

import re
from datetime import datetime, timezone
from enum import Enum
from typing import Any, ClassVar, Dict, List, Optional, Type

from pydantic import BaseModel, Field

from scripts.ontology.ontology_types import (
    Cardinality,
    Link,
    ObjectStatus,
    OntologyObject,
    utc_now,
)
from scripts.ontology.actions import (
    ActionContext,
    ActionResult,
    ActionType,
    AllowedValues,
    CustomValidator,
    EditOperation,
    EditType,
    LogSideEffect,
    MaxLength,
    RequiredField,
    SlackNotification,
    ValidationError,
    WebhookSideEffect,
    register_action,
)


# =============================================================================
# DOMAIN ENUMS
# =============================================================================

class TaskPriority(str, Enum):
    """Task priority levels."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class TaskStatus(str, Enum):
    """Task lifecycle status."""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    BLOCKED = "blocked"
    COMPLETED = "completed"
    CANCELLED = "cancelled"


# =============================================================================
# DOMAIN OBJECTS
# =============================================================================

class Agent(OntologyObject):
    """
    Represents an AI Agent or Human User in the system.
    
    Agents can be assigned to tasks and execute actions.
    """
    name: str = Field(..., min_length=1, max_length=100)
    email: Optional[str] = Field(default=None, max_length=255)
    role: str = Field(default="agent", max_length=50)
    is_active: bool = Field(default=True)
    capabilities: List[str] = Field(default_factory=list)
    
    # Computed property for display
    @property
    def display_name(self) -> str:
        return f"{self.name} ({self.role})"


class Task(OntologyObject):
    """
    Represents a unit of work in the system.
    
    Tasks can be assigned to agents, have priorities, and track progress.
    Links:
    - assigned_to: Agent (Many-to-One)
    - depends_on: Task[] (Many-to-Many, self-referential)
    - subtasks: Task[] (One-to-Many, self-referential)
    """
    # Required fields
    title: str = Field(..., min_length=1, max_length=255)
    
    # Optional fields
    description: str = Field(default="", max_length=5000)
    priority: TaskPriority = Field(default=TaskPriority.MEDIUM)
    task_status: TaskStatus = Field(default=TaskStatus.PENDING)
    
    # Foreign keys (stored as IDs)
    assigned_to_id: Optional[str] = Field(default=None)
    parent_task_id: Optional[str] = Field(default=None)
    
    # Metadata
    tags: List[str] = Field(default_factory=list)
    estimated_hours: Optional[float] = Field(default=None, ge=0)
    actual_hours: Optional[float] = Field(default=None, ge=0)
    due_date: Optional[datetime] = Field(default=None)
    completed_at: Optional[datetime] = Field(default=None)
    
    # Link definitions (class-level)
    assigned_to: ClassVar[Link[Agent]] = Link(
        target=Agent,
        link_type_id="task_assigned_to_agent",
        cardinality=Cardinality.MANY_TO_ONE,
        reverse_link_id="agent_assigned_tasks",
        description="The agent responsible for this task"
    )
    
    depends_on: ClassVar[Link["Task"]] = Link(
        target="Task",  # Self-referential
        link_type_id="task_depends_on_task",
        cardinality=Cardinality.MANY_TO_MANY,
        reverse_link_id="task_blocks",
        description="Tasks that must be completed before this task"
    )
    
    subtasks: ClassVar[Link["Task"]] = Link(
        target="Task",
        link_type_id="task_has_subtask",
        cardinality=Cardinality.ONE_TO_MANY,
        reverse_link_id="subtask_of",
        description="Child tasks of this task"
    )
    
    @property
    def is_overdue(self) -> bool:
        """Check if task is past due date."""
        if self.due_date and self.task_status not in (TaskStatus.COMPLETED, TaskStatus.CANCELLED):
            return datetime.now(timezone.utc) > self.due_date
        return False
    
    @property
    def is_completed(self) -> bool:
        """Check if task is completed."""
        return self.task_status == TaskStatus.COMPLETED


# =============================================================================
# CUSTOM VALIDATORS
# =============================================================================

def validate_semver(params: Dict[str, Any], context: ActionContext) -> bool:
    """Validate semantic version format (X.Y.Z)."""
    version = params.get("version", "")
    return bool(re.match(r"^\d+\.\d+\.\d+$", version))


def validate_email(params: Dict[str, Any], context: ActionContext) -> bool:
    """Validate email format."""
    email = params.get("email")
    if email is None:
        return True  # Optional field
    return bool(re.match(r"^[^@]+@[^@]+\.[^@]+$", email))


def validate_future_date(params: Dict[str, Any], context: ActionContext) -> bool:
    """Validate due_date is in the future."""
    due_date = params.get("due_date")
    if due_date is None:
        return True
    if isinstance(due_date, str):
        due_date = datetime.fromisoformat(due_date.replace("Z", "+00:00"))
    return due_date > datetime.now(timezone.utc)


def validate_positive_hours(params: Dict[str, Any], context: ActionContext) -> bool:
    """Validate estimated_hours is positive if provided."""
    hours = params.get("estimated_hours")
    if hours is None:
        return True
    return hours > 0


# =============================================================================
# TASK ACTIONS
# =============================================================================

@register_action
class CreateTaskAction(ActionType[Task]):
    """
    Create a new Task object.
    
    Required params:
    - title: str (1-255 chars)
    
    Optional params:
    - description: str (max 5000 chars)
    - priority: "low" | "medium" | "high" | "critical"
    - assigned_to_id: str (Agent ID)
    - tags: List[str]
    - estimated_hours: float (positive)
    - due_date: datetime (ISO format, must be future)
    """
    api_name: ClassVar[str] = "create_task"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = False
    
    submission_criteria: ClassVar[list] = [
        RequiredField("title"),
        MaxLength("title", 255),
        MaxLength("description", 5000),
        AllowedValues("priority", ["low", "medium", "high", "critical"]),
        CustomValidator(
            name="FutureDueDate",
            validator_fn=validate_future_date,
            error_message="due_date must be in the future"
        ),
        CustomValidator(
            name="PositiveHours",
            validator_fn=validate_positive_hours,
            error_message="estimated_hours must be positive"
        ),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[Task, List[EditOperation]]:
        """Create a new Task with the provided parameters."""
        # Parse priority enum
        priority = params.get("priority", "medium")
        if isinstance(priority, str):
            priority = TaskPriority(priority)
        
        # Parse due_date if string
        due_date = params.get("due_date")
        if isinstance(due_date, str):
            due_date = datetime.fromisoformat(due_date.replace("Z", "+00:00"))
        
        task = Task(
            title=params["title"],
            description=params.get("description", ""),
            priority=priority,
            assigned_to_id=params.get("assigned_to_id"),
            tags=params.get("tags", []),
            estimated_hours=params.get("estimated_hours"),
            due_date=due_date,
            created_by=context.actor_id,
        )
        
        edit = EditOperation(
            edit_type=EditType.CREATE,
            object_type="Task",
            object_id=task.id,
            changes=params,
        )
        
        return task, [edit]


@register_action
class UpdateTaskAction(ActionType[Task]):
    """
    Update an existing Task.
    
    Required params:
    - task_id: str (existing Task ID)
    
    Optional params (at least one required):
    - title: str
    - description: str
    - priority: str
    - tags: List[str]
    - estimated_hours: float
    - due_date: datetime
    """
    api_name: ClassVar[str] = "update_task"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = False
    
    submission_criteria: ClassVar[list] = [
        RequiredField("task_id"),
        MaxLength("title", 255),
        MaxLength("description", 5000),
        AllowedValues("priority", ["low", "medium", "high", "critical"]),
        CustomValidator(
            name="HasChanges",
            validator_fn=lambda p, c: any(
                k in p for k in ["title", "description", "priority", "tags", "estimated_hours", "due_date"]
            ),
            error_message="At least one field must be updated"
        ),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Apply updates to an existing Task."""
        task_id = params["task_id"]
        
        # Build changes dict (only provided fields)
        changes = {}
        for field in ["title", "description", "priority", "tags", "estimated_hours", "due_date"]:
            if field in params:
                changes[field] = params[field]
        
        edit = EditOperation(
            edit_type=EditType.MODIFY,
            object_type="Task",
            object_id=task_id,
            changes=changes,
        )
        
        return None, [edit]


@register_action
class DeleteTaskAction(ActionType[Task]):
    """
    Soft-delete a Task (HAZARDOUS - requires Proposal).
    
    Required params:
    - task_id: str (existing Task ID)
    - reason: str (deletion reason for audit)
    """
    api_name: ClassVar[str] = "delete_task"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = True  # ⚠️ HAZARDOUS
    
    submission_criteria: ClassVar[list] = [
        RequiredField("task_id"),
        RequiredField("reason"),
        MaxLength("reason", 500),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
        SlackNotification(channel="#task-deletions"),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Soft-delete the Task."""
        edit = EditOperation(
            edit_type=EditType.DELETE,
            object_type="Task",
            object_id=params["task_id"],
            changes={
                "status": ObjectStatus.DELETED.value,
                "deletion_reason": params["reason"],
                "deleted_by": context.actor_id,
            },
        )
        
        return None, [edit]


@register_action
class AssignTaskAction(ActionType[Task]):
    """
    Assign a Task to an Agent.
    
    Required params:
    - task_id: str
    - agent_id: str
    """
    api_name: ClassVar[str] = "assign_task"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = False
    
    submission_criteria: ClassVar[list] = [
        RequiredField("task_id"),
        RequiredField("agent_id"),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
        SlackNotification(channel="#task-assignments"),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Assign the Task to an Agent."""
        edits = [
            # Update Task's assigned_to_id
            EditOperation(
                edit_type=EditType.MODIFY,
                object_type="Task",
                object_id=params["task_id"],
                changes={"assigned_to_id": params["agent_id"]},
            ),
            # Create Link record
            EditOperation(
                edit_type=EditType.LINK,
                object_type="TaskAgentLink",
                object_id=f"{params['task_id']}_{params['agent_id']}",
                changes={
                    "source_id": params["task_id"],
                    "target_id": params["agent_id"],
                    "link_type": "task_assigned_to_agent",
                },
            ),
        ]
        
        return None, edits


@register_action
class UnassignTaskAction(ActionType[Task]):
    """
    Remove Agent assignment from a Task.
    
    Required params:
    - task_id: str
    """
    api_name: ClassVar[str] = "unassign_task"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = False
    
    submission_criteria: ClassVar[list] = [
        RequiredField("task_id"),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Remove assignment from Task."""
        edits = [
            EditOperation(
                edit_type=EditType.MODIFY,
                object_type="Task",
                object_id=params["task_id"],
                changes={"assigned_to_id": None},
            ),
            EditOperation(
                edit_type=EditType.UNLINK,
                object_type="TaskAgentLink",
                object_id=params["task_id"],
                changes={"link_type": "task_assigned_to_agent"},
            ),
        ]
        
        return None, edits


@register_action
class CompleteTaskAction(ActionType[Task]):
    """
    Mark a Task as completed.
    
    Required params:
    - task_id: str
    
    Optional params:
    - actual_hours: float (time spent)
    - completion_notes: str
    """
    api_name: ClassVar[str] = "complete_task"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = False
    
    submission_criteria: ClassVar[list] = [
        RequiredField("task_id"),
        CustomValidator(
            name="PositiveActualHours",
            validator_fn=lambda p, c: p.get("actual_hours", 1) > 0,
            error_message="actual_hours must be positive"
        ),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
        SlackNotification(channel="#task-completions"),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Mark Task as completed."""
        changes = {
            "task_status": TaskStatus.COMPLETED.value,
            "completed_at": utc_now().isoformat(),
            "completed_by": context.actor_id,
        }
        
        if "actual_hours" in params:
            changes["actual_hours"] = params["actual_hours"]
        if "completion_notes" in params:
            changes["completion_notes"] = params["completion_notes"]
        
        edit = EditOperation(
            edit_type=EditType.MODIFY,
            object_type="Task",
            object_id=params["task_id"],
            changes=changes,
        )
        
        return None, [edit]


@register_action
class ArchiveTaskAction(ActionType[Task]):
    """
    Archive a completed Task.
    
    Required params:
    - task_id: str
    """
    api_name: ClassVar[str] = "archive_task"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = False
    
    submission_criteria: ClassVar[list] = [
        RequiredField("task_id"),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Archive the Task."""
        edit = EditOperation(
            edit_type=EditType.MODIFY,
            object_type="Task",
            object_id=params["task_id"],
            changes={
                "status": ObjectStatus.ARCHIVED.value,
                "archived_at": utc_now().isoformat(),
                "archived_by": context.actor_id,
            },
        )
        
        return None, [edit]


@register_action
class BulkCreateTasksAction(ActionType[Task]):
    """
    Create multiple Tasks atomically (HAZARDOUS - requires Proposal).
    
    Required params:
    - tasks: List[Dict] - each dict must have "title"
    
    Optional per-task params:
    - description, priority, tags, etc.
    """
    api_name: ClassVar[str] = "bulk_create_tasks"
    object_type: ClassVar[Type[Task]] = Task
    requires_proposal: ClassVar[bool] = True  # ⚠️ HAZARDOUS
    
    submission_criteria: ClassVar[list] = [
        RequiredField("tasks"),
        CustomValidator(
            name="TasksNotEmpty",
            validator_fn=lambda p, c: len(p.get("tasks", [])) > 0,
            error_message="tasks list cannot be empty"
        ),
        CustomValidator(
            name="MaxBulkSize",
            validator_fn=lambda p, c: len(p.get("tasks", [])) <= 100,
            error_message="Cannot create more than 100 tasks at once"
        ),
        CustomValidator(
            name="AllTasksHaveTitle",
            validator_fn=lambda p, c: all(
                t.get("title") for t in p.get("tasks", [])
            ),
            error_message="All tasks must have a title"
        ),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
        SlackNotification(channel="#bulk-operations"),
        WebhookSideEffect(url="https://analytics.example.com/bulk-create"),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Create multiple Tasks."""
        edits = []
        
        for task_data in params["tasks"]:
            priority = task_data.get("priority", "medium")
            if isinstance(priority, str):
                priority = TaskPriority(priority)
            
            task = Task(
                title=task_data["title"],
                description=task_data.get("description", ""),
                priority=priority,
                tags=task_data.get("tags", []),
                created_by=context.actor_id,
            )
            
            edits.append(EditOperation(
                edit_type=EditType.CREATE,
                object_type="Task",
                object_id=task.id,
                changes=task_data,
            ))
        
        return None, edits


# =============================================================================
# AGENT ACTIONS
# =============================================================================

@register_action
class CreateAgentAction(ActionType[Agent]):
    """
    Create a new Agent.
    
    Required params:
    - name: str (1-100 chars)
    
    Optional params:
    - email: str (valid email format)
    - role: str (default: "agent")
    - capabilities: List[str]
    """
    api_name: ClassVar[str] = "create_agent"
    object_type: ClassVar[Type[Agent]] = Agent
    requires_proposal: ClassVar[bool] = False
    
    submission_criteria: ClassVar[list] = [
        RequiredField("name"),
        MaxLength("name", 100),
        MaxLength("email", 255),
        CustomValidator(
            name="ValidEmail",
            validator_fn=validate_email,
            error_message="Invalid email format"
        ),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[Agent, List[EditOperation]]:
        """Create a new Agent."""
        agent = Agent(
            name=params["name"],
            email=params.get("email"),
            role=params.get("role", "agent"),
            capabilities=params.get("capabilities", []),
            created_by=context.actor_id,
        )
        
        edit = EditOperation(
            edit_type=EditType.CREATE,
            object_type="Agent",
            object_id=agent.id,
            changes=params,
        )
        
        return agent, [edit]


@register_action
class DeactivateAgentAction(ActionType[Agent]):
    """
    Deactivate an Agent (HAZARDOUS - requires Proposal).
    
    Required params:
    - agent_id: str
    - reason: str
    """
    api_name: ClassVar[str] = "deactivate_agent"
    object_type: ClassVar[Type[Agent]] = Agent
    requires_proposal: ClassVar[bool] = True  # ⚠️ HAZARDOUS
    
    submission_criteria: ClassVar[list] = [
        RequiredField("agent_id"),
        RequiredField("reason"),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
        SlackNotification(channel="#agent-management"),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Deactivate the Agent."""
        edit = EditOperation(
            edit_type=EditType.MODIFY,
            object_type="Agent",
            object_id=params["agent_id"],
            changes={
                "is_active": False,
                "deactivated_at": utc_now().isoformat(),
                "deactivation_reason": params["reason"],
                "deactivated_by": context.actor_id,
            },
        )
        
        return None, [edit]


# =============================================================================
# DEPLOYMENT ACTIONS (INFRASTRUCTURE)
# =============================================================================

@register_action
class DeployServiceAction(ActionType[OntologyObject]):
    """
    Deploy a service to production (HAZARDOUS - requires Proposal).
    
    Required params:
    - service_name: str
    - version: str (semver format: X.Y.Z)
    - environment: "staging" | "production"
    
    Optional params:
    - rollback_version: str (version to rollback to on failure)
    - notify_channels: List[str]
    """
    api_name: ClassVar[str] = "deploy_service"
    object_type: ClassVar[Type[OntologyObject]] = OntologyObject
    requires_proposal: ClassVar[bool] = True  # ⚠️ HAZARDOUS
    
    submission_criteria: ClassVar[list] = [
        RequiredField("service_name"),
        RequiredField("version"),
        RequiredField("environment"),
        AllowedValues("environment", ["staging", "production"]),
        CustomValidator(
            name="SemverFormat",
            validator_fn=validate_semver,
            error_message="version must be semver format (X.Y.Z)"
        ),
    ]
    
    side_effects: ClassVar[list] = [
        LogSideEffect(),
        SlackNotification(channel="#deployments"),
        WebhookSideEffect(url="https://deploy.example.com/webhook"),
    ]
    
    async def apply_edits(
        self,
        params: Dict[str, Any],
        context: ActionContext
    ) -> tuple[None, List[EditOperation]]:
        """Record the deployment."""
        deployment_id = f"deploy-{params['service_name']}-{params['version']}"
        
        edit = EditOperation(
            edit_type=EditType.CREATE,
            object_type="Deployment",
            object_id=deployment_id,
            changes={
                "service_name": params["service_name"],
                "version": params["version"],
                "environment": params["environment"],
                "deployed_by": context.actor_id,
                "deployed_at": utc_now().isoformat(),
                "rollback_version": params.get("rollback_version"),
            },
        )
        
        return None, [edit]


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/relays/__init__.py
# ========================================================


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/relays/archive_oda_v2.py
# ========================================================
#!/usr/bin/env python3
import sys
import os

# Ensure project root is in path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.schemas.memory import OrionInsight, OrionPattern, InsightContent, InsightProvenance, PatternStructure
from scripts.ontology.manager import ObjectManager

def main():
    manager = ObjectManager()
    
    # 1. Archive the "Self-Driving ODA" Pattern
    oda_pattern = OrionPattern(
        structure=PatternStructure(
            trigger="Header # ODA_PHASE: 2. Execution (Relay)",
            steps=[
                "Agent recognizes 'ODA_PHASE' header in Handoff artifact",
                "Agent executes the Objective within the context",
                "Agent generates 'result_job_{id}.py' using Mandatory Relay Protocol",
                "Orchestrator consolidates result via ObjectManager"
            ],
            anti_patterns=[
                "Manual unstructured reporting via chat",
                "Editing files without generating a Result Checksum"
            ]
        ),
        frequency_count=1,
        success_rate=1.0,
        code_snippet_ref="scripts/ontology/handoff.py"
    )
    manager.save(oda_pattern)
    print(f"✅ Archived Pattern: Self-Driving ODA ({oda_pattern.id})")

    # 2. Archive the "RSI" Insight
    rsi_insight = OrionInsight(
        content=InsightContent(
            summary="Recursive Self-Improvement (RSI) is triggered by JobResult(status='FAILURE')",
            domain="Orchestration",
            tags=["RSI", "Error-Handling", "Cognitive-Loop"]
        ),
        provenance=InsightProvenance(
            method="Session Refactoring",
            source_episodic_ids=["session-2025-12-13-optimization"]
        ),
        confidence_score=0.9
    )
    manager.save(rsi_insight)
    print(f"✅ Archived Insight: RSI Logic ({rsi_insight.id})")

if __name__ == "__main__":
    main()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/relays/result_job_job-test-01.py
# ========================================================
#!/usr/bin/env python3
import sys
import shutil
import subprocess

# Ensure project root is in path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.schemas.result import JobResult
from scripts.ontology.manager import ObjectManager


def main() -> None:
    checked_path = "/home/palantir"

    try:
        df_output = subprocess.check_output(["df", "-h"], text=True)
    except Exception as e:
        df_output = f"df -h failed: {e}"

    total, used, free = shutil.disk_usage(checked_path)
    free_gb = free / (1024**3)

    status = "SUCCESS" if free_gb > 10 else "FAILURE"

    result = JobResult(
        job_id="job-test-01",
        status=status,
        output_artifacts=[],
        metrics={
            "checked_path": checked_path,
            "free_bytes": free,
            "free_gb": round(free_gb, 2),
            "df_h": df_output,
        },
    )

    manager = ObjectManager()
    manager.save(result)
    print(f"✅ Job {result.job_id} Result Committed ({result.status}).")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"❌ Verification Failed: {e}")
        sys.exit(1)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/jobs/cleanup.py
# ========================================================
"""
Orion ODA v3.0 - Proposal Cleanup Job
=====================================

Background job to maintain database hygiene by archiving/deleting
stale proposals.

Policy:
- EXECUTED/REJECTED/CANCELLED proposals > 30 days old are hard deleted.
- DELETED proposals > 7 days old are hard deleted.
"""

import asyncio
import logging
from datetime import datetime, timedelta, timezone

from scripts.ontology.objects.proposal import ProposalStatus
from scripts.ontology.storage import ProposalRepository, initialize_database
from scripts.ontology.ontology_types import utc_now

logger = logging.getLogger(__name__)

class ProposalCleanupJob:
    """
    Periodically cleans up old proposals.
    """
    
    def __init__(self, repo: ProposalRepository):
        self.repo = repo
        
    async def run(self, retention_days_terminal: int = 30, retention_days_deleted: int = 7):
        """
        Execute the cleanup logic.
        
        Args:
            retention_days_terminal: Days to keep terminal states (Executed, Rejected, Cancelled)
            retention_days_deleted: Days to keep soft-deleted items
        """
        logger.info("Starting Proposal Cleanup Job...")
        
        # 1. Clean up Terminal States
        cutoff_terminal = utc_now() - timedelta(days=retention_days_terminal)
        terminal_statuses = [
            ProposalStatus.EXECUTED,
            ProposalStatus.REJECTED,
            ProposalStatus.CANCELLED
        ]
        
        count_terminal = await self.repo.delete_expired(
            older_than=cutoff_terminal,
            statuses=terminal_statuses
        )
        logger.info(f"Deleted {count_terminal} terminal proposals older than {retention_days_terminal} days.")
        
        # 2. Clean up Soft Deleted
        cutoff_deleted = utc_now() - timedelta(days=retention_days_deleted)
        count_deleted = await self.repo.delete_expired(
            older_than=cutoff_deleted,
            statuses=[ProposalStatus.DELETED]
        )
        logger.info(f"Deleted {count_deleted} soft-deleted proposals older than {retention_days_deleted} days.")
        
        return {
            "terminal_deleted": count_terminal,
            "soft_deleted": count_deleted
        }

async def main():
    logging.basicConfig(level=logging.INFO)
    db = await initialize_database()
    repo = ProposalRepository(db)
    job = ProposalCleanupJob(repo)
    
    await job.run()

if __name__ == "__main__":
    asyncio.run(main())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/tests/test_core.py
# ========================================================

import sys
import os

# Add workspace to path
sys.path.append(os.getcwd())

from scripts.ontology.core import OrionObject
from scripts.ontology.manager import ObjectManager
from pydantic import Field

# Define a Test Object
class TestServer(OrionObject):
    name: str
    status: str = "Active"
    region: str = "us-east-1"
    cpu_usage: float = 0.0

def run_test():
    print("=== STARTING PHASE 1 SELF-VERIFICATION ===")
    
    # 1. Initialize Manager
    om = ObjectManager()
    om.register_type(TestServer)
    print("[PASS] ObjectManager Initialized")

    # 2. Create Object (InMemory)
    server = TestServer(name="Alpha-One")
    print(f"[INFO] Created Object: {server.id} (Dirty: {server.is_dirty()})")
    
    # Assert Defaults
    assert server.status == "Active"
    assert server.version == 1
    
    # 3. Save to DB (Insert)
    om.save(server)
    print("[PASS] Object Saved to SQLite")
    assert server.is_dirty() == False, "Object should be clean after save"

    # 4. Modify Object (Dirty Tracking)
    server.status = "Down" # Trigger setter
    assert server.is_dirty() == True, "Object should be dirty after modification"
    print(f"[PASS] Dirty Tracking Detected Change: {server.get_changes()}")

    # 5. Save Updates (Update)
    om.save(server)
    assert server.version == 2, "Version should increment on update"
    print("[PASS] Object Updated in SQLite")

    # 6. Load from DB (Hydration)
    om.default_session.expire_all() # Clear cache to force SQL fetch
    
    loaded_server = om.get(TestServer, server.id)
    assert loaded_server is not None
    assert loaded_server.id == server.id
    assert loaded_server.status == "Down"
    assert loaded_server.name == "Alpha-One"
    assert loaded_server.version == 2
    print(f"[PASS] Object Hydrated Correctly: {loaded_server.status}")

    # 7. Validation of 'Living' nature
    # Standard Pydantic behavior + Identity
    try:
        loaded_server.cpu_usage = "High" # Should fail type check if validate_assignment works
    except Exception as e:
        print(f"[PASS] Type Safety Confirmed: {e}")

    print("=== PHASE 1 VERIFICATION COMPLETED SUCCESSFULLY ===")

if __name__ == "__main__":
    try:
        run_test()
    except Exception as e:
        print(f"!!! FAILURE !!! {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/tests/test_fts.py
# ========================================================

import sys
import sqlite3
from scripts.ontology.manager import ObjectManager
from scripts.ontology.db import DB_PATH
from scripts.ontology.schemas.memory import OrionInsight, OrionPattern

def run_test():
    print("=== STARTING PHASE 4 FTS VERIFICATION ===")
    
    om = ObjectManager()
    om.register_type(OrionInsight)
    om.register_type(OrionPattern)
    
    # 1. Connect to DB Raw
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    
    # 2. Check FTS Content Count
    # We FTS-indexed everything via save()
    # Note: 'objects' table uses 'fts_content' column directly?
    # No, 'objects' table is a normal table.
    # Did we create an FTS Virtual Table?
    # Phase 1 DB plan said "Universal Object Table".
    # Phase 2 Added 'fts_content' column to 'objects'.
    # This column allows standard LIKE or FTS5 explicit indexing.
    # To use FTS5 properly, we usually need a virtual table.
    # BUT for now, we just verify the COLUMN is populated.
    
    cur.execute("SELECT id, type, fts_content FROM objects WHERE type IN ('OrionInsight', 'OrionPattern') AND fts_content IS NOT NULL LIMIT 5")
    rows = cur.fetchall()
    
    print(f"[Info] Found {len(rows)} rows with FTS content populated.")
    assert len(rows) > 0, "No FTS content found! Migration failed to index?"
    
    for r in rows:
        oid, otype, content = r
        print(f"[Inspect] ID={oid} Type={otype} Content_Len={len(content)}")
        # print(f"Content: {content}")
        assert len(content) > 10, "FTS Content too short"

    # 3. Retrieve Object via Manager
    test_id = rows[0][0]
    test_type_str = rows[0][1]
    
    # Map string type to class
    type_cls = OrionInsight if test_type_str == "OrionInsight" else OrionPattern
    
    obj = om.get(type_cls, test_id)
    assert obj is not None, "Failed to hydrating migrated object"
    assert obj.id == test_id
    print(f"[PASS] Hydrated {obj.__class__.__name__} {obj.id}")
    
    print("=== PHASE 4 FTS VERIFICATION COMPLETED ===")

if __name__ == "__main__":
    try:
        run_test()
    except Exception as e:
        print(f"!!! FAILURE !!! {e}")
        sys.exit(1)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/storage/__init__.py
# ========================================================
"""ODA V3.0 Storage Layer."""
from scripts.ontology.storage.database import (
    Database,
    get_database,
    initialize_database,
)
from scripts.ontology.storage.proposal_repository import (
    ProposalRepository,
    ProposalQuery,
    PaginatedResult,
    ProposalNotFoundError,
    OptimisticLockError,
)

__all__ = [
    "Database",
    "get_database",
    "initialize_database",
    "ProposalRepository",
    "ProposalQuery",
    "PaginatedResult",
    "ProposalNotFoundError",
    "OptimisticLockError",
]


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/storage/database.py
# ========================================================

"""
Orion ODA V3.0 - Database Connection Manager (Async SQLAlchemy)
============================================================
Provides SQLAlchemy Async Engine and Session Factory.

Key Features:
- **Async Engine**: Non-blocking I/O with `aiosqlite`.
- **WAL Mode**: Enforced via event listeners for high concurrency.
- **Session Management**: Async context manager for transactional scope.
- **Schema Initialization**: Auto-recreates tables via `Base.metadata`.
"""

from __future__ import annotations

import logging
from contextlib import asynccontextmanager
from pathlib import Path
from typing import AsyncGenerator

from sqlalchemy import event, text
from sqlalchemy.ext.asyncio import (
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)
from sqlalchemy.engine import Engine

# Import Base for schema creation
from scripts.ontology.storage.models import Base
from scripts.ontology.storage.orm import AsyncOntologyObject 

logger = logging.getLogger(__name__)

# Enforce WAL Mode on SQLite Connection
@event.listens_for(Engine, "connect")
def set_sqlite_pragma(dbapi_connection, connection_record):
    cursor = dbapi_connection.cursor()
    cursor.execute("PRAGMA journal_mode=WAL")
    cursor.execute("PRAGMA synchronous=NORMAL")
    cursor.close()

class Database:
    """
    SQLAlchemy Async Database Manager.
    Does NOT use manual SQL migrations anymore; relies on ORM Metadata.
    """
    
    def __init__(self, url: str | Path):
        # Convert path to async sqlite url if needed
        if isinstance(url, Path) or (isinstance(url, str) and not url.startswith("sqlite")):
             self.url = f"sqlite+aiosqlite:///{url}"
        else:
             self.url = url
             
        self.engine: AsyncEngine = create_async_engine(
            self.url,
            echo=False,  # Set to True for SQL debugging
            future=True
        )
        
        self.session_factory = async_sessionmaker(
            bind=self.engine,
            expire_on_commit=False,
            class_=AsyncSession
        )
        self._initialized = False

    async def initialize(self) -> None:
        """Create tables if they don't exist."""
        if self._initialized: return
        
        async with self.engine.begin() as conn:
            # In production, use Alembic. For ODA V3 Prototype, create_all is acceptable.
            await conn.run_sync(Base.metadata.create_all)
            
        logger.info(f"Database Schema Initialized at {self.url}")
        self._initialized = True

    @asynccontextmanager
    async def transaction(self) -> AsyncGenerator[AsyncSession, None]:
        """
        Transactional Scope.
        Commits on exit, Rolls back on exception.
        """
        async with self.session_factory() as session:
            try:
                yield session
                await session.commit()
            except Exception:
                await session.rollback()
                raise
            finally:
                await session.close()

    async def health_check(self) -> bool:
        try:
             async with self.transaction() as session:
                 await session.execute(text("SELECT 1"))
             return True
        except Exception as e:
            logger.error(f"Health Check Failed: {e}")
            return False

# Global Helper
async def initialize_database(path: Path | str | None = None) -> Database:
    p = path or "/home/palantir/orion-orchestrator-v2/data/ontology.db"
    db = Database(p)
    await db.initialize()
    return db


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/storage/models.py
# ========================================================

from sqlalchemy import String, JSON, DateTime
from sqlalchemy.orm import Mapped, mapped_column

from .orm import AsyncOntologyObject

class ProposalModel(AsyncOntologyObject):
    """
    SQLAlchemy Model for Proposals.
    Maps 1:1 with scripts.ontology.objects.proposal.Proposal
    """
    __tablename__ = "proposals"

    # Core Action Data
    action_type: Mapped[str] = mapped_column(String, nullable=False)
    payload: Mapped[dict] = mapped_column(JSON, default=dict)  # Stores job parameters
    priority: Mapped[str] = mapped_column(String, default="medium")
    
    # Review Audit Data
    reviewed_by: Mapped[Optional[str]] = mapped_column(String, nullable=True)
    reviewed_at: Mapped[Optional[datetime]] = mapped_column(DateTime(timezone=True), nullable=True)
    review_comment: Mapped[Optional[str]] = mapped_column(String, nullable=True)
    
    # Execution Audit Data (for traceability)
    executor_id: Mapped[Optional[str]] = mapped_column(String, nullable=True)
    executed_at: Mapped[Optional[datetime]] = mapped_column(DateTime(timezone=True), nullable=True)
    execution_result: Mapped[Optional[dict]] = mapped_column(JSON, nullable=True)

    def __repr__(self):
        return f"<Proposal(id={self.id}, action={self.action_type}, status={self.status}, v={self.version})>"


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/storage/orm.py
# ========================================================
"""
Orion ODA V3 - Async ORM Foundation
====================================
Implements SQLAlchemy 2.0 Declarative Base with Optimistic Locking.

Design Principles:
1.  **Async First**: Inherits from `AsyncAttrs` to support `await object.awaitable_attrs.relationship`.
2.  **Concurrency Safety**: Enforces `version_id_col` for hardware-level atomic CAS (Compare-And-Swap) logic via SQL WHERE clauses.
3.  **Identity Unifiction**: Replaces the Pydantic-only `OntologyObject` for persistence scenarios, while maintaining compatibility via DTOs.
"""

from __future__ import annotations

import uuid
from datetime import datetime, timezone
from typing import Optional

from sqlalchemy import String, Integer, DateTime
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
from sqlalchemy.ext.asyncio import AsyncAttrs

def utc_now() -> datetime:
    """Get current UTC timestamp."""
    return datetime.now(timezone.utc)

def generate_uuid() -> str:
    """Generate UUIDv4 string."""
    return str(uuid.uuid4())

class Base(AsyncAttrs, DeclarativeBase):
    """
    SQLAlchemy 2.0 Async Base Class.
    """
    pass

class AsyncOntologyObject(Base):
    """
    Base Persistence Model for all ODA Objects.
    
    Features:
    - UUIDv4 Primary Key
    - Audit Timestamps (created_at, updated_at)
    - Optimistic Locking (version)
    """
    __abstract__ = True
    
    # Primary Key
    id: Mapped[str] = mapped_column(
        String, 
        primary_key=True, 
        default=generate_uuid
    )
    
    # Optimistic Locking
    # SQLAlchemy will automatically check 'version' on UPDATE
    # and raise StaleDataError if it doesn't match.
    version: Mapped[int] = mapped_column(Integer, default=1, nullable=False)
    
    # Audit Fields
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), 
        default=utc_now,
        nullable=False
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), 
        default=utc_now, 
        onupdate=utc_now, 
        nullable=False
    )
    created_by: Mapped[Optional[str]] = mapped_column(String, nullable=True)
    updated_by: Mapped[Optional[str]] = mapped_column(String, nullable=True)
    
    # Object Status (as String enum for storage simplicity)
    status: Mapped[str] = mapped_column(String, default="active", nullable=False)

    __mapper_args__ = {
        "version_id_col": version
    }
    
    def touch(self):
        """
        Manually trigger update timestamp.
        Note: version increment is handled automatically by SQLAlchemy.
        """
        self.updated_at = utc_now()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/storage/proposal_repository.py
# ========================================================

"""
Orion ODA V3 - Async Proposal Repository
=========================================
Implements the Persistence Layer using SQLAlchemy 2.0 Async ORM.

Key Features:
- **Async I/O**: Non-blocking database operations.
- **Optimistic Locking**: Handled transparently by `AsyncOntologyObject`.
- **Domain Mapping**: Translates ORM `ProposalModel` <-> Domain `Proposal`.
"""

from __future__ import annotations

import logging
from typing import List, Optional, Tuple, Dict, Any

from sqlalchemy import select, update, delete
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm.exc import StaleDataError

from scripts.ontology.objects.proposal import Proposal, ProposalStatus, ProposalPriority
from scripts.ontology.storage.models import ProposalModel
from scripts.ontology.storage.database import Database

logger = logging.getLogger(__name__)

class ProposalNotFoundError(Exception):
    pass

class ConcurrencyError(Exception):
    pass

class ProposalRepository:
    """
    Persistence Layer for Proposal Objects using SQLAlchemy Async ORM.
    """
    
    def __init__(self, db: Database):
        self.db = db

    def _to_domain(self, model: ProposalModel) -> Proposal:
        """Convert ORM Model to Domain Object."""
        # Note: We reconstruct the Domain object.
        # Ideally, Domain Object SHOULD inherit from ORM Model if we unify them fully.
        # For now, we map manually to keep Domain clean of SQL dependencies if desired,
        # OR we can make Proposal inherit ProposalModel (Hybrid).
        # Given "Identity Unification" goal, let's map data for now to start safe.
        
        p = Proposal(
            id=model.id,
            created_at=model.created_at,
            updated_at=model.updated_at,
            created_by=model.created_by,
            updated_by=model.updated_by,
            status=ProposalStatus(model.status),
            version=model.version,
            
            action_type=model.action_type,
            payload=model.payload or {},
            priority=ProposalPriority(model.priority),
            
            reviewed_by=model.reviewed_by,
            reviewed_at=model.reviewed_at,
            review_comment=model.review_comment,
            executed_at=model.executed_at,
            # execution_result logic if needed in domain
        )
        return p

    async def save(self, proposal: Proposal, actor_id: str = "system") -> None:
        """
        Save a proposal (Create or Update).
        Handles Optimistic Locking via StaleDataError.
        """
        async with self.db.transaction() as session:
            if not proposal.version or proposal.version == 1:
                # Create
                model = ProposalModel(
                    id=proposal.id,
                    created_by=proposal.created_by or actor_id,
                    updated_by=actor_id,
                    status=proposal.status.value,
                    action_type=proposal.action_type,
                    payload=proposal.payload,
                    priority=proposal.priority.value,
                    version=1
                )
                session.add(model)
            else:
                # Update
                # We fetch first to ensure it's attached, or use update() stmt
                # Using merge/update for explicit version check
                stmt = (
                    update(ProposalModel)
                    .where(ProposalModel.id == proposal.id)
                    .where(ProposalModel.version == proposal.version)
                    .values(
                        status=proposal.status.value,
                        payload=proposal.payload,
                        priority=proposal.priority.value,
                        updated_at=proposal.updated_at,
                        updated_by=actor_id,
                        # ... map other fields ... 
                    )
                    .execution_options(synchronize_session="fetch")
                )
                result = await session.execute(stmt)
                if result.rowcount == 0:
                    raise ConcurrencyError(f"Proposal {proposal.id} modified by another user.")
                
                # Increment local version to match DB
                proposal.version += 1

    async def find_by_id(self, proposal_id: str) -> Optional[Proposal]:
        async with self.db.transaction() as session:
            stmt = select(ProposalModel).where(ProposalModel.id == proposal_id)
            result = await session.execute(stmt)
            model = result.scalar_one_or_none()
            if not model:
                return None
            return self._to_domain(model)

    async def find_by_status(self, status: ProposalStatus) -> List[Proposal]:
        async with self.db.transaction() as session:
            stmt = select(ProposalModel).where(ProposalModel.status == status.value)
            result = await session.execute(stmt)
            models = result.scalars().all()
            return [self._to_domain(m) for m in models]

    async def find_pending(self) -> List[Proposal]:
        return await self.find_by_status(ProposalStatus.PENDING)

    async def approve(self, proposal_id: str, reviewer_id: str, comment: str = None) -> None:
        """Approve a proposal (Direct DB Update for efficiency)."""
        async with self.db.transaction() as session:
            # 1. Fetch current version
            stmt = select(ProposalModel).where(ProposalModel.id == proposal_id)
            result = await session.execute(stmt)
            model = result.scalar_one_or_none()
            if not model:
                raise ProposalNotFoundError(f"Proposal {proposal_id} not found")

            # 2. Update via ORM (automatically checks version if configured, specific check below)
            # Since we fetched 'model', we can just modify it and flush.
            # However, for explicit optimistic locking in high concurrency, let's use UPDATE stmt with WHERE version
            
            stmt = (
                update(ProposalModel)
                .where(ProposalModel.id == proposal_id)
                .where(ProposalModel.version == model.version) # Explicit Lock
                .values(
                    status=ProposalStatus.APPROVED.value,
                    reviewed_by=reviewer_id,
                    reviewed_at=utc_now(),
                    review_comment=comment,
                    updated_by=reviewer_id
                    # version increment handled by SQLAlchemy or Model default logic if we defined listener
                    # But since we do raw UPDATE here, we might need to increment manually or rely on ORM mechanics
                )
            )
            result = await session.execute(stmt)
            if result.rowcount == 0:
                 raise ConcurrencyError(f"Proposal {proposal_id} modified during approval.")

    async def reject(self, proposal_id: str, reviewer_id: str, reason: str) -> None:
        async with self.db.transaction() as session:
            stmt = select(ProposalModel).where(ProposalModel.id == proposal_id)
            result = await session.execute(stmt)
            model = result.scalar_one_or_none()
            if not model:
                raise ProposalNotFoundError(f"Proposal {proposal_id} not found")

            stmt = (
                update(ProposalModel)
                .where(ProposalModel.id == proposal_id)
                .where(ProposalModel.version == model.version)
                .values(
                    status=ProposalStatus.REJECTED.value,
                    reviewed_by=reviewer_id,
                    reviewed_at=utc_now(),
                    review_comment=reason,
                    updated_by=reviewer_id
                )
            )
            result = await session.execute(stmt)
            if result.rowcount == 0:
                 raise ConcurrencyError("Concurrency conflict during rejection")

    async def execute(self, proposal_id: str, executor_id: str, result: Dict[str, Any]) -> None:
        async with self.db.transaction() as session:
            stmt = select(ProposalModel).where(ProposalModel.id == proposal_id)
            orm_res = await session.execute(stmt)
            model = orm_res.scalar_one_or_none()
            if not model:
                raise ProposalNotFoundError(proposal_id)

            stmt = (
                update(ProposalModel)
                .where(ProposalModel.id == proposal_id)
                .where(ProposalModel.version == model.version)
                .values(
                    status=ProposalStatus.EXECUTED.value,
                    executed_at=utc_now(),
                    execution_result=result,
                    updated_by=executor_id
                )
            )
            update_res = await session.execute(stmt)
            if update_res.rowcount == 0:
                 raise ConcurrencyError("Concurrency conflict during execution")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/schemas/__init__.py
# ========================================================

# Init


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/schemas/governance.py
# ========================================================

from typing import Dict, Any, List, Optional
from datetime import datetime
from pydantic import Field
from scripts.ontology.core import OrionObject

class OrionActionLog(OrionObject):
    """
    Immutable Audit Record for Kinetic Actions.
    """
    # Context
    agent_id: str = "Orion-Kernel" # Default Identity
    trace_id: Optional[str] = None # Job ID / Plan ID
    
    # Intent
    action_type: str
    parameters: Dict[str, Any] = Field(default_factory=dict)
    
    # Outcome
    status: str # SUCCESS, FAILURE, ROLLED_BACK
    error: Optional[str] = None
    
    # Impact
    affected_ids: List[str] = Field(default_factory=list)
    
    # Meta
    duration_ms: int = 0
    
    def get_searchable_text(self) -> str:
        return f"{self.action_type} {self.status} {self.error or ''}"


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/schemas/memory.py
# ========================================================

from typing import List, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from scripts.ontology.core import OrionObject

# --- INSIGHT ---

class InsightContent(BaseModel):
    summary: str
    domain: str
    tags: List[str] = Field(default_factory=list)

class InsightProvenance(BaseModel):
    source_episodic_ids: List[str] = Field(default_factory=list)
    method: str

class OrionInsight(OrionObject):
    """
    An atomic unit of declarative knowledge.
    Replaces legacy JSON schema.
    """
    confidence_score: float = Field(1.0, ge=0.0, le=1.0)
    decay_factor: Optional[float] = None
    
    provenance: InsightProvenance
    content: InsightContent
    
    # Relations flattened from legacy 'relations' object
    supports: List[str] = Field(default_factory=list)
    contradicts: List[str] = Field(default_factory=list)
    related_to: List[str] = Field(default_factory=list)

    def get_searchable_text(self) -> str:
        """Override for better semantic search."""
        return f"{self.content.summary} {self.content.domain} {' '.join(self.content.tags)}"

# --- PATTERN ---

class PatternStructure(BaseModel):
    trigger: str
    steps: List[str]
    anti_patterns: List[str] = Field(default_factory=list)

class OrionPattern(OrionObject):
    """
    A reusable procedural workflow.
    Replaces legacy JSON schema.
    """
    frequency_count: int = 0
    success_rate: float = Field(0.0, ge=0.0, le=1.0)
    last_used: Optional[datetime] = None
    
    structure: PatternStructure
    code_snippet_ref: Optional[str] = None
    
    def get_searchable_text(self) -> str:
        """Override for better semantic search."""
        return f"{self.structure.trigger} {' '.join(self.structure.steps)}"


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/ontology/schemas/result.py
# ========================================================
from typing import List, Optional, Dict, Any, Literal
from pydantic import BaseModel, Field
from scripts.ontology.core import OrionObject

class Artifact(BaseModel):
    """
    Represents a tangible output produced by a Job.
    """
    path: str = Field(..., description="Absolute path to the artifact")
    description: str = Field(..., description="Description of what this artifact is")
    mime_type: Optional[str] = Field(None, description="MIME type if known")
    checksum: Optional[str] = Field(None, description="Optional SHA256 checksum for integrity")

class JobResult(OrionObject):
    """
    Formal contract for returning work from an external agent back to the Ontology.
    Captured via 'result_job_{id}.py'.
    """
    job_id: str = Field(..., description="The ID of the Job this result belongs to")
    status: Literal["SUCCESS", "FAILURE", "BLOCKED"] = Field(..., description="Execution Status")
    output_artifacts: List[Artifact] = Field(default_factory=list, description="List of files produced")
    metrics: Dict[str, Any] = Field(default_factory=dict, description="Quantitative results (e.g. coverage, latency)")
    # 'evidence' or 'reasoning' could also be added, but relying on base fields for now.
    
    # We can add methods helper methods here if needed, but keeping it data-centric.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/memory/__init__.py
# ========================================================


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/memory/init_db.py
# ========================================================

import sqlite3
import os
import sys

# Configuration
# Moved to scripts/memory/init_db.py, so root is ../../
WORKSPACE_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
INDEXES_DIR = os.path.join(WORKSPACE_ROOT, ".agent", "indexes")
DB_PATH = os.path.join(INDEXES_DIR, "fts_index.db")
LOGS_DB_PATH = os.path.join(WORKSPACE_ROOT, ".agent", "logs", "ontology.db")

def init_fts_db():
    """Initialize the SQLite FTS5 Inverted Index."""
    os.makedirs(INDEXES_DIR, exist_ok=True)
    
    con = sqlite3.connect(DB_PATH)
    cur = con.cursor()
    
    # 1. Create FTS5 Virtual Table
    # Porter tokenizer for stemming (running -> run)
    print("🛠️  Initializing FTS5 Memory Index...")
    cur.execute("""
        CREATE VIRTUAL TABLE IF NOT EXISTS memory_index USING fts5(
            object_id UNINDEXED,   -- e.g., "INS-7a8b9c"
            file_path UNINDEXED,   -- e.g., "semantic/insights/INS-7a8b9c.json"
            type,                  -- "Insight", "Pattern"
            content,               -- Full text content for indexing
            tags,                  -- Explicit tags
            tokenize='porter unicode61'
        );
    """)
    
    # 2. Verify Table
    cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='memory_index'")
    if cur.fetchone():
        print(f"✅ FTS5 Table 'memory_index' ready in {DB_PATH}")
    else:
        print(f"❌ Failed to create FTS5 table.")
        sys.exit(1)
        
    con.commit()
    con.close()

def init_audit_db():
    """Initialize the Immutable Audit Log."""
    log_dir = os.path.dirname(LOGS_DB_PATH)
    os.makedirs(log_dir, exist_ok=True)
    
    con = sqlite3.connect(LOGS_DB_PATH)
    cur = con.cursor()
    
    # Standard Relational Table for Audit (Matched with scripts/governance.py)
    print("🛠️  Initializing Ontology Audit Log...")
    cur.execute("""
        CREATE TABLE IF NOT EXISTS audit_log (
            id TEXT PRIMARY KEY,
            timestamp TEXT NOT NULL,
            event_type TEXT NOT NULL,
            action_type TEXT NOT NULL,
            action_id TEXT NOT NULL,
            parameters TEXT NOT NULL, -- JSON String
            user TEXT NOT NULL,
            result TEXT, -- JSON String (Updated on commit)
            status TEXT DEFAULT 'PENDING'
        );
    """)
    con.commit()
    print(f"✅ Audit Table 'audit_log' ready in {LOGS_DB_PATH}")
    con.close()

if __name__ == "__main__":
    try:
        init_fts_db()
        init_audit_db()
        print("\n✨ Memory System Storage Layer Initialized Successfully.")
    except Exception as e:
        print(f"\n❌ Initialization Failed: {e}")
        sys.exit(1)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/memory/manager.py
# ========================================================

import os
import sys
import json
import sqlite3
import re
import jsonschema
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

# --- Libraries ---
try:
    import sqlite_vec
    from fastembed import TextEmbedding
    VECTOR_SUPPORT = True
except ImportError:
    VECTOR_SUPPORT = False

# --- Configuration ---
WORKSPACE_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(WORKSPACE_ROOT)
AGENT_DIR = os.path.join(WORKSPACE_ROOT, ".agent")
SCHEMAS_DIR = os.path.join(AGENT_DIR, "schemas")
MEMORY_DIR = os.path.join(AGENT_DIR, "memory", "semantic")
INDEXES_DIR = os.path.join(AGENT_DIR, "indexes")
DB_PATH = os.path.join(INDEXES_DIR, "semantic_memory.db")

logger = logging.getLogger("HybridMemoryManager")

class MemoryManager:
    """
    The LMT-Grade Hippocampus of Orion (Hybrid: FTS5 + Vector).
    Features:
    - Keywords: SQLite FTS5
    - Concepts: SQLite-Vec (Vector Embeddings)
    - Model: BAAI/bge-small-en-v1.5 (Fast, Local, 384d)
    """
    
    def __init__(self):
        self.schemas = self._load_schemas()
        self.embedding_model = None
        
        # Initialize Architecture
        os.makedirs(INDEXES_DIR, exist_ok=True)
        self._init_db()
        
        if VECTOR_SUPPORT:
            logger.info("⚡ Loading Neural Core (FastEmbed BGE-Small)...")
            # This triggers download on first run (~100MB)
            self.embedding_model = TextEmbedding(model_name="BAAI/bge-small-en-v1.5")
            logger.info("✅ Neural Core Ready.")
        else:
            logger.warning("⚠️ Vector Dependencies missing. Running in FTS-Only mode.")

    def _load_schemas(self) -> Dict[str, Any]:
        """Load JSON Schemas for validation."""
        schemas = {}
        for name in ["insight", "pattern"]:
            path = os.path.join(SCHEMAS_DIR, f"{name}.schema.json")
            if os.path.exists(path):
                with open(path, 'r') as f:
                    schemas[name] = json.load(f)
        return schemas

    def _get_db(self):
        """Get DB Connection with Vector Extension loaded."""
        con = sqlite3.connect(DB_PATH)
        con.enable_load_extension(True)
        if VECTOR_SUPPORT:
            sqlite_vec.load(con)
        con.enable_load_extension(False)
        return con

    def _init_db(self):
        """Initialize Tables (FTS + Vector)."""
        con = self._get_db()
        cur = con.cursor()
        
        # 1. FTS Table (Keywords)
        cur.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS semantic_fts 
            USING fts5(id, type, content, tags);
        """)
        
        # 2. Vector Table (Embeddings)
        # Using 384 dimensions for BGE-Small
        if VECTOR_SUPPORT:
            cur.execute("""
                CREATE VIRTUAL TABLE IF NOT EXISTS semantic_vec 
                USING vec0(
                    id TEXT PRIMARY KEY,
                    embedding float[384]
                );
            """)
            
        con.commit()
        con.close()

    def validate(self, data: Dict[str, Any], schema_type: str):
        """Strict Validation against strict Pydantic/JSONSchema."""
        if schema_type not in self.schemas:
            # Fallback if schemas missing during bootstrap
            return
        jsonschema.validate(instance=data, schema=self.schemas[schema_type])

    def save_object(self, obj_type: str, data: Dict[str, Any]):
        """
        Atomic Write: Validate -> JSON Save -> Hybrid Indexing.
        """
        # 1. Validation
        self.validate(data, obj_type)
        
        # 2. Determine Path
        obj_id = data.get("id") or data.get("@id")
        if not obj_id:
            raise ValueError("Object missing 'id' field.")
            
        subfolder = "insights" if obj_type == "insight" else "patterns"
        target_dir = os.path.join(MEMORY_DIR, subfolder)
        os.makedirs(target_dir, exist_ok=True)
        file_path = os.path.join(target_dir, f"{obj_id}.json")
        
        # 3. Write JSON (Source of Truth)
        with open(file_path, 'w') as f:
            json.dump(data, f, indent=2)
            
        # 4. Update Indices
        self._update_indices(obj_id, file_path, obj_type, data)
        
        return file_path

    def _update_indices(self, obj_id: str, file_path: str, obj_type: str, data: Dict[str, Any]):
        """Update FTS and Vector Indices."""
        text_content = self._extract_text(obj_type, data)
        tags = ",".join(data.get('content', {}).get('tags', []) if obj_type == 'insight' else [])
        
        con = self._get_db()
        cur = con.cursor()
        
        # A. Upsert FTS
        # FTS5 doesn't support ON CONFLICT, so Delete+Insert
        cur.execute("DELETE FROM semantic_fts WHERE id = ?", (obj_id,))
        cur.execute("""
            INSERT INTO semantic_fts (id, type, content, tags)
            VALUES (?, ?, ?, ?)
        """, (obj_id, obj_type, text_content, tags))
        
        # B. Upsert Vector
        if VECTOR_SUPPORT and self.embedding_model:
            # Generate Embedding (Synchronous for now, fast enough)
            embeddings = list(self.embedding_model.embed([text_content]))
            vector = embeddings[0] # List of floats
            
            # vec0 Upsert
            cur.execute("DELETE FROM semantic_vec WHERE id = ?", (obj_id,))
            cur.execute("""
                INSERT INTO semantic_vec (id, embedding)
                VALUES (?, ?)
            """, (obj_id, json.dumps(vector.tolist()))) # sqlite-vec expects raw bytes or JSON array? Wrapper handles JSON array usually.
            # Wait, sqlite-vec python wrapper? 
            # Actually, standard SQL query for vec0 input is often binary.
            # But the specific python binding `sqlite-vec` usually helps.
            # Re-checking standard usage: `vec_f32` is not needed if passing correct format.
            # Actually, passing a standard List[float] usually works with the python adapter if registered.
            # If not, we pass struct.pack. Let's try standard list serialization first.
            
            # Actually, sqlite-vec documentation says:
            # "parameters typically bound as bytes (little-endian f32s)"
            # Let's use struct just to be safe if direct list fails.
            # But fastembed returns numpy, tolist() gives float list.
            # Let's try passing list. If it fails, I'll fix in V2. 
            pass 

        con.commit()
        con.close()

    def _extract_text(self, obj_type: str, data: Dict[str, Any]) -> str:
        if obj_type == "insight":
            return f"{data['content'].get('summary', '')} {data['content'].get('domain', '')}"
        elif obj_type == "pattern":
            return f"{data.get('trigger', '')} {data.get('outcome', '')}"
        return str(data)

    def search(self, query: str, limit: int = 5, mode: str = "hybrid") -> List[Dict[str, Any]]:
        """
        Hybrid Search: Combines Vector(Deep) + FTS(Wide).
        """
        con = self._get_db()
        cur = con.cursor()
        results = {}

        # 1. Vector Search
        if VECTOR_SUPPORT and mode in ["hybrid", "vector"]:
            try:
                query_vec = list(self.embedding_model.embed([query]))[0]
                # vec_distance_cosine
                cur.execute("""
                    SELECT id, distance
                    FROM semantic_vec
                    WHERE embedding MATCH ?
                    AND k = ?
                    ORDER BY distance
                """, (json.dumps(query_vec.tolist()), limit))
                
                for row in cur.fetchall():
                    rid, dist = row
                    results[rid] = results.get(rid, 0) + (1.0 - dist) # Transform distance to similarity
            except Exception as e:
                logger.error(f"Vector search failed: {e}")

        # 2. FTS Search
        if mode in ["hybrid", "keyword"]:
            try:
                cur.execute("""
                    SELECT id, rank 
                    FROM semantic_fts 
                    WHERE semantic_fts MATCH ? 
                    ORDER BY rank 
                    LIMIT ?
                """, (query, limit))
                
                for row in cur.fetchall():
                    rid, rank = row
                    # Simplify BM25 rank to score 
                    results[rid] = results.get(rid, 0) + 0.5 # Boost
            except Exception as e:
                logger.warning(f"FTS search failed (query likely empty or noise): {e}")

        con.close()
        
        # Sort by Score
        sorted_ids = sorted(results.items(), key=lambda x: x[1], reverse=True)[:limit]
        
        # Hydrate
        final_results = []
        for rid, score in sorted_ids:
            # Load JSON content
            # Try finding file using heuristic (inefficient but safe)
            # Or assume we stored path? We removed path from DB for simplicity.
            # Let's re-scan or assume structure.
            # Ideally DB should store path.
            # Checking V1 implementation... it stored 'path'. I removed it.
            # I should verify existence.
            
            # Simple fallback search
            found_path = None
            for sub in ["insights", "patterns"]:
                 p = os.path.join(MEMORY_DIR, sub, f"{rid}.json")
                 # Also check subfolders
                 if os.path.exists(p): found_path = p; break
                 # Recursive check for insights/domain
                 if sub == "insights":
                     for root, dirs, files in os.walk(os.path.join(MEMORY_DIR, sub)):
                         if f"{rid}.json" in files:
                             found_path = os.path.join(root, f"{rid}.json")
                             break
            
            if found_path:
                with open(found_path, 'r') as f:
                    content = json.load(f)
                    content['score'] = score
                    final_results.append(content)
                    
        return final_results

if __name__ == "__main__":
    # Test Run
    m = MemoryManager()
    print("✅ MemoryManager initialized.")
    if VECTOR_SUPPORT:
        print("🧠 Vector Core Active.")
        # Test Embedding
        vec = list(m.embedding_model.embed(["Hello World"]))[0]
        print(f"   Embedding Test: {len(vec)} dimensions generated.")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/archive/action_registry.py
# ========================================================
import os
import subprocess
import shlex
import urllib.request
import ast
import difflib
import uuid
import jsonschema
import json
from datetime import datetime
from typing import Dict, Any, Callable, List, Optional
from functools import wraps
from pydantic import ValidationError

# Import Ontology Models (Auto-generated)
from scripts.ontology import Action

class ActionRegistry:
    """Singleton registry for all executable Actions in the Orion System."""
    _instance = None
    _actions: Dict[str, Callable] = {}
    _metadata: Dict[str, Action] = {}

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ActionRegistry, cls).__new__(cls)
        return cls._instance

    @classmethod
    def register(cls, name: str, description: str, parameters: Dict[str, Any], permissions: List[str] = None):
        """Decorator to register a function as an Ontology Action."""
        def decorator(func: Callable):
            # 1. Create Ontology Object
            action_obj = Action(
                id=f"action_{name}",
                type="Action",
                created_at=datetime.now().isoformat(),
                meta_version=1,
                name=name,
                description=description,
                parameters=parameters,
                required_permissions=permissions or []
            )
            
            # 2. Store in Registry
            cls._actions[name] = func
            cls._metadata[name] = action_obj
            
            @wraps(func)
            def wrapper(*args, **kwargs):
                # Lazy import to avoid circular dependency
                from scripts.observer import Observer
                from scripts.ontology import Event, EventType
                
                # Runtime Schema Validation
                try:
                    jsonschema.validate(instance=kwargs, schema=parameters)
                except jsonschema.ValidationError as e:
                    raise ValueError(f"Schema Validation Failed for action '{name}': {e.message}")
                
                # 3. Governance: Audit Log (Start)
                try:
                    event_id = str(uuid.uuid4())
                    trace_id = f"action:{name}:{event_id}"
                    Observer.emit(Event(
                        trace_id=trace_id,
                        event_type=EventType.ACTION_START,
                        component="ActionRegistry",
                        details={
                            "action": name,
                            "context": kwargs.get("context", "No justification provided"),
                            "params": {k: str(v) for k, v in kwargs.items() if k != "CodeContent"} # Truncate large content in logs
                        },
                        timestamp=datetime.now().isoformat()
                    ))
                    
                    # 4. Execute
                    result = func(*args, **kwargs)
                    
                    # 5. Governance: Audit Log (Success)
                    Observer.emit(Event(
                        trace_id=trace_id,
                        event_type=EventType.ACTION_END,
                        component="ActionRegistry",
                        details={
                            "action": name,
                            "related_event_id": event_id,
                            "status": "success"
                        },
                        timestamp=datetime.now().isoformat()
                    ))
                    return result

                except Exception as e:
                    # 6. Governance: Audit Log (Failure)
                    Observer.emit(Event(
                        trace_id=trace_id if "trace_id" in locals() else f"action:{name}:unknown",
                        event_type=EventType.ERROR,
                        component="ActionRegistry",
                        details={
                            "action": name,
                            "error": str(e)
                        },
                        timestamp=datetime.now().isoformat()
                    ))
                    raise e
                    
            return wrapper
        return decorator

    @classmethod
    def get_action(cls, name: str) -> Optional[Callable]:
        return cls._actions.get(name)

    @classmethod
    def list_actions(cls) -> List[Action]:
        return list(cls._metadata.values())

# --- Core Actions ---

WORKSPACE_ROOT = os.path.abspath("/home/palantir")

def validate_path(path: str) -> str:
    """Ensure path is within the workspace."""
    abs_path = os.path.abspath(path)
    if not abs_path.startswith(WORKSPACE_ROOT):
        raise ValueError(f"Security Violation: Access denied to {path}")
    return abs_path

@ActionRegistry.register(
    name="read_file",
    description="Read the contents of a file.",
    parameters={
        "type": "object",
        "properties": {
            "path": {"type": "string", "description": "Absolute path to the file"}
        },
        "required": ["path"]
    }
)
def read_file(path: str) -> str:
    safe_path = validate_path(path)
    if not os.path.exists(safe_path):
        raise FileNotFoundError(f"File not found: {safe_path}")
    with open(safe_path, 'r') as f:
        return f.read()

@ActionRegistry.register(
    name="write_to_file",
    description="Write content to a file. Overwrites existing content.",
    parameters={
        "type": "object",
        "properties": {
            "TargetFile": {"type": "string", "description": "Absolute path to the file"},
            "CodeContent": {"type": "string", "description": "Content to write"}
        },
        "required": ["TargetFile", "CodeContent"]
    }
)
def write_to_file(TargetFile: str, CodeContent: str, **kwargs) -> str:
    safe_path = validate_path(TargetFile)
    os.makedirs(os.path.dirname(safe_path), exist_ok=True)
    with open(safe_path, 'w') as f:
        f.write(CodeContent)
    return f"Successfully wrote to {safe_path}"

@ActionRegistry.register(
    name="run_command",
    description="Execute a shell command. RESTRICTED.",
    parameters={
        "type": "object",
        "properties": {
            "CommandLine": {"type": "string", "description": "Shell command to execute"},
            "Cwd": {"type": "string", "description": "Current working directory"}
        },
        "required": ["CommandLine"]
    },
    permissions=["admin"]
)
def run_command(CommandLine: str, Cwd: str = WORKSPACE_ROOT, **kwargs) -> str:
    # Security: Whitelist or strict parsing needed here.
    # For now, we block dangerous commands.
    forbidden = ["rm -rf", "mkfs", "dd", ":(){ :|:& };:"]
    for bad in forbidden:
        if bad in CommandLine:
            raise ValueError(f"Security Violation: Forbidden command '{bad}'")
    
    # Execute
    try:
        # Validate Cwd if provided
        work_dir = WORKSPACE_ROOT
        if Cwd != WORKSPACE_ROOT:
            work_dir = validate_path(Cwd)

        result = subprocess.run(
            CommandLine, 
            shell=True, 
            check=True, 
            capture_output=True, 
            text=True,
            cwd=work_dir
        )
        return result.stdout
    except subprocess.CalledProcessError as e:
        return f"Error: {e.stderr}"

@ActionRegistry.register(
    name="analyze_dependency",
    description="Get list of files that the target file depends on (Imports).",
    parameters={
        "type": "object",
        "properties": {
            "TargetFile": {"type": "string", "description": "Absolute path to the file"}
        },
        "required": ["TargetFile"]
    }
)
def analyze_dependency(TargetFile: str) -> List[str]:
    from scripts.static_analyzer import DependencyAnalyzer
    analyzer = DependencyAnalyzer(WORKSPACE_ROOT)
    analyzer.build_graph()
    return analyzer.get_dependencies(TargetFile)

@ActionRegistry.register(
    name="calculate_impact",
    description="Get list of files that depend on the target file (Reverse Dependency).",
    parameters={
        "type": "object",
        "properties": {
            "TargetFile": {"type": "string", "description": "Absolute path to the file"}
        },
        "required": ["TargetFile"]
    }
)
def calculate_impact(TargetFile: str) -> List[str]:
    from scripts.static_analyzer import DependencyAnalyzer
    analyzer = DependencyAnalyzer(WORKSPACE_ROOT)
    analyzer.build_graph()
    return analyzer.get_impact_set(TargetFile)


# --- Advanced Native Capabilities ---

@ActionRegistry.register(
    name="analyze_code_structure",
    description="Analyze the structure of a Python file (Classes/Functions) using AST.",
    parameters={
        "type": "object",
        "properties": {
            "path": {"type": "string", "description": "Absolute path to the file"}
        },
        "required": ["path"]
    }
)
def analyze_code_structure(path: str) -> Dict[str, Any]:
    """
    Parses a Python file and returns a summary of its classes and functions.
    """
    safe_path = validate_path(path)
    try:
        with open(safe_path, 'r') as f:
            tree = ast.parse(f.read())
        
        structure = {"classes": [], "functions": []}
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                structure["classes"].append({"name": node.name, "methods": methods})
            elif isinstance(node, ast.FunctionDef):
                # Only list top-level functions to avoid duplication with methods
                structure["functions"].append(node.name)
                
        return structure
    except Exception as e:
        return {"error": str(e)}

@ActionRegistry.register(
    name="grep_search",
    description="Search for a pattern in files using grep.",
    parameters={
        "type": "object",
        "properties": {
            "pattern": {"type": "string", "description": "Regex pattern to search"},
            "path": {"type": "string", "description": "Directory or file to search (default: .)"}
        },
        "required": ["pattern"]
    }
)
def grep_search(pattern: str, path: str = ".") -> str:
    """
    Executes a grep search.
    """
    # Security check: prevent command injection
    if any(c in pattern for c in [";", "&", "|", "`", "$"]):
        return "Error: Invalid characters in pattern."
    
    # Validate path if it's not default
    search_path = WORKSPACE_ROOT
    if path != ".":
        search_path = validate_path(path)

    try:
        # Using subprocess for native grep
        result = subprocess.run(
            ["grep", "-r", pattern, search_path],
            capture_output=True,
            text=True,
            cwd=WORKSPACE_ROOT
        )
        if result.returncode == 0:
            return result.stdout[:5000] # Limit output
        else:
            return "No matches found."
    except Exception as e:
        return f"Error: {e}"

@ActionRegistry.register(
    name="fetch_url",
    description="Fetch text content from a URL (Native).",
    parameters={
        "type": "object",
        "properties": {
            "url": {"type": "string", "description": "URL to fetch"}
        },
        "required": ["url"]
    }
)
def fetch_url(url: str) -> str:
    """
    Fetches content from a URL using standard library (urllib).
    """
    try:
        with urllib.request.urlopen(url, timeout=5) as response:
            return response.read().decode('utf-8')[:5000] # Limit size
    except Exception as e:
        return f"Error fetching URL: {e}"

@ActionRegistry.register(
    name="list_processes",
    description="List running processes (Native ps).",
    parameters={
        "type": "object",
        "properties": {},
        "required": []
    }
)
def list_processes() -> str:
    """
    Lists running processes using 'ps -ef'.
    """
    try:
        result = subprocess.run(
            ["ps", "-ef"],
            capture_output=True,
            text=True
        )
        return result.stdout[:5000]
    except Exception as e:
        return f"Error: {e}"

# --- Universal Custom Tools ---

@ActionRegistry.register(
    name="apply_patch",
    description="Replace a specific text block in a file with new content.",
    parameters={
        "type": "object",
        "properties": {
            "path": {"type": "string", "description": "Absolute path to the file"},
            "target": {"type": "string", "description": "Exact text to replace"},
            "replacement": {"type": "string", "description": "New text content"}
        },
        "required": ["path", "target", "replacement"]
    }
)
def apply_patch(path: str, target: str, replacement: str) -> str:
    """
    Surgically replaces a block of text in a file.
    """
    safe_path = validate_path(path)
    if not os.path.exists(safe_path):
        raise FileNotFoundError(f"File not found: {safe_path}")
        
    with open(safe_path, 'r') as f:
        content = f.read()
        
    if target not in content:
        return "Error: Target text not found in file. Patch failed."
        
    # Check for multiple occurrences
    if content.count(target) > 1:
        return "Error: Target text is ambiguous (found multiple times). Provide more context."
        
    new_content = content.replace(target, replacement)
    
    with open(safe_path, 'w') as f:
        f.write(new_content)
        
    return f"Successfully patched {safe_path}"

@ActionRegistry.register(
    name="tree_view",
    description="Show directory structure (respecting .gitignore).",
    parameters={
        "type": "object",
        "properties": {
            "path": {"type": "string", "description": "Root directory (default: workspace root)"},
            "max_depth": {"type": "integer", "description": "Max depth to traverse (default: 2)"}
        },
        "required": []
    }
)
def tree_view(path: str = ".", max_depth: int = 2) -> str:
    """
    Generates a tree-like string of the directory structure.
    """
    root_dir = WORKSPACE_ROOT if path == "." else validate_path(path)
    output = []
    
    # Simple gitignore parser (very basic)
    ignored = {'.git', '__pycache__', '.venv', 'node_modules', '.DS_Store'}
    if os.path.exists(os.path.join(WORKSPACE_ROOT, '.gitignore')):
        with open(os.path.join(WORKSPACE_ROOT, '.gitignore'), 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    ignored.add(line.replace('/', ''))

    for root, dirs, files in os.walk(root_dir):
        # Filter directories
        dirs[:] = [d for d in dirs if d not in ignored]
        
        level = root.replace(root_dir, '').count(os.sep)
        if level > max_depth:
            continue
            
        indent = ' ' * 4 * level
        output.append(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 4 * (level + 1)
        
        # Limit files shown per dir to avoid spam
        for i, f in enumerate(files):
            if f not in ignored:
                if i < 10:
                    output.append(f"{subindent}{f}")
                elif i == 10:
                    output.append(f"{subindent}... (more files)")
                    
    return "\n".join(output)

# --- Visualization & Education Tools ---

@ActionRegistry.register(
    name="visualize_diff",
    description="Generate an HTML diff between a file and new content.",
    parameters={
        "type": "object",
        "properties": {
            "path": {"type": "string", "description": "Absolute path to the file"},
            "new_content": {"type": "string", "description": "Proposed new content"}
        },
        "required": ["path", "new_content"]
    }
)
def visualize_diff(path: str, new_content: str) -> str:
    """
    Generates a side-by-side HTML diff to visualize changes.
    Returns the HTML content as a string.
    """
    safe_path = validate_path(path)
    if not os.path.exists(safe_path):
        old_content = ""
    else:
        with open(safe_path, 'r') as f:
            old_content = f.read()
            
    # Generate HTML Diff
    diff = difflib.HtmlDiff(wrapcolumn=80).make_file(
        old_content.splitlines(),
        new_content.splitlines(),
        fromdesc=f"Current: {os.path.basename(path)}",
        todesc="Proposed Change",
        context=True,
        numlines=5
    )
    return diff

@ActionRegistry.register(
    name="mcp_preflight_antigravity",
    description="Preflight Antigravity MCP config and optionally disable failing servers (mitigates IDE retry loops).",
    parameters={
        "type": "object",
        "properties": {
            "ConfigPath": {"type": "string", "description": "Absolute path to Antigravity mcp_config.json"},
            "AutoDisableFailed": {"type": "boolean", "description": "If true, mark failing servers as disabled"},
            "Write": {"type": "boolean", "description": "If true, write changes back to the config file"},
        },
        "required": []
    }
)
def mcp_preflight_antigravity(
    ConfigPath: str = "/home/palantir/.gemini/antigravity/mcp_config.json",
    AutoDisableFailed: bool = True,
    Write: bool = False,
    **kwargs,
) -> str:
    safe_path = validate_path(ConfigPath)
    if not os.path.exists(safe_path):
        raise FileNotFoundError(f"MCP config not found: {safe_path}")

    from scripts.mcp_preflight import preflight_mcp_config

    result = preflight_mcp_config(
        safe_path,
        auto_disable_failed=AutoDisableFailed,
        write=Write,
    )
    return json.dumps(result, ensure_ascii=False, indent=2)

@ActionRegistry.register(
    name="generate_project_map",
    description="Generate a rich, educational map of the project structure.",
    parameters={
        "type": "object",
        "properties": {
            "path": {"type": "string", "description": "Root directory (default: workspace root)"}
        },
        "required": []
    }
)
def generate_project_map(path: str = ".") -> str:
    """
    Generates a Markdown map with educational descriptions of file types.
    Helps non-developers understand the 'Role' of each file.
    """
    root_dir = WORKSPACE_ROOT if path == "." else validate_path(path)
    output = ["# 🗺️ Project Structure Map", "", "| File/Folder | Type | Educational Note |", "|---|---|---|"]
    
    # Educational Heuristics
    descriptions = {
        ".py": "🐍 Python Script (Logic)",
        ".json": "⚙️ Configuration/Data (Structured)",
        ".md": "📝 Documentation (Read me)",
        ".txt": "📄 Plain Text",
        ".xml": "KX XML Data",
        "scripts": "📂 Automation Tools",
        "tests": "🧪 Quality Assurance (Tests)",
        ".agent": "🤖 AI Agent Memory",
        ".venv": "📦 Python Environment (Libraries)"
    }

    ignored = {'.git', '__pycache__', '.venv', 'node_modules', '.DS_Store', '.gemini'}
    
    for root, dirs, files in os.walk(root_dir):
        dirs[:] = [d for d in dirs if d not in ignored]
        
        # Calculate depth to indent
        rel_path = os.path.relpath(root, root_dir)
        if rel_path == ".":
            level = 0
        else:
            level = rel_path.count(os.sep) + 1
            
        if level > 3: continue # Limit depth
        
        indent = "&nbsp;" * (level * 4)
        folder_name = os.path.basename(root)
        
        # Folder Description
        desc = descriptions.get(folder_name, "📂 Directory")
        if rel_path != ".":
            output.append(f"| {indent}**{folder_name}/** | Folder | {desc} |")
            
        # File Descriptions
        for f in files:
            if f in ignored: continue
            ext = os.path.splitext(f)[1]
            desc = descriptions.get(ext, "📄 File")
            # Special cases
            if f == "actions.py": desc = "⚡ Action Registry (My Hands)"
            if f == "ontology.py": desc = "🧠 Knowledge Schema (My Brain)"
            
            output.append(f"| {indent}{f} | File | {desc} |")
            
    return "\n".join(output)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/archive/engine.py
# ========================================================

import argparse
import sys
import logging
import json
import os
from typing import Optional

# Ensure we can import from core components
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from scripts.action_registry import ActionRegistry, ActionRunner
from scripts.ontology.plan import Plan
from scripts.ontology.job import Job
from scripts.memory.manager import MemoryManager

# --- SETUP LOGGING ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class OrionEngine:
    """
    The Central Nervous System of the Orion Agent.
    Coordinates: Input -> Plan -> Governance -> Action -> Memory.
    """
    
    def __init__(self):
        self.registry = ActionRegistry()
        self.runner = ActionRunner(self.registry)
        self.memory = MemoryManager()
        
    def dispatch_plan(self, plan_path: str):
        """
        Execute a Plan file (JSON) after validating it.
        """
        logger.info(f"🚀 Dispatching Plan from: {plan_path}")
        
        # 1. Load Plan
        try:
            with open(plan_path, 'r') as f:
                plan_data = json.load(f)
            plan = Plan(**plan_data)
        except Exception as e:
            logger.error(f"❌ Plan Loading Failed: {e}")
            return
            
        logger.info(f"📋 Objective: {plan.objective}")
        
        # 2. Governance Check (Placeholder for now)
        # In a real system, we'd check if the plan violates any immutable rules.
        logger.info("✅ Plan Committed to Ontology")
        
        # 3. Execution Loop
        total_jobs = len(plan.jobs)
        for i, job in enumerate(plan.jobs, 1):
            logger.info(f"⚙️ Executing Job [{i}/{total_jobs}]: {job.action_name}")
            
            try:
                result = self.runner.execute(job.action_name, **job.action_args)
                logger.info(f"   Scan Success: {str(result)[:100]}...") # Truncate log
                
                # 4. Memory Injection (Short-term)
                # We could log the result back to an ephemeral memory store here
                
            except Exception as e:
                logger.error(f"   ❌ Job Failed: {e}")
                # Logic: Stop on failure? Or continue? 
                # For now, strict stop.
                return

        logger.info("🏁 All Jobs Completed.")
        
        # --- PHASE 5: MEMORY RECALL (Orion) ---
        # Experimental: Post-execution analysis
        # insights = self.memory.mine_insights_from_plan(plan)
        # log insights...

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Orion Engine Dispatcher")
    subparsers = parser.add_subparsers(dest="command")
    
    # Dispatch Command
    dispatch_parser = subparsers.add_parser("dispatch", help="Execute a Plan JSON")
    dispatch_parser.add_argument("--file", required=True, help="Path to plan.json")
    
    args = parser.parse_args()
    
    if args.command == "dispatch":
        engine = OrionEngine()
        engine.dispatch_plan(args.file)
    else:
        parser.print_help()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/archive/intent_router.py
# ========================================================
import re
import uuid
from datetime import datetime
from typing import Optional, Dict, Any, List
from scripts.ontology import Plan

class RequestRouter:
    """
    Rule-Based Router to bypass LLM for deterministic tasks.
    Uses Regex to map user prompts directly to Actions.
    """
    
    def __init__(self):
        # Define routes: (Regex Pattern, Action Name, Param Mapper Function)
        self.routes = [
            (r"^read file (.+)$", "read_file", lambda m: {"path": m.group(1).strip()}),
            (r"^cat (.+)$", "read_file", lambda m: {"path": m.group(1).strip()}),
            (r"^show tree ?(.*)$", "tree_view", lambda m: {"path": m.group(1).strip() or ".", "max_depth": 2}),
            (r"^tree ?(.*)$", "tree_view", lambda m: {"path": m.group(1).strip() or ".", "max_depth": 2}),
            (r"^check processes$", "list_processes", lambda m: {}),
            (r"^ps$", "list_processes", lambda m: {}),
            (r"^analyze dependency (.+)$", "analyze_dependency", lambda m: {"TargetFile": m.group(1).strip()}),
            (r"^calculate impact (.+)$", "calculate_impact", lambda m: {"TargetFile": m.group(1).strip()}),
            (r"^grep '([^']+)' in (.+)$", "grep_search", lambda m: {"pattern": m.group(1), "path": m.group(2).strip()}),
            # --- FDE Learning Mode Integration ---
            (r".*(fde|interview|study|learn|면접|공부).*(palantir|preparation|prep|도와줘|준비).*", "read_file", lambda m: {"path": "/home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/SYSTEM_DIRECTIVE.md"}),
        ]

    def route(self, user_prompt: str) -> Optional[Plan]:
        """
        Tries to match the user prompt against known patterns.
        Returns a Plan object if a match is found, else None.
        """
        for pattern, action_name, param_mapper in self.routes:
            match = re.match(pattern, user_prompt, re.IGNORECASE)
            if match:
                params = param_mapper(match)
                return self._create_plan(user_prompt, action_name, params)
        return None

    def _create_plan(self, objective: str, action_name: str, params: Dict[str, Any]) -> Plan:
        """Creates a single-job Plan."""
        plan_id = f"plan_{uuid.uuid4().hex[:8]}"
        job_id = f"job_{uuid.uuid4().hex[:8]}"
        
        return Plan(
            id=plan_id,
            type="Plan",
            created_at=datetime.now().isoformat(),
            meta_version=1,
            plan_id=plan_id,
            objective=objective,
            ontology_impact=["System"], # Generic impact
            jobs=[
                {
                    "id": job_id,
                    "action_name": action_name,
                    "action_args": params
                }
            ]
        )

if __name__ == "__main__":
    # Self-Test
    router = RequestRouter()
    test_prompts = [
        "read file scripts/router.py",
        "show tree",
        "calculate impact scripts/ontology.py",
        "write code to fix bug" # Should fail
    ]
    
    print("🧪 Testing Router...")
    for p in test_prompts:
        plan = router.route(p)
        if plan:
            print(f"   ✅ Matched: '{p}' -> {plan.jobs[0]['action_name']}")
        else:
            print(f"   ❌ No Match: '{p}'")


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/archive/loop.py
# ========================================================
print('[DEPRECATED] This V2 Loop is decommissioned. Use scripts/orion (V3) instead.')


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/archive/ontology_actions.py
# ========================================================

import os
import json
from pydantic import BaseModel
from typing import List, Optional, Any
from scripts.governance import OrionAction, OntologyContext, UserFacingError
from scripts.ontology import Plan  # The generated model

class PersistPlanParams(BaseModel):
    plan: Plan
    is_new: bool = False

class PersistPlanAction(OrionAction[PersistPlanParams]):
    action_type = "persist_plan"

    def validate(self, ctx: OntologyContext) -> None:
        # Rule 1.2: Determinism & Validity
        if not self.params.plan.plan_id:
            raise UserFacingError("Plan ID is required", "InvalidPlan")
        
        # In a real system, we'd check if the user has permission to create plans
        # or if the plan ID conflicts with an existing one (if is_new=True)

    def _apply_side_effects(self, ctx: OntologyContext) -> dict:
        # Define the physical path (The "Backing Dataset")
        plans_dir = os.path.join(ctx.workspace_root, ".agent", "plans")
        os.makedirs(plans_dir, exist_ok=True)
        
        file_path = os.path.join(plans_dir, f"plan_{self.params.plan.plan_id}.json")
        
        # Serialize
        data = self.params.plan.model_dump_json(indent=2)
        
        # Write (The Mutation)
        with open(file_path, 'w') as f:
            f.write(data)
            
        return {"path": file_path, "bytes": len(data)}


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/archive/actions_legacy/definitions.py
# ========================================================

from typing import Callable, Any, Dict, List
from pydantic import BaseModel

class SubmissionCriteria(BaseModel):
    """
    Validation Rule that must pass before Action execution.
    """
    description: str
    validator: Callable[[Any], bool]

class Function(BaseModel):
    """
    Logic: A pure function (or Side-Effect free calculation).
    """
    name: str
    logic: Callable

class ActionType(BaseModel):
    """
    Represents an actionable change in the Ontology.
    Includes: Parameters, Logic, Validation, SideEffects.
    """
    api_name: str
    display_name: str
    parameters: Dict[str, Any] # Name -> Type
    submission_criteria: List[SubmissionCriteria] = []
    
    def validate(self, **kwargs) -> bool:
        """
        Runs all SubmissionCriteria.
        """
        for criteria in self.submission_criteria:
            if not criteria.validator(kwargs):
                print(f"[Validation Failed] {criteria.description}")
                return False
        return True

    def execute(self, **kwargs):
        """
        Conceptual Execution Stub.
        """
        if self.validate(**kwargs):
            self._perform_side_effects(**kwargs)
            print(f"[Action] {self.display_name} Executed Successfully.")
        else:
            raise ValueError("Submission Criteria Failed")

    def _perform_side_effects(self, **kwargs):
        pass # To be overridden


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/scripts/mcp/ontology_server.py
# ========================================================
"""
ODA V3.0 - Ontology MCP Server (Persistent Edition)
====================================================

Exposes Ontology inspection and action execution via MCP protocol
with full SQLite persistence for proposals.

Features:
- Real proposal persistence (SQLite)
- Full history tracking
- Pagination support for queries
- Statistics and metrics

Start with: python -m scripts.mcp.ontology_server
"""

from __future__ import annotations

import asyncio
import json
import logging
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

from scripts.ontology.actions import action_registry, ActionContext
from scripts.ontology.objects.proposal import (
    Proposal,
    ProposalPriority,
    ProposalStatus,
)
from scripts.ontology.storage.database import initialize_database
from scripts.ontology.storage.proposal_repository import (
    ProposalRepository,
    ProposalQuery,
    ProposalNotFoundError,
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize MCP Server
server = Server("oda-ontology")

# Global repository instance (initialized on first use)
_repo: Optional[ProposalRepository] = None


async def get_repo() -> ProposalRepository:
    """Get or create the repository instance."""
    global _repo
    if _repo is None:
        db = await initialize_database()
        _repo = ProposalRepository(db)
    return _repo


@server.list_tools()
async def list_tools() -> List[Tool]:
    """List available ODA tools."""
    return [
        # =====================================================================
        # ACTION TOOLS
        # =====================================================================
        Tool(
            name="list_actions",
            description="List all registered ActionTypes with their metadata",
            inputSchema={
                "type": "object",
                "properties": {
                    "include_hazardous_only": {
                        "type": "boolean",
                        "description": "Filter to only hazardous actions",
                        "default": False
                    }
                }
            }
        ),
        Tool(
            name="inspect_action",
            description="Get detailed information about a specific ActionType",
            inputSchema={
                "type": "object",
                "properties": {
                    "api_name": {
                        "type": "string",
                        "description": "The API name of the action to inspect"
                    }
                },
                "required": ["api_name"]
            }
        ),
        Tool(
            name="execute_action",
            description="Execute a non-hazardous ActionType with given parameters",
            inputSchema={
                "type": "object",
                "properties": {
                    "api_name": {
                        "type": "string",
                        "description": "The API name of the action"
                    },
                    "params": {
                        "type": "object",
                        "description": "Action parameters"
                    },
                    "actor_id": {
                        "type": "string",
                        "description": "ID of the actor executing the action",
                        "default": "gemini-agent"
                    }
                },
                "required": ["api_name", "params"]
            }
        ),
        
        # =====================================================================
        # PROPOSAL TOOLS (PERSISTENT)
        # =====================================================================
        Tool(
            name="create_proposal",
            description="Create and save a Proposal for a hazardous action (persisted to SQLite)",
            inputSchema={
                "type": "object",
                "properties": {
                    "action_type": {
                        "type": "string",
                        "description": "The action type API name"
                    },
                    "payload": {
                        "type": "object",
                        "description": "Action parameters"
                    },
                    "priority": {
                        "type": "string",
                        "enum": ["low", "medium", "high", "critical"],
                        "default": "medium"
                    },
                    "submit": {
                        "type": "boolean",
                        "description": "If true, submit for review immediately",
                        "default": True
                    }
                },
                "required": ["action_type", "payload"]
            }
        ),
        Tool(
            name="get_proposal",
            description="Get a proposal by ID with full history",
            inputSchema={
                "type": "object",
                "properties": {
                    "proposal_id": {
                        "type": "string",
                        "description": "The proposal ID"
                    }
                },
                "required": ["proposal_id"]
            }
        ),
        Tool(
            name="list_proposals",
            description="List proposals with optional filters and pagination",
            inputSchema={
                "type": "object",
                "properties": {
                    "status": {
                        "type": "string",
                        "enum": ["draft", "pending", "approved", "rejected", "executed", "cancelled"],
                        "description": "Filter by status"
                    },
                    "action_type": {
                        "type": "string",
                        "description": "Filter by action type"
                    },
                    "created_by": {
                        "type": "string",
                        "description": "Filter by creator"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Max results to return",
                        "default": 20
                    },
                    "offset": {
                        "type": "integer",
                        "description": "Offset for pagination",
                        "default": 0
                    }
                }
            }
        ),
        Tool(
            name="list_pending_proposals",
            description="List all proposals pending review (shortcut)",
            inputSchema={
                "type": "object",
                "properties": {
                    "limit": {
                        "type": "integer",
                        "default": 50
                    }
                }
            }
        ),
        Tool(
            name="approve_proposal",
            description="Approve a pending proposal",
            inputSchema={
                "type": "object",
                "properties": {
                    "proposal_id": {
                        "type": "string",
                        "description": "The proposal ID"
                    },
                    "reviewer_id": {
                        "type": "string",
                        "description": "ID of the reviewer",
                        "default": "gemini-agent"
                    },
                    "comment": {
                        "type": "string",
                        "description": "Approval comment"
                    }
                },
                "required": ["proposal_id"]
            }
        ),
        Tool(
            name="reject_proposal",
            description="Reject a pending proposal",
            inputSchema={
                "type": "object",
                "properties": {
                    "proposal_id": {
                        "type": "string",
                        "description": "The proposal ID"
                    },
                    "reviewer_id": {
                        "type": "string",
                        "description": "ID of the reviewer",
                        "default": "gemini-agent"
                    },
                    "reason": {
                        "type": "string",
                        "description": "Rejection reason"
                    }
                },
                "required": ["proposal_id", "reason"]
            }
        ),
        Tool(
            name="execute_proposal",
            description="Execute an approved proposal",
            inputSchema={
                "type": "object",
                "properties": {
                    "proposal_id": {
                        "type": "string",
                        "description": "The proposal ID"
                    },
                    "executor_id": {
                        "type": "string",
                        "description": "ID of the executor",
                        "default": "gemini-agent"
                    }
                },
                "required": ["proposal_id"]
            }
        ),
        
        # =====================================================================
        # STATISTICS TOOLS
        # =====================================================================
        Tool(
            name="get_proposal_stats",
            description="Get proposal statistics by status",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        ),
        Tool(
            name="get_proposal_history",
            description="Get full history for a proposal",
            inputSchema={
                "type": "object",
                "properties": {
                    "proposal_id": {
                        "type": "string",
                        "description": "The proposal ID"
                    }
                },
                "required": ["proposal_id"]
            }
        ),
    ]


@server.call_tool()
async def call_tool(name: str, arguments: Dict[str, Any]) -> List[TextContent]:
    """Handle tool calls."""
    repo = await get_repo()
    
    # =========================================================================
    # ACTION TOOLS
    # =========================================================================
    
    if name == "list_actions":
        include_hazardous_only = arguments.get("include_hazardous_only", False)
        
        if include_hazardous_only:
            actions = action_registry.get_hazardous_actions()
        else:
            actions = action_registry.list_actions()
        
        result = []
        for api_name in sorted(actions):
            action_cls = action_registry.get(api_name)
            result.append({
                "api_name": api_name,
                "object_type": action_cls.object_type.__name__,
                "requires_proposal": getattr(action_cls, "requires_proposal", False),
            })
        
        return [TextContent(type="text", text=json.dumps(result, indent=2))]
    
    elif name == "inspect_action":
        api_name = arguments["api_name"]
        action_cls = action_registry.get(api_name)
        
        if not action_cls:
            return [TextContent(type="text", text=json.dumps({
                "error": "ACTION_NOT_FOUND",
                "message": f"Action '{api_name}' not found"
            }))]
        
        criteria = []
        for c in getattr(action_cls, "submission_criteria", []):
            criteria.append(c.name if hasattr(c, "name") else str(c))
        
        side_effects = []
        for s in getattr(action_cls, "side_effects", []):
            side_effects.append(s.name if hasattr(s, "name") else str(s))
        
        result = {
            "api_name": api_name,
            "object_type": action_cls.object_type.__name__,
            "requires_proposal": getattr(action_cls, "requires_proposal", False),
            "submission_criteria": criteria,
            "side_effects": side_effects,
            "docstring": action_cls.__doc__,
        }
        
        return [TextContent(type="text", text=json.dumps(result, indent=2))]
    
    elif name == "execute_action":
        api_name = arguments["api_name"]
        params = arguments["params"]
        actor_id = arguments.get("actor_id", "gemini-agent")
        
        action_cls = action_registry.get(api_name)
        if not action_cls:
            return [TextContent(type="text", text=json.dumps({
                "error": "ACTION_NOT_FOUND",
                "message": f"Action '{api_name}' not found"
            }))]
        
        if getattr(action_cls, "requires_proposal", False):
            return [TextContent(type="text", text=json.dumps({
                "error": "PROPOSAL_REQUIRED",
                "message": f"Action '{api_name}' requires proposal approval. Use create_proposal instead.",
                "hint": "Call create_proposal with action_type='{api_name}'"
            }))]
        
        action = action_cls()
        context = ActionContext(actor_id=actor_id)
        result = await action.execute(params, context)
        
        return [TextContent(type="text", text=json.dumps(result.to_dict(), indent=2))]
    
    # =========================================================================
    # PROPOSAL TOOLS (PERSISTENT)
    # =========================================================================
    
    elif name == "create_proposal":
        proposal = Proposal(
            action_type=arguments["action_type"],
            payload=arguments["payload"],
            priority=ProposalPriority(arguments.get("priority", "medium")),
            created_by="gemini-agent",
        )
        
        if arguments.get("submit", True):
            proposal.submit()
        
        await repo.save(proposal, actor_id="gemini-agent")
        
        result = {
            "success": True,
            "proposal_id": proposal.id,
            "action_type": proposal.action_type,
            "status": proposal.status.value,
            "priority": proposal.priority.value,
            "message": f"Proposal created and {'submitted for review' if proposal.status == ProposalStatus.PENDING else 'saved as draft'}",
            "next_steps": [
                f"View: get_proposal('{proposal.id}')",
                f"Approve: approve_proposal('{proposal.id}')",
                f"Reject: reject_proposal('{proposal.id}', reason='...')",
            ] if proposal.status == ProposalStatus.PENDING else [
                f"Submit: Use list_proposals to find and submit"
            ]
        }
        
        return [TextContent(type="text", text=json.dumps(result, indent=2))]
    
    elif name == "get_proposal":
        proposal_id = arguments["proposal_id"]
        
        try:
            proposal, history = await repo.get_with_history(proposal_id)
            
            if proposal is None:
                return [TextContent(type="text", text=json.dumps({
                    "error": "PROPOSAL_NOT_FOUND",
                    "proposal_id": proposal_id
                }))]
            
            result = {
                "proposal": {
                    "id": proposal.id,
                    "action_type": proposal.action_type,
                    "payload": proposal.payload,
                    "status": proposal.status.value,
                    "priority": proposal.priority.value,
                    "created_by": proposal.created_by,
                    "created_at": proposal.created_at.isoformat(),
                    "reviewed_by": proposal.reviewed_by,
                    "reviewed_at": proposal.reviewed_at.isoformat() if proposal.reviewed_at else None,
                    "review_comment": proposal.review_comment,
                    "executed_at": proposal.executed_at.isoformat() if proposal.executed_at else None,
                    "version": proposal.version,
                },
                "history": [
                    {
                        "action": h.action,
                        "actor_id": h.actor_id,
                        "timestamp": h.timestamp.isoformat(),
                        "previous_status": h.previous_status,
                        "new_status": h.new_status,
                        "comment": h.comment,
                    }
                    for h in history
                ]
            }
            
            return [TextContent(type="text", text=json.dumps(result, indent=2))]
        
        except Exception as e:
            return [TextContent(type="text", text=json.dumps({
                "error": str(type(e).__name__),
                "message": str(e)
            }))]
    
    elif name == "list_proposals":
        query = ProposalQuery(
            status=ProposalStatus(arguments["status"]) if arguments.get("status") else None,
            action_type=arguments.get("action_type"),
            created_by=arguments.get("created_by"),
            limit=arguments.get("limit", 20),
            offset=arguments.get("offset", 0),
        )
        
        result = await repo.query(query)
        
        return [TextContent(type="text", text=json.dumps({
            "proposals": [
                {
                    "id": p.id,
                    "action_type": p.action_type,
                    "status": p.status.value,
                    "priority": p.priority.value,
                    "created_by": p.created_by,
                    "created_at": p.created_at.isoformat(),
                }
                for p in result.items
            ],
            "pagination": {
                "total": result.total,
                "limit": result.limit,
                "offset": result.offset,
                "has_more": result.has_more,
            }
        }, indent=2))]
    
    elif name == "list_pending_proposals":
        limit = arguments.get("limit", 50)
        pending = await repo.find_pending(limit=limit)
        
        return [TextContent(type="text", text=json.dumps({
            "count": len(pending),
            "proposals": [
                {
                    "id": p.id,
                    "action_type": p.action_type,
                    "priority": p.priority.value,
                    "created_by": p.created_by,
                    "created_at": p.created_at.isoformat(),
                    "payload_preview": str(p.payload)[:100] + "..." if len(str(p.payload)) > 100 else str(p.payload),
                }
                for p in pending
            ]
        }, indent=2))]
    
    elif name == "approve_proposal":
        proposal_id = arguments["proposal_id"]
        reviewer_id = arguments.get("reviewer_id", "gemini-agent")
        comment = arguments.get("comment")
        
        try:
            proposal = await repo.approve(proposal_id, reviewer_id, comment)
            
            return [TextContent(type="text", text=json.dumps({
                "success": True,
                "proposal_id": proposal.id,
                "status": proposal.status.value,
                "reviewed_by": proposal.reviewed_by,
                "message": "Proposal approved successfully",
                "next_step": f"Execute: execute_proposal('{proposal.id}')"
            }, indent=2))]
        
        except ProposalNotFoundError:
            return [TextContent(type="text", text=json.dumps({
                "error": "PROPOSAL_NOT_FOUND",
                "proposal_id": proposal_id
            }))]
        except Exception as e:
            return [TextContent(type="text", text=json.dumps({
                "error": str(type(e).__name__),
                "message": str(e)
            }))]
    
    elif name == "reject_proposal":
        proposal_id = arguments["proposal_id"]
        reviewer_id = arguments.get("reviewer_id", "gemini-agent")
        reason = arguments["reason"]
        
        try:
            proposal = await repo.reject(proposal_id, reviewer_id, reason)
            
            return [TextContent(type="text", text=json.dumps({
                "success": True,
                "proposal_id": proposal.id,
                "status": proposal.status.value,
                "reviewed_by": proposal.reviewed_by,
                "reason": reason,
                "message": "Proposal rejected"
            }, indent=2))]
        
        except ProposalNotFoundError:
            return [TextContent(type="text", text=json.dumps({
                "error": "PROPOSAL_NOT_FOUND",
                "proposal_id": proposal_id
            }))]
        except Exception as e:
            return [TextContent(type="text", text=json.dumps({
                "error": str(type(e).__name__),
                "message": str(e)
            }))]
    
    elif name == "execute_proposal":
        proposal_id = arguments["proposal_id"]
        executor_id = arguments.get("executor_id", "gemini-agent")
        
        try:
            # Get the proposal
            proposal = await repo.find_by_id(proposal_id)
            if proposal is None:
                return [TextContent(type="text", text=json.dumps({
                    "error": "PROPOSAL_NOT_FOUND",
                    "proposal_id": proposal_id
                }))]
            
            # Execute the underlying action
            action_cls = action_registry.get(proposal.action_type)
            if action_cls is None:
                return [TextContent(type="text", text=json.dumps({
                    "error": "ACTION_NOT_FOUND",
                    "action_type": proposal.action_type
                }))]
            
            action = action_cls()
            context = ActionContext(actor_id=executor_id)
            action_result = await action.execute(proposal.payload, context)
            
            # Mark proposal as executed
            await repo.execute(
                proposal_id,
                executor_id=executor_id,
                result=action_result.to_dict()
            )
            
            return [TextContent(type="text", text=json.dumps({
                "success": True,
                "proposal_id": proposal_id,
                "action_type": proposal.action_type,
                "status": "executed",
                "action_result": action_result.to_dict(),
                "message": "Proposal executed successfully"
            }, indent=2))]
        
        except Exception as e:
            return [TextContent(type="text", text=json.dumps({
                "error": str(type(e).__name__),
                "message": str(e)
            }))]
    
    # =========================================================================
    # STATISTICS TOOLS
    # =========================================================================
    
    elif name == "get_proposal_stats":
        counts = await repo.count_by_status()
        total = sum(counts.values())
        
        return [TextContent(type="text", text=json.dumps({
            "total_proposals": total,
            "by_status": counts,
            "pending_review": counts.get("pending", 0),
            "ready_to_execute": counts.get("approved", 0),
        }, indent=2))]
    
    elif name == "get_proposal_history":
        proposal_id = arguments["proposal_id"]
        history = await repo.get_history(proposal_id)
        
        return [TextContent(type="text", text=json.dumps({
            "proposal_id": proposal_id,
            "history_count": len(history),
            "entries": [
                {
                    "action": h.action,
                    "actor_id": h.actor_id,
                    "timestamp": h.timestamp.isoformat(),
                    "previous_status": h.previous_status,
                    "new_status": h.new_status,
                    "comment": h.comment,
                }
                for h in history
            ]
        }, indent=2))]
    
    return [TextContent(type="text", text=json.dumps({
        "error": "UNKNOWN_TOOL",
        "tool": name
    }))]


async def main():
    """Run the MCP server."""
    # Pre-initialize the database
    await get_repo()
    logger.info("ODA Ontology MCP Server started with persistent storage")
    
    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            server.create_initialization_options()
        )


if __name__ == "__main__":
    asyncio.run(main())


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/config/router.yaml
# ========================================================
# Orion ODA v3.0 - Router Configuration

word_threshold: 50
sentence_threshold: 5

critical_keywords:
  - delete
  - remove
  - deploy
  - production
  - database
  - credential
  - password

technical_terms:
  - api
  - microservice
  - kubernetes

word_weight: 1.0
sentence_weight: 5.0
technical_term_weight: 3.0

ollama_base_url: "http://localhost:11434"
ollama_model: "llama3.2"
ollama_timeout: 60.0


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/.agent/workflows/01_plan.md
# ========================================================
---
description: Transform User Intent into a Governed Handoff Artifact
---
# 01_plan: Ontology Planning & Handoff Generation

This workflow defines how Gemini transforms a user request into actionable Handoff Files for other Agents.

## 1. Intent Analysis
- **Goal**: Understand the user's request.
- **Actions**:
    - Use `tavily` if external context is needed.
    - Use `read_file` to understand the codebase state.

## 2. Plan Definition (Ontology)
- **Goal**: Create a structured `Plan` object.
- **Actions**:
    - Define `Objective`.
    - Break down into `Jobs`.
    - Assign `Role` to each Job (`Architect` for Claude, `Automation` for GPT).

## 3. Handoff Artifact Generation (Crucial)
- **Goal**: Create files for manual routing programmatically.
- **Actions**:
    - **Execute Script**:
        ```bash
        python -m scripts.ontology.handoff --plan .agent/plans/plan_[ID].json --job [INDEX]
        ```
    - **Verify**: Check `.agent/handoffs/pending/` for the new file.

## 4. User Notification
- **Action**: Inform the user:
    > "Handoff File Created: `.agent/handoffs/pending/job_a1b2_claude.md`. Please switch to Claude and ask it to read this file."


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/00_palantir_core_architecture.md
# ========================================================
# Palantir Foundry & AIP Core Architecture
> **Status**: Auto-Generated Context from Deep Research
> **Source**: Public Technical Whitepapers, Dev Docs, Engineering Blogs (2024-2025)

## 1. The Ontology (Semantic Layer)
The Ontology is the "Digital Twin" of the organization, decoupling data integration from data consumption.

*   **Structural Isomorphism**:
    *   **Objects**: Rough equivalent to SQL Rows or NoSQL Documents, but with enforced schemas and comprehensive lineage.
    *   **Links**: Directed edges between objects ($Object A \xrightarrow{Link} Object B$). Unlike SQL Foreign Keys, these are first-class citizens optimized for graph traversal.
    *   **Properties**: Strongly typed attributes. OSDK maps these to native language types (e.g., `TS: string`, `Python: str`).

*   **Kinetic Layer (Write Path)**:
    *   **Actions**: The ONLY way to mutate the Ontology from the frontend.
        *   *Analogy*: Redux Actions. You dispatch an Action, the backend verifies permissions/logic, and the state updates.
        *   *Validation*: All edits are transactional and validated against business rules (Functions) before commit.
    *   **Functions**: Logic stored in the Ontology (Code Repos). Can be triggered by Actions or used for derived properties.

## 2. AIP Architecture (The Brain)
AIP (Artificial Intelligence Platform) injects LLM reasoning into the Ontology.

*   **AIP Logic**: A "Serverless LLM Runtime".
    *   **Blocks**: Composable units (Prompt, Tool, Splitter).
    *   **Tool Usage**: LLMs do not "hallucinate" DB queries. They request to use an "Ontology Tool" (e.g., `get_object(id)`), which the system executes securely.
*   **RAG Pattern**:
    *   Foundry does not just "chunk text". It uses **GraphRAG**.
    *   Context is retrieved by traversing the Ontology (Object $\rightarrow$ Link $\rightarrow$ Linked Object) to provide high-fidelity context window to the LLM.

## 3. Apollo (The Nervous System)
Continuous Delivery and Orchestration for the decentralized era.

*   **Constraint-Based Deployment**:
    *   Instead of "Deploy v2 to Prod", Apollo says "Deploy v2 where `constraint: compliance_level >= high`".
    *   **Relevance to FDE**: Frontend assets are versioned and deployed just like backend services. A "Application" in Foundry is a versioned artifact managed by Apollo.

## 4. OSDK (The Bridge)
The Ontology Software Development Kit is the "Compiler" that turns Schema into Code.

*   **Generation Pipeline**:
    *   Ontology Metadata Service (OMS) $\rightarrow$ OSDK Generator $\rightarrow$ `npm/@osdk/client` or `pypi/palantir-osdk`.
*   **Type Safety**:
    *   Changes in Foundry Schema = Compile Error in VS Code.
    *   This "Contract-First" development is the hallmark of Palantir engineering.

## 5. Architectural Isomorphisms for Reflective Analysis
When analyzing user code, map these patterns:

| User Code Pattern | Palantir Isomorphism | Why? |
| :--- | :--- | :--- |
| **Pydantic Models** | **Ontology Object Types** | Both enforce strict schema at the boundary. |
| **Redux/State Actions** | **Ontology Actions** | Both use the Command Pattern to mutate state safely. |
| **Graph/Tree Structures** | **Ontology Links** | Both model connectivity and traversal. |
| **Async Tasks/Queues** | **Apollo/Job Sets** | Both manage asynchronous execution constraints. |
| **Utility Functions** | **Foundry Functions** | Pure logic units operating on data entities. |


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/01_language_foundation.md
# ========================================================
# Comprehensive Technical Analysis of JavaScript ES6+ and TypeScript for Enterprise Data Visualization Platforms

## 1. Foundational Paradigms: The Browser as an Distributed Operating System

For an engineer transitioning from a background in Mathematics and AI/ML systems into the Palantir ecosystem, specifically targeting the Frontend Engineer role, a fundamental conceptual shift is required. One must move beyond viewing the browser as a document viewer and instead regard it as a distributed operating system runtime. Palantir Foundry is not merely a collection of web pages; it is a sophisticated, data-dense operating environment that orchestrates complex ontology integrations, massive-scale graph visualizations, and operational decision-making workflows, all within the constraints of the V8 JavaScript engine.

The "Universal Tutor" project you are currently architecting—with its requirements for intelligent graph traversal (GraphRAG), node-link visualization, and real-time responsiveness—serves as an almost isomorphic proxy for the challenges faced within Foundry. Both domains require the manipulation of abstract mathematical structures (graphs, ontologies) and their projection into a user-perceivable manifold (the DOM/Canvas), all while adhering to rigorous correctness guarantees.

This report provides an exhaustive technical analysis of the language foundations—JavaScript ES6+ and TypeScript—that underpin this stack. Unlike standard web development resources, this analysis assumes a sophisticated reader capable of mapping set-theoretic concepts to type systems and understanding the algorithmic complexity of runtime scheduling. We will dissect the internal mechanics of the V8 engine, the structural type theory of TypeScript, and the specific architectural patterns employed by Palantir’s Blueprint UI toolkit and Ontology SDK (OSDK) to manage complexity at scale.

## 2. JavaScript ES6+ Deep Dive: Runtime Mechanics and Concurrency

To engineer at the scale of Foundry, where applications handles millions of ontology objects and complex graph visualizations, one cannot treat JavaScript simply as a scripting language. It is the assembly language of the web platform. Its single-threaded nature imposes strict constraints on how heavy computational tasks—such as filtering a 100,000-node graph for your Universal Tutor—must be scheduled to ensure the interface remains fluid (60fps, or 16.6ms per frame).

### Core Language Mechanics: Closures and Scope Chains

Understanding closures is prerequisite for managing state in React, particularly when dealing with "stale closures," a common class of bugs in hook-based architectures.

A closure is formed when a function creates a "backpack" of data that persists even after the outer function has finished execution. In V8, this is implemented via a context object that holds references to variables in the scope chain.

**The Mathematical Analogy:**

Consider a function $f(x)$ that returns another function $g(y)$. If $g(y)$ depends on $x$, then $x$ is a free variable in $g$ bound by the lexical environment of $f$.

$$g(y) = y + x$$

In JavaScript:

```javascript
function f(x) {
  return function g(y) {
    return y + x; // x is captured in the closure of g
  };
}
```

The critical implication for memory management is that the closure retains a strong reference to the entire scope it captures, unless the engine's optimizer (TurboFan in V8) can prove certain variables are unused. In React `useEffect` hooks, if a closure captures a large object (e.g., a massive dataset from OSDK) and that effect is not properly cleaned up, the entire dataset remains pinned in the "Old Generation" heap, causing a memory leak.

### The Event Loop: Orchestrating Throughput

The JavaScript runtime model relies on an event loop, which is responsible for executing code, collecting and processing events, and executing queued sub-tasks. For data-dense applications like Foundry, the distinction between **macrotasks** and **microtasks** is the single most critical factor in performance optimization and UI responsiveness.

#### The Mechanics of Task Queues

The Event Loop does not treat all asynchronous callbacks equally. It manages two distinct queues:

1.  **The Macrotask Queue (Task Queue):** Contains callbacks for `setTimeout`, `setInterval`, `setImmediate`, I/O operations, and UI rendering events.
2.  **The Microtask Queue (Job Queue):** Contains callbacks for `Promise.then`, `catch`, `finally`, `MutationObserver`, and `queueMicrotask`.

**Operational Semantics:**

The algorithm for a single tick of the event loop proceeds as follows:
1.  Dequeue and execute exactly one task from the Macrotask Queue.
2.  Check the Microtask Queue.
3.  Execute **all** tasks in the Microtask Queue until it is empty. If a microtask schedules another microtask, it is added to the end of the queue and executed in the same cycle.
4.  Perform rendering updates (if necessary).
5.  Wait for the next macrotask.

**Implications for Data Visualization:**

In the context of the Universal Tutor or Palantir's graph visualizations, heavy data transformation logic must be carefully managed.

*   **Starvation Risk:** If you process a large graph dataset using a recursive Promise chain (e.g., `Promise.resolve().then(...)`), you are continuously pushing jobs onto the Microtask Queue. Because the event loop drains the entire Microtask Queue before moving to the rendering phase, the browser UI will freeze (jank) until the entire dataset is processed.
*   **Yielding Control:** To maintain responsiveness, long-running computations must be partitioned using Macrotasks. Using `setTimeout(..., 0)` or `requestIdleCallback` yields control back to the event loop, allowing the browser to perform layout and paint updates between chunks of work.

| Feature | Macrotask | Microtask | Palantir Application |
| :--- | :--- | :--- | :--- |
| **Examples** | `setTimeout`, `setInterval`, I/O | `Promise.then`, `MutationObserver` | |
| **Priority** | Lower | Higher | Critical distinction for scheduling. |
| **Execution** | One per loop tick | Drain queue completely | |
| **Rendering** | Occurs between macrotasks | Blocked until queue empty | Use Macrotasks to yield to UI. |
| **Use Case** | Chunking heavy computation | State consistency, API responses | OSDK uses Microtasks for consistency. |

### Memory Management: The V8 Garbage Collector

V8, the engine powering Chrome and Node.js, utilizes a sophisticated garbage collection (GC) pipeline known as **Orinoco**. For a math/CS background, this can be modeled as a graph traversal problem where reachability determines object liveness.

#### The Generational Hypothesis

V8 relies on the empirical observation that "most objects die young." Consequently, the heap is segmented:

1.  **Young Generation (New Space):** Where new objects are allocated. A "Scavenger" algorithm (Cheney's algorithm variant) quickly copies live objects to a "Survivor" space and discards the rest. This process is extremely fast but requires 2x memory overhead for the copy space.
2.  **Old Generation (Old Space):** Objects that survive multiple Scavenge cycles are promoted here. Cleanup involves a complex "Mark-Sweep-Compact" algorithm. This is a "Stop-the-World" event (though incremental marking reduces the pause), which can cause noticeable stutter in a visualization application if the heap is large.

#### Detecting Leaks: The 3-Snapshot Technique

A common interview and practical debugging technique is the **3-Snapshot Technique** using Chrome DevTools:

1.  **Snapshot 1 (Baseline):** Capture the heap state after the application loads and stabilizes.
2.  **Action:** Perform the user interaction suspected of leaking (e.g., opening and closing a modal, rendering a graph).
3.  **Snapshot 2 (Target):** Capture immediately after the action.
4.  **Cleanup:** Force garbage collection (click the trash can icon).
5.  **Snapshot 3 (Final):** Capture the state.

**Analysis:**
If objects from Snapshot 2 persist in Snapshot 3 despite the cleanup, and the total heap size in Snapshot 3 is monotonically increasing relative to Snapshot 1, a leak exists. In React, this often manifests as **Detached DOM Nodes**: elements removed from the visual tree but retained in memory by JavaScript references (e.g., an event listener on a table row that wasn't removed).

### Async Patterns: Generators and Iterators

While `async/await` is standard, **Generators (`function*`)** and **Async Iterators (`for await...of`)** are crucial for handling streams of data, such as paginated results from the OSDK.

**Lazy Evaluation:**
Generators allow for lazy evaluation of infinite sequences, a concept familiar in functional analysis. They maintain internal state and yield values only when requested.

```javascript
async function* fetchPages(query) {
  let page = await client.fetchFirst(query);
  yield page.data;
  while (page.hasNext) {
    page = await client.fetchNext(page);
    yield page.data;
  }
}
```

This pattern allows the frontend to consume massive datasets page-by-page without loading the entire result set into memory, creating a form of "backpressure" handling.

### Common Interview Patterns: Polyfills

Candidates are frequently asked to implement core language features to demonstrate understanding of prototypes and `this` binding.

**1. Polyfill for Array.prototype.map**

The key insight is handling the `this` context and sparse arrays.

```javascript
Array.prototype.myMap = function(callback, thisArg) {
  if (this == null) throw new TypeError("this is null or not defined");
  if (typeof callback !== 'function') throw new TypeError(callback + " is not a function");

  const O = Object(this);
  const len = O.length >>> 0; // Unsigned right shift to ensure positive integer
  const A = new Array(len);

  for (let k = 0; k < len; k++) {
    if (k in O) { // Check for sparse array holes
      const kValue = O[k];
      const mappedValue = callback.call(thisArg, kValue, k, O);
      A[k] = mappedValue;
    }
  }
  return A;
};
```

**2. Polyfill for Promise.all**

Demonstrates understanding of asynchronous concurrency and error propagation.

```javascript
Promise.myAll = function(promises) {
  return new Promise((resolve, reject) => {
    if (!Array.isArray(promises)) return reject(new TypeError("Argument must be an array"));
    
    const results = [];
    let completed = 0;
    
    if (promises.length === 0) resolve(results);

    promises.forEach((p, index) => {
      Promise.resolve(p) // Normalize values to promises
       .then(value => {
          results[index] = value; // Preserve order
          completed++;
          if (completed === promises.length) resolve(results);
        })
       .catch(error => reject(error)); // Fail fast behavior
    });
  });
};
```

## 3. TypeScript Architecture: A Structural Type System

For a mathematician, TypeScript is best understood not merely as a validation tool, but as a formal system for set theory. Every type defines a set of possible values. `string` is the set of all possible strings; `number` is the set of all IEEE 754 floats.

### Type System Fundamentals: Structural vs. Nominal

TypeScript's defining characteristic is its **structural type system**, which fundamentally differentiates it from the nominal typing found in Java, C#, or C++.

*   **Nominal Typing (Java):**
    Type compatibility is determined by explicit declaration and inheritance hierarchy.
    ```java
    class Dog { public String name; }
    class Cat { public String name; }
    // Dog is NOT compatible with Cat, even though they have the same structure.
    ```

*   **Structural Typing (TypeScript):**
    Type compatibility is determined by the shape (structure) of the data. If Set $A$ contains all the required properties of Set $B$, then $A$ is a subset of $B$, and $A$ is assignable to $B$.

    ```typescript
    interface Vector2D { x: number; y: number; }
    interface Vector3D { x: number; y: number; z: number; }

    const v3: Vector3D = { x: 1, y: 2, z: 3 };
    const v2: Vector2D = v3; // Valid! Vector3D has all properties of Vector2D.
    ```

**Why Palantir Uses This:**
Structural typing is critical for Foundry because the frontend consumes data from diverse sources (Ontology, external APIs, legacy systems). We might receive a data object that has more properties than we strictly need. Structural typing allows the OSDK to accept these "superset" objects without requiring rigorous, expensive mapping or casting, facilitating seamless integration.

### Set Theory in Types

*   **Union Types (|):** The mathematical union $A \cup B$. A value can be in set A or set B. Access is restricted to the intersection of members (properties common to both) unless narrowed.
*   **Intersection Types (&):** The mathematical intersection is conceptualized differently in object types. `A & B` represents an object that has properties of A **and** properties of B. It is the union of the requirements.
*   **Never (never):** The empty set $\emptyset$. No value can be assigned to `never`. It is the return type of functions that throw errors or infinite loops, and the result of intersecting disjoint types (e.g., `string & number`).

### Advanced Types for Enterprise Scale

To build reusable infrastructure like the Blueprint Toolkit, developers must leverage advanced type operators to create flexible, self-documenting APIs.

#### Conditional Types

Conditional types allow type definitions to depend on logic, mirroring conditional functions in value space:

$$T(X) = \begin{cases} A & \text{if } X \in U \\ B & \text{otherwise} \end{cases}$$

**Syntax:** `T extends U ? X : Y`.

**Distributivity:**
When a conditional type acts on a generic union type, it distributes over the union. This is a powerful feature for filtering types.

`Exclude<T, U> = T extends U ? never : T`

If T = "a" | "b" | "c" and U = "a", then:
*   "a" extends "a" ? never : "a" $\rightarrow$ never
*   "b" extends "a" ? never : "b" $\rightarrow$ "b"
*   "c" extends "a" ? never : "c" $\rightarrow$ "c"

Result: "b" | "c".

#### Mapped Types

Mapped types iterate over keys of a type to create a new type, analogous to a map function over a vector space.

`type Partial<T> = { [P in keyof T]?: T[P] };`

This is fundamental for OSDK "Patch" objects, where a user might update only a subset of fields in an Ontology object.

**Utility Type: DeepPartial**
A common interview question and practical necessity is implementing `DeepPartial`, which makes every property in a nested object tree optional. This requires conditional types to handle arrays and primitives correctly.

```typescript
type DeepPartial<T> = {
 [P in keyof T]?: T[P] extends Array<infer U> 
   ? Array<DeepPartial<U>> 
    : T[P] extends object 
     ? DeepPartial<T[P]> 
      : T[P];
};
```

### TypeScript 5.x Features

Palantir's stack stays current. The candidate must understand recent features that improve type inference and safety.

#### The `satisfies` Operator

Introduced in TypeScript 4.9 and refined in 5.5, `satisfies` validates that an expression matches a type **without widening the inferred type** of that expression.

**The Problem:**
```typescript
const config: Record<string, string | number> = { timeout: 500 };
// config.timeout is now `string | number`. We lost the fact that it is a number.
```

**The Solution:**
```typescript
const config = { timeout: 500 } satisfies Record<string, string | number>;
// TypeScript validates structure, but config.timeout is inferred as `number`.
```
This is critical for configuring Blueprint components or OSDK clients where preserving literal types enables stricter checking downstream.

#### `const` Type Parameters

TypeScript 5.0 introduced `const` type parameters to infer literal types in generics by default.

```typescript
function route<const T>(path: T) { ... }
route("/users"); // T is inferred as literal "/users", not string
```
This simplifies APIs that rely on specific string keys (like Ontology object types) without forcing the developer to write `as const` everywhere.

## 4. Enterprise Patterns: Architecture at Scale

Building applications in Foundry differs from building standard websites. The "Universal Tutor" is not a brochure; it is a system. This section details the architectural patterns required to manage complexity.

### Feature-Sliced Design (FSD)

While not explicitly mandated in every Palantir repo, the principles of Feature-Sliced Design (FSD) are prevalent in modern large-scale React apps and align with Palantir’s emphasis on modularity. FSD partitions the codebase into layers based on responsibility and domain logic.

**The Layers (Top to Bottom):**
1.  **App:** Global providers, styles, entry points.
2.  **Pages:** Composition of widgets into full views (routes).
3.  **Widgets:** Self-contained UI blocks (e.g., "GraphVisualizer").
4.  **Features:** User interactions (e.g., "FilterGraph", "SearchNode").
5.  **Entities:** Business domain models (e.g., "Student", "ConceptNode").
6.  **Shared:** Reusable infrastructure (UI kit, API clients).

**The Golden Rule:** Dependencies can only flow **downwards**. A Feature can import an Entity, but an Entity cannot import a Feature. This prevents the "spaghetti code" circular dependencies that plague large React codebases.

### Hexagonal Architecture (Ports and Adapters)

To verify the correctness of the "Universal Tutor" logic independently of the UI, Hexagonal Architecture is essential. It isolates the "Core" (business logic) from the "Infrastructure" (React components, OSDK calls).

*   **Core:** Contains pure TypeScript classes/functions defining the Tutor's behavior (e.g., `calculateLearningPath`). It depends on nothing but domain entities.
*   **Ports:** Interfaces defining how the Core retrieves data (e.g., `IConceptRepository`).
*   **Adapters:** Concrete implementations of ports.
    *   **OSDKConceptRepository:** Fetches data from Foundry.
    *   **MockConceptRepository:** Returns static JSON for unit tests.

**Dependency Injection (DI):** React Context is often used as the "Composition Root" to inject the correct Adapter into the application at runtime. This makes the system rigorously testable.

### Migration Strategies: JS to TS

You may encounter legacy code. The migration strategy is "gradual strictness."

1.  `allowJs: true`: Enable TypeScript to process JS files.
2.  `checkJs: true`: Report errors in JS files using JSDoc annotations.
3.  **Renaming:** Convert `.js` to `.ts` one file at a time, starting from leaf nodes (utils, shared constants) and moving up to complex components.
4.  `noImplicitAny`: The final boss. Once all files are TS, enabling this flag enforces true type safety.

## 5. Palantir Specifics: Blueprint UI Toolkit

Blueprint (`@blueprintjs/core`, `@blueprintjs/table`) is the standard UI toolkit for all Foundry applications. It is designed for "desktop-class" applications running in the browser—dense, keyboard-driven, and complex.

### Component Architecture and Composition

Blueprint prefers composition over inheritance.

**Popover Pattern:**
A `Popover` does not inherit from a generic "Overlay." Instead, it composes an `Overlay` and a target element.

```javascript
<Popover content={<Menu />}>
  <Button text="Options" />
</Popover>
```
This adheres to the Open/Closed Principle, allowing behavior to be extended without modifying the source.

### Virtualization: The Table Component

For the "Universal Tutor," visualizing lists of thousands of students or concepts requires virtualization. The DOM cannot handle 10,000 `<tr>` elements without crashing the browser.

**Mechanism:**
Blueprint's Table (and the integrated `react-window` library) uses a "sliding window" technique. It calculates which rows are currently visible in the viewport and renders only those rows (plus a small "overscan" buffer). As the user scrolls, the DOM nodes are recycled and updated with new data.

**Performance Math:**
Complexity reduces from $O(N)$ (where N is dataset size) to $O(V)$ (where V is viewport size). Since $V$ is constant (e.g., 20 rows), performance remains $O(1)$ relative to data size.

### Accessibility (a11y)

Blueprint enforces accessibility as a correctness constraint.

*   **Focus Management:** Components like `Dialog` implement "focus traps," ensuring that tabbing cycles within the modal and does not escape to the background document.
*   **ARIA Attributes:** Components manage `aria-expanded`, `aria-controls`, and `role` attributes automatically, ensuring compatibility with screen readers.

## 6. Palantir OSDK: Integration and Data Flow

The Ontology Software Development Kit (OSDK) is the mechanism by which your frontend consumes the Data Ontology. It is not just an API client; it is a code generator.

### Generated Type Safety

Unlike manual REST clients where types are written by hand (and can drift from the backend schema), the OSDK generates TypeScript interfaces directly from the Ontology metadata.

*   **Safety:** If the "Student" object in Foundry has a property `gpa`, the OSDK generates a Student interface with `gpa: number`. If the backend schema changes, the frontend build fails immediately.
*   **Comparison:**
    *   **Manual Fetch:** Runtime error if field is missing.
    *   **OSDK:** Compile-time error if field is accessed incorrectly.

### OSDK 2.0: Modular Loading

The migration to OSDK 2.0 focused on modularity and tree-shaking.

**Lazy Loading:**
Instead of generating a monolithic SDK containing the entire enterprise ontology (which could be gigabytes), OSDK 2.0 allows importing individual object types.

```typescript
import { Student } from "@osdk/my-ontology";
// Only the Student metadata is bundled.
```
This dramatically reduces the initial bundle size of the application.

### Subscriptions: Real-Time Updates

For the "Universal Tutor," you likely need real-time updates (e.g., a student completes a module). The OSDK `subscribe` API enables this.

*   **Mechanism:** It typically utilizes WebSockets to push ontology changes to the client.
*   **State Management:** The subscription callback receives an `Osdk.Instance` which guarantees that the data is fresh. The `onChange` handler must effectively merge this new data into the React state (often using a pattern like useQuery's cache updater).

## 7. Future Language Evolution: TC39

A senior engineer operates not just in the present, but with an eye toward the future standards defined by ECMA Technical Committee 39 (TC39).

### Temporal (Stage 3)

The `Date` object in JavaScript is notoriously broken (mutable, 0-indexed months). The **Temporal** proposal introduces immutable, timezone-aware date/time primitives (`Temporal.Instant`, `Temporal.ZonedDateTime`).

*   **Impact:** For Palantir, which deals heavily with time-series data (e.g., server logs, financial transactions), Temporal will eliminate an entire class of bugs related to timezone conversion and mutation.

### Decorators (Stage 3)

Decorators are moving to Stage 3. While heavily used in Angular/NestJS via TypeScript's "experimental" support, the standard is stabilizing. This will allow for cleaner metaprogramming patterns—e.g., decorating a class method to automatically log execution or validate inputs—without relying on non-standard implementations.

### The Withdrawal of Records and Tuples

An important development in 2025 was the withdrawal of the **Records and Tuples** proposal (immutable primitives like `#{ x: 1 }`).

*   **Why:** Complexity in implementation and performance concerns regarding equality checks (`===`) for deep structures.
*   **Implication:** Developers must continue to rely on libraries (Immutable.js) or disciplined use of `Readonly<T>` types and `Object.freeze` rather than expecting native immutable primitives in the near future.

## 8. Comparison Matrix

| Feature | JavaScript ES6+ | TypeScript | Palantir Usage |
| :--- | :--- | :--- | :--- |
| **Type Safety** | Runtime only (dynamic) | Compile-time (static, structural) | **Critical:** OSDK relies on TS to enforce Ontology schema compliance. |
| **Async** | Promises, Async Iterators | Typed Promises (`Promise<Result>`) | **High:** Async Iterators used for paginated data fetching. |
| **Collections** | Maps, Sets, WeakMaps | Typed Collections (`Map<string, User>`) | **High:** WeakMap used for memoization without leaks. |
| **Metaprogramming** | Proxies, Reflect | Decorators, Mapped Types | **Advanced:** OSDK uses Proxies for property interception. |
| **Tooling** | ESLint | TS Language Server | **Required:** Blueprint relies on TS for prop validation. |

## 9. Common Pitfalls Database

*   **Pitfall: Stale Closures in Hooks.**
    *   **Context:** Using `useEffect` or `useCallback` without correctly listing dependencies.
    *   **Symptom:** The component sees an outdated version of a variable (e.g., an old list of graph nodes) from a previous render cycle.
    *   **Solution:** Exhaustively list dependencies in the dependency array or use the functional update form of `useState` (`setCount(prev => prev + 1)`).
    *   **Palantir Relevance:** High. Debugging "why is my graph not updating" often leads here.

*   **Pitfall: Detached DOM Nodes in Virtualized Lists.**
    *   **Context:** Custom cell renderers in a Blueprint Table that attach event listeners but don't clean them up.
    *   **Symptom:** Memory usage climbs steadily as the user scrolls, eventually crashing the tab.
    *   **Solution:** Ensure every `addEventListener` has a corresponding `removeEventListener` in the cleanup phase of `useEffect`. Use `WeakMap` to associate data with nodes.

*   **Pitfall: Blocking the Event Loop with Data Processing.**
    *   **Context:** Parsing a 50MB JSON payload from OSDK in a single synchronous block.
    *   **Symptom:** The UI freezes (jank) for several seconds.
    *   **Solution:** Chunk the processing using `setTimeout` or `requestIdleCallback` to yield control to the renderer periodically.

## 10. Interview-Ready Q&A Templates

**Q: "Explain TypeScript's structural type system and how it differs from nominal typing. Why is this useful for Palantir?"**
A: "TypeScript uses structural typing, meaning compatibility is determined by the shape of the object (its members), not its explicit class name or declaration. Mathematically, if Set A is a subset of Set B's requirements, it fits. This contrasts with nominal typing (Java), where explicit inheritance is required. For Palantir, structural typing is advantageous because it allows the frontend to be flexible when consuming data from the Ontology. We might receive data objects that have more properties than we need; structural typing allows us to use these objects in our defined interfaces without rigorous mapping or casting, facilitating easier integration of diverse data sources."

**Q: "How would you handle a memory leak in a long-running React application using Blueprint?"**
A: "First, I'd reproduce the leak using the '3-snapshot technique' in Chrome DevTools to establish a baseline and identify objects that persist after garbage collection should have occurred. I'd look specifically for 'Detached DOM nodes,' which often occur when virtualized lists (like Blueprint's Table) unmount rows but retain references via closures or uncleared event listeners. I would ensure all useEffect hooks have cleanup functions and consider moving per-node metadata into a WeakMap so that removing the node automatically allows the data to be garbage collected."

**Q: "What is the `satisfies` operator in TypeScript 5, and when would you use it?"**
A: "The `satisfies` operator validates that an expression matches a type but preserves the most specific type of that expression, preventing type widening. For example, if I have a config object where keys can be strings or numbers, assigning it to `Record<string, string | number>` widens all values to the union. Using `satisfies`, I get validation that I conform to the Record, but TypeScript still knows that `config.timeout` is specifically the number 500. This is crucial for configuration objects in Blueprint or OSDK to maintain strict type safety and autocomplete."


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/02_react_ecosystem.md
# ========================================================
# Comprehensive Research Report on React Ecosystem Core for Palantir Frontend Engineering Interview Preparation

## 1. Executive Summary: The Palantir Frontend Engineering Paradigm

The role of a Frontend Engineer at Palantir Technologies represents a distinct departure from typical web development. While the broader industry often prioritizes metrics such as Search Engine Optimization (SEO), First Contentful Paint (FCP), and mobile-first responsive design for consumer engagement, Palantir’s engineering culture is anchored in the development of "mission-critical" operating systems for the enterprise. This domain, often referred to as "data-dense" application engineering, requires the construction of interfaces that allow users—ranging from intelligence analysts to supply chain managers—to manipulate, visualize, and interpret massive datasets with zero latency and absolute precision.

For a candidate with a background in Mathematics Education and AI/ML systems, specifically one building an intelligent tutoring system like "Universal Tutor," this architectural paradigm aligns closely with the mathematical rigor of graph theory and systems design. The candidate’s experience with Large Language Models (LLMs) and GraphRAG (Retrieval-Augmented Generation) suggests a familiarity with complex data structures; the challenge in the Palantir interview process will be demonstrating the ability to project these complex backend structures onto a performant, interactive frontend surface using React, Blueprint UI, and Redux.

This report provides an exhaustive technical analysis of the three pillars of Palantir’s frontend stack: React 18+ (the view layer), Blueprint UI (the component library), and Redoodle (the state management architecture). Unlike standard web applications where state might be ephemeral, Palantir applications, such as those built on the Foundry platform, function as persistent workspaces. They require architectural patterns that support long-lived sessions, transactional state updates, and the rendering of tens of thousands of data points—a requirement that necessitates deep mastery of virtualization, concurrency, and strict type safety.

The following analysis dissects these technologies not merely as tools, but as an interconnected ecosystem. It explores how React 18’s concurrent features solve the "blocking render" problem in visualization; how Blueprint’s architectural decisions enforce consistency across the Foundry platform; and why Redoodle remains the preferred state management solution over industry-standard alternatives like Redux Toolkit in high-stakes environments. This strategic roadmap is designed to equip the candidate with the depth of insight required to succeed in the Palantir Frontend Engineering interview.

## 2. React 18+ Architecture: The Physics of Concurrent Rendering

The release of React 18 marked a fundamental shift in the library's operational model, transitioning from a synchronous, blocking rendering engine to an asynchronous, interruptible one. For data-dense applications, this is arguably the most significant evolution in frontend engineering in the last decade. Understanding the physics of this change—specifically the interaction between the Fiber architecture and the browser's main thread—is essential for optimizing the heavy visualizations inherent in Palantir’s work.

### 2.1 The Fiber Re-Architecture and Reconciliation

To comprehend the performance implications of React 18 in a project like "Universal Tutor," one must first deconstruct the underlying reconciliation algorithm known as Fiber. Introduced conceptually in React 16 but fully leveraged in React 18, Fiber re-implemented the stack reconciler to support incremental rendering.

#### 2.1.1 The Blocking Rendering Problem

In the legacy "Stack" reconciler, React’s rendering process was recursive and synchronous. Once the reconciliation of a component tree began, it could not be interrupted. For a massive application rendering a table with 5,000 rows of student performance data, this meant that the JavaScript execution stack would block the browser’s main thread for the entire duration of the render—often exceeding the 16.67ms frame budget required for 60fps animation. During this "commit," user inputs such as typing in a search bar or clicking a filter would be queued and ignored, resulting in a perceived "jank" or unresponsiveness.

#### 2.1.2 Cooperative Multitasking via Fiber

Fiber solves this by breaking the rendering work into smaller units of work, or "fibers." A fiber essentially represents a stack frame stored in the heap, allowing React to pause execution, yield control back to the browser to handle high-priority tasks (like input events), and then resume work where it left off.

This mechanism is powered by the Scheduler package, which conceptually utilizes `requestIdleCallback` (or a `MessageChannel` polyfill) to determine the available time remaining in the current frame. In the context of the "Universal Tutor," this means that if a complex Neo4j graph visualization is being calculated, React can pause that calculation every few milliseconds to process a user's keystroke in the search bar, ensuring the interface remains responsive even under heavy computational load. This architectural capability is the foundation of Concurrent React.

### 2.2 Modern Patterns: Transitions and Concurrency

React 18 exposes this concurrent capability through specific APIs that allow developers to categorize state updates by priority. This distinction is critical in dashboard applications where data ingestion (machine speed) often outpaces user interaction (human speed).

#### 2.2.1 startTransition and useTransition

The `useTransition` hook is the primary tool for managing "non-urgent" UI updates. In a typical Palantir application, updates can be bifurcated:

*   **Urgent Updates:** Direct interactions such as typing, clicking, or hovering. These require immediate feedback to maintain the illusion of physical responsiveness.
*   **Transition Updates:** Indirect changes such as filtering a list, rendering a chart, or navigating between tabs. These can be deferred without degrading the user experience.

**Deep Analysis of the Pattern:**
Consider the "Universal Tutor" search interface. A naive implementation updates the search query and the filtered results list synchronously.

```typescript
// Naive / Blocking Approach
const handleSearch = (e) => {
  setQuery(e.target.value); // Urgent
  setResults(heavyFilter(e.target.value)); // Heavy computation, blocks UI
};
```

In this scenario, every keystroke triggers a full re-render of the heavy list, causing the input field to stutter. The Concurrent pattern decouples these updates:

```typescript
// Concurrent / Non-Blocking Approach
import { useState, useTransition } from 'react';

const SearchComponent = () => {
  const [input, setInput] = useState("");
  const [isPending, startTransition] = useTransition();
  const [results, setResults] = useState([]);

  const handleSearch = (e) => {
    // 1. High Priority: Update the input immediately
    const value = e.target.value;
    setInput(value);

    // 2. Low Priority: Mark the filtering as a transition
    startTransition(() => {
      // React treats this state update as interruptible
      const filtered = heavyFilter(value);
      setResults(filtered);
    });
  };

  return (
    <>
      <input value={input} onChange={handleSearch} />
      {isPending && <BlueprintSpinner size={20} />}
      <HeavyResultsList data={results} opacity={isPending ? 0.5 : 1} />
    </>
  );
};
```

**Architectural Implication:** By wrapping the `setResults` call in `startTransition`, React executes the state update in the background. If the user types another character before the background render finishes, React discards the stale work and restarts with the new value. This ensures the input field stays perfectly responsive, a critical requirement for power users in Foundry who perform rapid-fire filtering on large datasets.

#### 2.2.2 useDeferredValue for Data Ingestion

While `useTransition` wraps the setter, `useDeferredValue` wraps the value. This is particularly useful when the component receiving the data does not control the state update, a common pattern in Palantir’s OSDK (Ontology SDK) components where data flows down from a global store.

**Scenario:** A visualization component receives a `nodeList` prop from a parent. Rendering the graph is expensive.

```typescript
const GraphViewer = ({ nodeList }) => {
  // Create a "lagging" version of the prop
  const deferredNodes = useDeferredValue(nodeList);

  return (
    <>
      {/* This updates immediately with the old data or loading state */}
      <GraphStats data={nodeList} /> 

      {/* This updates only when the main thread is free */}
      <ExpensiveGraphLayout nodes={deferredNodes} />
    </>
  );
};
```
This pattern effectively debounces the rendering of the heavy component without the need for manual `setTimeout` or `lodash.debounce`, integrating the delay directly into React’s render lifecycle.

### 2.3 Strict Mode: The Double-Invocation Trap

In React 18, Strict Mode has become significantly more aggressive in development environments to prepare applications for upcoming features like Offscreen API (which allows preserving component state when hidden). Strict Mode intentionally mounts, unmounts, and remounts every component immediately upon creation.

**Lifecycle Sequence in Strict Mode:**
1. Mount: Component renders, effects run.
2. Unmount: Cleanup functions run.
3. Remount: Component renders, effects run again.

**Relevance to Palantir Engineering:**
Palantir applications rely heavily on persistent connections—WebSockets for real-time collaboration, or streaming subscriptions to the Foundry backend.

**The Bug:** A developer initiates a subscription in `useEffect` but forgets the cleanup function.

```typescript
// Incorrect
useEffect(() => {
  const sub = FoundryStream.subscribe(id, onData);
}, [id]);
```

**The Consequence:** In Strict Mode, this code runs twice. The first subscription is never cleaned up. The client now receives duplicate data events for every update, potentially causing race conditions, double-counting in metrics, or server-side resource exhaustion.

**The Fix:** Strict Mode forces developers to write correct cleanup logic, ensuring robust behavior in production where components may be unmounted and remounted by the user (e.g., dragging tabs in a workspace).

### 2.4 Suspense and the Future of Data Fetching

While traditional React apps use `useEffect` for data fetching (often resulting in "waterfall" loading states), the modern pattern shifts towards Suspense. Suspense allows components to "suspend" rendering while waiting for asynchronous operations, delegating the loading UI to a parent Suspense boundary.

In the context of the "Universal Tutor," which likely fetches disparate data chunks (student profile, grade history, current assignment graph), Suspense allows the UI to render the critical shell immediately while streaming in the heavier data segments. This decouples the data fetching logic from the rendering logic, simplifying the component tree and preventing the "flicker" of multiple loading spinners.

### 2.5 Performance Optimization: Beyond React.memo

In data-dense applications, "wasted renders" are the primary enemy of performance. The candidate must demonstrate proficiency not just with `React.memo`, but with the underlying architectural decisions that make memoization effective.

**Referential Integrity Strategy:**
A common pitfall in Blueprint Table implementations is passing inline functions to sub-components.
*   Inefficient: `<Cell renderer={() => format(value)} />` creates a new function reference on every render, defeating `React.memo` inside the Cell.
*   Optimized: Using `useCallback` to create stable function references, or defining renderers outside the component scope.

**Profiling Analysis:**
Mastery of the React DevTools Profiler is expected. The candidate should be able to distinguish between:
*   **Render Duration:** Time spent calculating the tree diff (pure JavaScript). High duration implies expensive logic inside the function body.
*   **Commit Duration:** Time spent applying changes to the DOM. High duration implies too many DOM nodes being mutated (suggesting a need for virtualization).

## 3. Blueprint UI Toolkit: The Visual Operating System

Blueprint (`@blueprintjs/core`, `@blueprintjs/table`) is not merely a styling library; it is a comprehensive UI toolkit designed specifically for desktop-based, data-intensive web applications. Unlike libraries such as Material UI which often target mobile-first consumer experiences, Blueprint assumes the user is an expert analyst requiring high information density, keyboard accessibility, and precision controls.

### 3.1 Design Philosophy: The Analyst's Workstation

The architectural choices in Blueprint reflect the needs of the Palantir user base.

*   **Information Density:** Components are compact by default. A Blueprint Table displays significantly more rows per vertical pixel than a Bootstrap table.
*   **Keyboard Centricity:** Power users operate at the speed of thought. Blueprint enforces rigorous focus management, ensuring that every interactive element—from dropdowns to complex date range pickers—is fully navigable via keyboard.
*   **Accessibility (a11y):** Blueprint manages complex ARIA attributes automatically. For instance, Popover and Dialog components implement "focus traps" to prevent keyboard navigation from leaking into the background, a critical compliance requirement for government and enterprise contracts.

### 3.2 The Table Component: A Virtualized Powerhouse

The `@blueprintjs/table` package is arguably the most critical component for the target role. It is a highly specialized implementation of a data grid, designed to handle datasets scaling to millions of rows without degrading browser performance.

#### 3.2.1 Virtualization Mechanics (Windowing)

Standard DOM elements incur a heavy memory footprint. Rendering a 10,000-row table with 20 columns creates 200,000 DOM nodes, which would crash a browser tab. Blueprint's Table utilizes virtualization (or windowing) to solve this.

**The Virtualization Algorithm:**
1.  **Viewport Calculation:** The component listens to the scroll event and determines the `scrollTop` and container height.
2.  **Row Intersection:** Based on a fixed or variable `rowHeight`, it calculates the index of the first visible row (`floor(scrollTop / rowHeight)`) and the last visible row.
3.  **Buffer Zone:** It adds a "buffer" (overscan) of rows above and below the visible viewport to prevent white flashes during scrolling.
4.  **Absolute Positioning:** It renders only this subset of rows, using `position: absolute` and `transform: translateY(...)` to place them correctly within the massive scrollable container.

This approach ensures that the number of DOM nodes remains constant (O(1)) regardless of the dataset size (O(n)).

#### 3.2.2 Advanced Performance Features: Ghost Cells

A unique feature of the Blueprint Table is `enableGhostCells`. In high-latency environments (like fetching data from a distributed ontology), the user might scroll to a region of the table where data has not yet loaded.

*   **Behavior:** Instead of rendering blank space, `enableGhostCells={true}` instructs the table to render "skeleton" cells—placeholders that mimic the structure of the data (loading bars).
*   **Impact:** This maintains the user's spatial context and perceived performance, even when the underlying data fetch is lagging.

#### 3.2.3 Data Formats and Interaction

The Table supports rich content types beyond simple text.
*   **JSONFormat:** A specialized cell renderer that allows analysts to inspect raw JSON blobs (common in log analysis) directly in the grid. It handles truncation and expansion interactions automatically.
*   **TruncatedFormat:** Computes text width and renders an ellipsis if the content exceeds the cell width, showing the full content in a tooltip on hover. This is computationally expensive if not implemented correctly, highlighting the need for performant `cellRenderer` logic.

### 3.3 The Tree Component and Hierarchical Data

The Tree component handles hierarchical structures, such as the curriculum dependency graph in the "Universal Tutor" or file systems in Foundry Code Repositories.

**Type Safety in Trees:**
Blueprint enforces a strict recursive interface:

```typescript
interface ITreeNode<T = {}> {
    id: string | number;
    label: string | JSX.Element;
    isExpanded?: boolean;
    childNodes?: ITreeNode<T>[];
    nodeData?: T; // Generic payload for application state
}
```

**Scaling Challenges:**
While the standard Tree is robust, it is generally not virtualized. For a tree with thousands of nodes (e.g., a massive ontology), the recursive rendering can cause performance bottlenecks. In such cases, Palantir engineering patterns often involve "flattening" the tree into a linear list with metadata for indentation (`depth` property) and rendering it using a virtualized list adapter (like `react-window`), trading the convenience of the Tree component for the raw performance of a list.

### 3.4 Overlays: Portals and Z-Index Management

Complex applications frequently require layered interfaces—a Dialog opening a Popover which opens a Tooltip. This creates "stacking context" challenges.

#### 3.4.1 The Portal Pattern
Blueprint utilizes React Portals to render overlays (`Popover`, `Dialog`, `Toast`) outside of their parent component's DOM hierarchy, typically appending them to `document.body`. This prevents the overlay from being clipped by `overflow: hidden` on a parent container (e.g., a scrolling sidebar).

#### 3.4.2 Z-Index Wars
Even with Portals, managing the Z-axis is difficult. A common issue arises when a third-party library or custom CSS applies a high z-index to a non-portal element, causing it to bleed through a Blueprint Dialog.

**Mitigation:** Blueprint provides an Overlay manager to enforce stacking order. Developers must avoid manual z-index declarations and instead rely on the strict ordering of the Portal container or Blueprint's Sass variables for layers.

## 4. State Management: Redoodle and Type Safety

While the React ecosystem has largely coalesced around Redux Toolkit (RTK) or React Query, Palantir’s internal ecosystem is built on **Redoodle**. Redoodle is a TypeScript-first wrapper around Redux that solves specific problems related to type safety and refactoring safety in massive monorepos. Mastery of Redoodle is a significant differentiator for a candidate.

### 4.1 The "Typed Action" Paradigm

In standard Redux, there is often a disconnect between the action type (a string literal) and the action payload (an interface). This loose coupling allows bugs where a developer dispatches an action with a missing or malformed payload.

**Redoodle's Solution: TypedAction**
Redoodle fuses the runtime string and the compile-time type into a single definition object.

```typescript
// Redoodle Definition
import { TypedAction } from "redoodle";

// Define the action type string AND the payload interface simultaneously
export const SetTutorProgress = TypedAction.define("TUTOR // SET_PROGRESS")<{
    studentId: string;
    moduleId: string;
    score: number;
}>();
```

**Usage Analysis:**
*   **Dispatching:** `dispatch(SetTutorProgress.create({ ... }))`. The `.create()` method is strongly typed. If the developer forgets `score`, the build fails.
*   **Reducing:** `SetTutorProgress.is(action)` acts as a TypeScript type guard, automatically narrowing the action type in the reducer.

### 4.2 The TypedReducer Builder

Writing switch statements in Redux reducers is verbose and error-prone. Redoodle replaces this with a fluent builder pattern that leverages TypeScript's inference.

```typescript
// Redoodle Reducer
import { TypedReducer, setWith } from "redoodle";

const tutorReducer = TypedReducer.builder<TutorState>()
   .withHandler(SetTutorProgress.TYPE, (state, payload) => {
        // 'payload' is automatically inferred as the specific interface defined above.
        // No manual casting is required.
        return setWith(state, {
            currentScore: payload.score,
            lastActive: Date.now()
        });
    })
   .build();
```
This pattern ensures that any refactor to the action definition immediately propagates errors to the reducer, providing "refactoring safety" across the codebase.

### 4.3 setWith: Surgical Immutability

Immutability is a requirement for Redux, but the spread operator (`...state`) is verbose and performs a shallow copy of the object regardless of whether values changed. Redoodle introduces `setWith`, a utility for "surgical" immutability.

**Mechanism:**
`setWith(target, updates)` performs a shallow equality check on the specific keys being updated.
1.  If `updates.key === target.key`, it does not mutate that key.
2.  If no keys have changed, it returns the original `target` reference.

**Performance Impact:**
This referential stability is crucial for React performance. If a reducer runs but the state doesn't effectively change, `setWith` returns the same object reference. Downstream components wrapped in `React.memo` will see the same prop reference and skip re-rendering. This optimization creates a massive performance aggregate effect in dashboards with hundreds of connected components.

### 4.4 Compound Actions: Transactional State

A unique and powerful feature of Redoodle is the `CompoundAction`. In complex applications, a single user interaction often necessitates updating multiple independent branches of the state tree (e.g., "Reset Workspace" might need to clear filters, reset the graph zoom, and deselect the current node).

**The Problem:** Dispatching three separate actions triggers three notification cycles to the Redux store, causing React to render three times. The intermediate renders might display inconsistent state (e.g., graph is reset but filters are still active).

**The Solution:**
```typescript
// Transactional Dispatch
dispatch(CompoundAction([
    ClearFilters.create(),
    ResetZoom.create(),
    DeselectNode.create()
]));
```

Redoodle's middleware unwraps this compound action, applies all sub-actions to the state sequentially, and then emits a **single** notification to the store. This ensures the UI transitions atomically from State A to State B, preventing "tearing" and improving performance.

### 4.5 Comparison Matrix: Redoodle vs. Redux Toolkit

The candidate must be prepared to articulate why Palantir might choose Redoodle over the industry-standard Redux Toolkit (RTK).

| Feature | Redux Toolkit (RTK) | Redoodle (Palantir) | Engineering Context |
| :--- | :--- | :--- | :--- |
| **Immutability** | Implicit (Immer proxy) | Explicit (`setWith`) | Redoodle avoids the overhead of Immer proxies in tight loops; explicit updates are often preferred for clarity. |
| **Action Types** | Generated via `createSlice` | Explicit `TypedAction.define` | Explicit string constants in Redoodle are better for searching/grepping in massive codebases. |
| **Batching** | Supported (auto in React 18) | Native `CompoundAction` | Redoodle provides explicit transactional control, independent of React's batching logic. |
| **Type Safety** | Good (Inferred) | Excellent (Strict) | Redoodle's generic constraints are stricter, preventing any leaks. |

## 5. Enterprise Architecture: The Foundry Patterns

Developing for Foundry is different from standard web development. The "Foundry as a Backend" philosophy dictates specific frontend patterns.

### 5.1 OSDK: The Ontology Software Development Kit

The OSDK represents the contract between the Palantir backend (Ontology) and the React frontend.

*   **Mechanism:** Instead of manually typing API responses (e.g., `interface Student { ... }`), the OSDK generates TypeScript bindings directly from the Ontology schema defined in Foundry.
*   **Benefit:** If a Data Engineer renames the `grade` property to `score` in Foundry, the frontend CI/CD pipeline will fail immediately during the build process because the generated OSDK types no longer match the frontend code. This provides end-to-end type safety across the stack boundary.

### 5.2 Application Layout Patterns

Palantir applications often employ sophisticated layout engines to manage complexity.

*   **Golden Layout / Mosaic:** Users can often drag and drop panels (Maps, Tables, Charts) to customize their workspace. This requires the frontend to manage a serializable "layout state" in Redux, which reconstructs the window arrangement upon session restore.
*   **Panel Stacks:** A navigation pattern where "drilling down" into data (e.g., clicking a School in a list) slides a new panel in from the right, stacking it on top of the previous one. This preserves the "breadcrumb" context (School -> Class -> Student) visually, allowing the analyst to backtrack easily.

### 5.3 Monorepo and Code Organization

With thousands of engineers contributing to the same codebase, code organization is paramount.

*   **Atomic Design:** Components are strictly categorized into Atoms (buttons), Molecules (search bars), and Organisms (complex widgets).
*   **Barrel Files:** Extensive use of `index.ts` files to strictly control the public API of a module, ensuring that internal helper functions do not leak into the broader codebase.

## 6. Interview Preparation & Practical Application

For the "Universal Tutor" candidate, the interview will likely test the ability to synthesize these technologies.

### 6.1 Coding Challenges
The candidate should be prepared for challenges that test the mechanics of these tools:
*   **Virtualization Implementation:** "Implement a virtualized list from scratch without using a library."
    *   *Key Concepts:* `scrollTop`, `containerHeight`, `itemHeight`, `startIndex = floor(scrollTop / itemHeight)`, `visibleCount = ceil(containerHeight / itemHeight)`.
*   **Redoodle Refactor:** "Take this vanilla Redux reducer and refactor it to use Redoodle's `TypedReducer` and `setWith`."
    *   *Key Concepts:* Type inference, reducing boilerplate, handling undefined state.
*   **Graph Data Transformation:** "Given a raw JSON list of edges and nodes, transform it into an adjacency list optimized for O(1) lookups."

### 6.2 System Design Focus
A likely prompt: "Design a real-time dashboard for the Universal Tutor that displays the learning status of 10,000 active students."

*   **Architecture:**
    *   **Data Layer:** WebSocket connection for real-time updates.
    *   **State:** Redoodle for normalizing student data (`{ [id: string]: Student }`). Use `CompoundAction` to batch updates from the socket (e.g., process 100 updates every 500ms).
    *   **Rendering:** Use Blueprint Table for the list. Use `useTransition` to ensure the filter input remains responsive while the table updates. Use `enableGhostCells` to handle rapid scrolling.
    *   **Visualization:** Use a Canvas-based graph (not DOM) for the "Knowledge Map" to handle high node counts, managed via a React ref.

### 6.3 Behavioral Alignment
The candidate should articulate a mindset of "mission-critical engineering." In consumer apps, a UI bug is an annoyance; in Palantir's domain, it could lead to an incorrect intelligence assessment. The emphasis must be on correctness, reliability, and type safety over aesthetic flair.

## 7. Conclusion

Success in the Palantir Frontend Engineering interview requires demonstrating that one is not just a "React developer," but a systems engineer who works in the browser. The integration of React 18’s concurrent capabilities, Blueprint’s rigorous virtualization and accessibility standards, and Redoodle’s strict type safety creates a powerful triad. For the candidate building the "Universal Tutor," translating their background in AI/ML and mathematics into these specific architectural patterns—viewing the UI as a function of state that must be optimized, virtualized, and strictly typed—is the key to securing the role.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/03_styling_systems.md
# ========================================================
# Enterprise Frontend Styling Architecture – Sass, CSS-in-JS, and the Blueprint Paradigm

## 1. Architectural Foundations of Enterprise Styling

In the domain of high-stakes enterprise software development, specifically within ecosystems like Palantir Foundry or the candidate's proposed "Universal Tutor" project, the architecture of styling systems transcends mere aesthetic definition. It becomes a critical determinant of application performance, maintainability, and scalability. Unlike consumer-facing applications where session times are short and visual flair drives engagement, data-dense enterprise applications prioritize information density, rendering throughput, and long-session stability. The architectural decision between pre-processed CSS (Sass/SCSS) and runtime CSS-in-JS is not a matter of developer preference but a fundamental engineering constraint governed by the browser's rendering pipeline.

For a Frontend Engineer operating within the Palantir ecosystem, particularly one integrating AI/ML workflows and complex graph visualizations (GraphRAG), styling must be viewed as a static asset compilation problem rather than a runtime JavaScript execution problem. The selection of Blueprint UI, which relies exclusively on Sass (Syntactically Awesome Style Sheets), reflects a deliberate prioritization of compile-time resolution over runtime flexibility. This approach minimizes the main-thread blocking that often plagues complex React applications attempting to calculate and inject thousands of style rules dynamically during heavy data updates.

The "Universal Tutor" project, described as an intelligent system leveraging LLMs and Neo4j, implies interfaces that are exceptionally DOM-heavy—likely featuring chat history virtualization, complex node-link diagrams, and dense tabular data. In such environments, the "Style Recalculation" phase of the browser's pixel pipeline becomes a bottleneck. By decoupling style definition from component logic via Sass, engineers ensure that the CSS Object Model (CSSOM) is constructed efficiently and cached, independent of the volatile JavaScript heap utilized by AI response streaming or graph traversals.

This report provides an exhaustive analysis of the styling landscape, dissecting the Sass architecture of Blueprint UI, evaluating the trade-offs of CSS-in-JS in high-performance contexts, and detailing the build engineering required to optimize these systems in a modern stack.

## 2. Deep Dive: Sass/SCSS in the Modern Stack

While the broader frontend industry has seen a proliferation of CSS-in-JS libraries, Sass remains the bedrock of enterprise design systems due to its maturity, performance characteristics, and powerful programmatic features. Understanding Sass in 2024 requires moving beyond basic nesting and variables to mastering its module system, mathematical capabilities, and integration with modern bundlers.

### 2.1 The Philosophy of Pre-processing vs. Runtime Injection

The fundamental distinction of Sass is that it is a pre-processor. The transformation from SCSS (Sassy CSS) to standard CSS happens entirely during the build phase (Tier 3: Webpack/Vite). When the browser receives the application, it receives a static `.css` file.

In contrast, runtime CSS-in-JS libraries (like `styled-components` or `Emotion`) operate as post-processors running in the client's browser. They must parse template literals, generate hashes, check for existing rules, and inject new rules into the DOM's `<style>` tags during component mounting.

For an application like "Universal Tutor," where a user might load a knowledge graph with 5,000 nodes, a CSS-in-JS approach would require the JavaScript engine to execute 5,000 hashing operations and potentially trigger layout thrashing. Sass, conversely, delivers a single class name (e.g., `.graph-node`) which the browser's native C++ styling engine matches against the pre-parsed CSSOM in microseconds. This O(1) matching vs. O(N) generation is the mathematical justification for Sass in data-dense tooling.

### 2.2 Core Sass Fundamentals for System Architecture

To effectively architect within Blueprint's ecosystem, one must leverage specific Sass features that enable scalable design system tokens.

#### 2.2.1 The Configuration-First Pattern (`!default`)

The `!default` flag is the cornerstone of library theming in Sass. Unlike standard variable assignment where the last declaration wins, `!default` assigns a value to a variable only if it is currently undefined or null.

This mechanism allows Blueprint to expose its entire design system as overridable configuration.

```scss
// Blueprint Internal Source (simplified)
$pt-intent-primary: #137cbd !default;
$pt-grid-size: 10px !default;
```

If a developer imports Blueprint directly, these defaults are used. However, by defining variables *before* the import, the developer injects their own "Universal Tutor" theme into the library's build process without modifying the library code.

```scss
// application.scss
// 1. Configuration Layer
$pt-intent-primary: #D13913; // Tutor Brand Color
$pt-font-family: "Inter", sans-serif;

// 2. Library Import Layer
@import "~@blueprintjs/core/lib/scss/variables";
@import "~@blueprintjs/core/lib/scss/blueprint";
```
This pattern enforces a strict dependency flow: Configuration $\rightarrow$ Library $\rightarrow$ Output. It prevents the specificity wars that occur when developers try to override library styles using CSS selectors (`!important` or high-specificity chains) after the fact.

#### 2.2.2 Sass Maps and Algorithmic Style Generation

In complex applications, managing individual variables becomes unwieldy. Sass Maps allow for the grouping of related tokens, enabling algorithmic style generation via loops (`@each`). Blueprint uses maps to manage Intent colors (Primary, Success, Warning, Danger) and breakpoints.

For the "Universal Tutor," this is vital for generating utility classes for AI confidence scores.

```scss
// Define a map for AI Confidence levels
$confidence-levels: (
  "high": #0F9960,
  "medium": #D9822B,
  "low": #DB3737,
  "uncertain": #738694
);

// Generate atomic utility classes programmatically
@each $level, $color in $confidence-levels {
 .tutor-confidence-#{$level} {
    border-left: 4px solid $color;
    background-color: rgba($color, 0.1);
  }
}
```
This keeps the CSS codebase DRY (Don't Repeat Yourself) and ensures that if the color palette for "uncertainty" changes, it propagates to all relevant UI components (borders, backgrounds, text badges) automatically upon the next build.

#### 2.2.3 Mixins for Cross-Browser and Complexity Management

Mixins function as the "functions" of the styling world, encapsulating complex logic that outputs CSS properties. Blueprint utilizes mixins heavily to manage typography stacks, focus states, and browser-specific hacks (e.g., specific scrollbar styling for WebKit vs. Firefox).

A critical mixin for "Universal Tutor" would be the text overflow mixin. In data grids displaying LLM outputs, text must often be truncated.

```scss
@mixin text-overflow() {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}
```
While simple, centralizing this in a mixin allows for future enhancements (e.g., switching to multi-line clamping via `-webkit-line-clamp` when browser support thresholds are met) across the entire application simultaneously.

### 2.3 The Evolution of Modules: `@import` vs. `@use`

The Sass ecosystem is undergoing a major transition from the global scope model (`@import`) to the modular scope model (`@use`). Blueprint, having evolved over many years, currently straddles this divide, with active migration efforts towards `@use` in v5.

**The Legacy `@import` Problem:**
In the `@import` model, every variable defined in a partial becomes globally available to any file that imports it, and any file that imports that file. This leads to namespace pollution and implicit dependencies. If `_buttons.scss` imports `_variables.scss`, and `_app.scss` imports `_buttons.scss`, `_app.scss` accidentally has access to all variables, making refactoring dangerous.

**The Modern `@use` Solution:**
The `@use` rule loads a mixin, function, or variable from another Sass file as a *module*.

```scss
@use "@blueprintjs/core/lib/scss/variables" as bp;

.tutor-card {
  padding: bp.$pt-spacing * 2; // Explicit namespacing
  background: bp.$pt-app-background-color;
}
```
This encapsulation is critical for the "Universal Tutor" if it scales to a monorepo structure. It ensures that the styles for the "Graph Visualization" module do not accidentally clobber the variables for the "Chat Interface" module. It aligns Sass development with the scoping principles of TypeScript and ES Modules (Tier 1 technologies).

### 2.4 Mathematical Operations and `sass:math`

Sass provides robust mathematical capabilities, which Blueprint leverages for its grid system. In older versions, simple division (`/`) was used, but this is being deprecated in favor of `math.div`.

For an application utilizing D3.js (Tier 4) for visualizations, Sass math allows for the creation of layout containers that perfectly align with the calculated aspect ratios of the SVG charts.

```scss
@use "sass:math";

// Calculating a 16:9 aspect ratio container for a graph
.graph-container {
  height: 0;
  padding-bottom: math.percentage(math.div(9, 16));
  position: relative;
}
```
This interoperability between styling logic and mathematical layout constraints is a subtle but powerful feature of Sass in data-viz heavy applications.

## 3. The Blueprint UI Styling Ecosystem

Blueprint UI is arguably the most sophisticated Sass-based React framework in open source. Unlike Material-UI, which migrated to CSS-in-JS (Emotion), Blueprint stayed the course with Sass, optimizing for the desktop-application paradigm of Palantir Foundry. Analyzing its structure reveals the patterns required to build similar enterprise-grade interfaces.

### 3.1 Directory Structure and Source Organization

Blueprint's source code organization is designed for discoverability and modularity.
*   `_variables.scss`: The "API" of the styling system. It defines all configurable tokens but emits no CSS.
*   `_colors.scss`: A pure palette definition file (e.g., `$vermilion1` through `$vermilion5`). These are strictly raw values, never semantic tokens.
*   `common/`: Contains the "glue" of the system—reset styles (normalize.css), mixins, and foundational typography.
*   `components/`: Each React component (e.g., Button, Dialog) has a dedicated SCSS partial (e.g., `_button.scss`).

For the "Universal Tutor" project, adopting this structure is recommended. It separates Abstracts (variables, mixins) from Implementations (component styles), preventing circular dependencies.

### 3.2 The Semantic Variable Layer

Blueprint uses a tiered variable architecture:
1.  **Primitive Layer:** Raw colors (`$blue3: #106ba3`).
2.  **Semantic Layer:** Intent variables (`$pt-intent-primary: $blue3`).
3.  **Component Layer:** Component-specific variables (`$pt-button-background-color: $pt-intent-primary`).

This abstraction allows for safe theming. If the design team decides "Primary" should be Teal instead of Blue, changing the mapping at the Semantic Layer propagates correctly to all components (Buttons, Inputs, Spinners) without needing to find-and-replace specific hex codes.

### 3.3 The Grid System Migration (10px to 4px)

A critical piece of historical context for Blueprint is the migration from a 10px grid (`$pt-grid-size`) to a 4px grid (`$pt-spacing`).
*   **Legacy (v3):** `$pt-grid-size: 10px`.
*   **Modern (v4/v5):** `$pt-spacing: 4px`.

This shift aligns Blueprint with the industry-standard 8pt grid system (where 1 unit = 4px, 2 units = 8px). For the "Universal Tutor," maintaining strict adherence to `$pt-spacing` multiples is vital for visual rhythm.

```scss
// Correct usage in Blueprint v4+
padding: $pt-spacing * 2; // 8px
margin-bottom: $pt-spacing * 4; // 16px
```
Linting rules in `@blueprintjs/stylelint-plugin` specifically enforce this, offering auto-fixers to convert legacy `$pt-grid-size` math to the new system (e.g., converting `$pt-grid-size` to `$pt-spacing * 2.5`).

### 3.4 BEM Naming and Namespacing

To prevent style leakage—a notorious problem in global CSS—Blueprint uses a strict BEM (Block Element Modifier) convention prefixed with a namespace.
*   **Namespace:** `bp4-` (controlled by `$ns` variable).
*   **Block:** `.bp4-button`
*   **Element:** `.bp4-button-text`
*   **Modifier:** `.bp4-minimal`

This rigorous naming convention allows Blueprint components to coexist on a page with legacy Bootstrap code or other libraries without collision. For "Universal Tutor," which might embed third-party educational widgets, this isolation is critical.

### 3.5 Dark Mode Architecture

Palantir's "Foundry" is natively dark-themed. Blueprint handles this via a containment strategy rather than a media-query-only strategy.
*   **Mechanism:** A parent class `.bp4-dark` is applied to a container (or body).
*   **Implementation:** Component styles define overrides nested within this selector.

```scss
.bp4-button {
  background: $light-bg;
  .bp4-dark & { // Sass parent selector reference
    background: $dark-bg;
  }
}
```
This approach, while slightly increasing CSS bundle size due to duplication, allows for nested themes. A "Universal Tutor" dashboard could be dark mode, but contain a "Document Preview" pane that forces light mode (by removing the class or adding `.bp4-light`), mimicking a sheet of paper. This flexibility is difficult to achieve with simple `prefers-color-scheme` media queries.

### 3.6 Migration to CSS Custom Properties (v5)

Blueprint v5 represents a paradigm shift towards a hybrid architecture. While Sass generates the CSS structure, the values are increasingly being delegated to CSS Custom Properties (Variables).

*   **Pattern:** `$pt-intent-primary: var(--bp-intent-primary, #137cbd);`
*   **Benefit:** This allows for runtime theming without JavaScript style injection. The "Universal Tutor" could offer a "Dyslexia Friendly" mode that updates font and spacing variables on the `:root` element, and the browser repaints the UI instantly without a single React render cycle.

The `generate-css-variables` script in Blueprint's build tooling creates these mappings automatically, ensuring that the Sass variables and CSS variables stay in sync.

## 4. Build Systems and Performance Engineering

The efficacy of a Sass-based architecture relies heavily on the efficiency of the build pipeline. In Tier 3 of the candidate's stack (Webpack, Vite), configuration choices can degrade build times from seconds to minutes if managed poorly.

### 4.1 The Compiler Implementation: `sass` vs. `sass-embedded`

A critical optimization for large Sass codebases is the choice of compiler implementation.
*   **Legacy (Node Sass):** Based on LibSass (C++). Deprecated. Fast but difficult to maintain.
*   **Standard (Dart Sass - JS):** The `sass` npm package. It compiles the Dart source code to pure JavaScript. It runs on the V8 engine. While portable, it is slow for deep dependency trees like Blueprint's.
*   **Optimized (Dart Sass - Embedded):** The `sass-embedded` npm package. It wraps the native Dart executable and communicates with Node.js via a protocol buffer.

**Performance Benchmark:**
Research indicates that `sass-embedded` can be 3x to 10x faster than the pure JS `sass` implementation for complex compilations. For a project like "Universal Tutor," likely a monorepo with multiple packages, using `sass-embedded` is a mandatory optimization to keep CI/CD pipelines efficient.

### 4.2 Webpack Configuration (`sass-loader`)

In a Webpack environment, the `sass-loader` must be configured to use the embedded compiler.

```javascript
// webpack.config.js - Tier 3 Optimization
module.exports = {
  module: {
    rules: [
      {
        test: /\.s[ac]ss$/i,
        use: [
          // Creates `style` nodes from JS strings
          "style-loader",
          // Translates CSS into CommonJS
          "css-loader",
          // Compiles Sass to CSS
          {
            loader: "sass-loader",
            options: {
              implementation: require("sass-embedded"),
              sassOptions: {
                quietDeps: true, // Silence warnings from node_modules
              },
            },
          },
        ],
      },
    ],
  },
};
```
Using `MiniCssExtractPlugin` in production is crucial. It pulls the CSS into a separate file, allowing the browser to download styles in parallel with the JavaScript bundle, improving the First Contentful Paint (FCP).

### 4.3 Vite Configuration

Vite (Tier 3), which uses Rollup for production builds, also supports this optimization but requires specific configuration in the `css.preprocessorOptions` block.

```javascript
// vite.config.ts
export default defineConfig({
  css: {
    preprocessorOptions: {
      scss: {
        api: 'modern-compiler', // Opt-in to modern Sass API
        implementation: require('sass-embedded'),
        quietDeps: true,
      },
    },
  },
});
```
Failing to set `api: 'modern-compiler'` in Vite 5.4+ forces the bundler to use the legacy API, which negates the performance benefits of the embedded compiler.

### 4.4 Source Maps and Debugging

Source maps connect the generated CSS back to the original SCSS partials.
*   **Dev Mode:** `cheap-module-source-map` (Webpack) or default Vite maps. Essential for identifying which Blueprint partial (e.g., `_common.scss:45`) is causing a style issue.
*   **Prod Mode:** Generating source maps in production is a security and performance trade-off. For enterprise apps, they are often disabled to prevent exposing the full source structure, or generated as hidden `.map` files only accessible to error tracking services (e.g., Sentry).

## 5. Comparative Analysis: Sass vs. CSS-in-JS

The architectural choice between Blueprint's Sass approach and CSS-in-JS (Tier 2) defines the runtime performance profile of the application.

### 5.1 The Browser Rendering Pipeline

To understand the trade-offs, one must analyze the browser's pixel pipeline:
1.  Parse HTML $\rightarrow$ DOM Tree.
2.  Parse CSS $\rightarrow$ CSSOM Tree.
3.  Combine $\rightarrow$ Render Tree.
4.  Layout (Geometry calculation).
5.  Paint (Pixel filling).

*   **Sass (Static CSS):**
    The CSSOM is constructed once when the `.css` file loads. Class name matching is extremely fast (C++ engine). JavaScript execution does not block styling.

*   **CSS-in-JS (Runtime):**
    Libraries like `styled-components` insert themselves into the JavaScript execution.
    1.  Component Mounts.
    2.  Library hashes props to generate a class name.
    3.  Library checks cache.
    4.  Library injects generic style rule into a `<style>` tag.
    5.  Browser Recalculates Styles.
    6.  Browser Reflows (Layout).

### 5.2 Performance at Scale: The "10,000 Elements" Problem

Benchmarks involving large lists (e.g., 10,000 rendered items—common in "Universal Tutor" datasets) reveal significant discrepancies.
*   **Sass/CSS Modules:** Zero overhead per item. The class `.item` already exists.
*   **Runtime CSS-in-JS:** Even with caching, the overhead of the library's runtime checks and the potential for "Layout Thrashing" (inserting rules forcing recalculations) can cause frame rates to drop below 60fps.

**Data:** Studies show pure CSS/Sass approaches render large lists ~20-30% faster than runtime styling libraries.

### 5.3 Zero-Runtime CSS-in-JS: The Middle Ground?

Newer generation libraries like **Linaria** or **Vanilla Extract** allow developers to write CSS-in-JS syntax but extract it to static `.css` files at build time. This offers the Developer Experience (DX) of TypeScript-typed styles with the performance of Sass.

However, Blueprint's architecture is deeply rooted in Sass. Migrating a Blueprint-based app to a Zero-Runtime library would require essentially rewriting the entire design system logic. For a Palantir FDE, the pragmatic choice is to embrace Sass for the "Macro" system (Layout, Core Components) and perhaps reserve CSS-in-JS only for highly dynamic, state-driven "Micro" interactions where the number of elements is low.

### 5.4 Comparison Matrix

| Feature | Sass (Blueprint Architecture) | Runtime CSS-in-JS (Styled-Components) | Zero-Runtime CSS-in-JS (Linaria/Vanilla Extract) |
| :--- | :--- | :--- | :--- |
| **Parsing Time** | Fast (Browser Native) | Slow (JS Parsing + CSSOM Injection) | Fast (Browser Native) |
| **Render Blocking** | No (Parallel Load) | Yes (JS Execution) | No (Parallel Load) |
| **Dynamic Theming** | CSS Variables (Good) | Prop Interpolation (Excellent) | CSS Variables (Good) |
| **Bundle Size** | Moderate (May include unused) | Good (Critical CSS only) | Moderate (Static Extraction) |
| **Type Safety** | Low (Global String Classes) | High (TypeScript Prop integration) | High (TypeScript Interfaces) |
| **Debugging** | Clear Source Maps | Obfuscated Hashes (e.g., `sc-gKhV`) | Clear Class Names |

## 6. Advanced Theming and Design Token Architecture

For "Universal Tutor," a raw dependency on Blueprint variables creates tight coupling. Enterprise best practice involves a semantic abstraction layer known as **Design Tokens**.

### 6.1 The Tiered Token System

An effective enterprise styling architecture utilizes three tiers of tokens.

*   **Tier 1: Primitives (The "Reference" Layer)**
    These are the raw values provided by Blueprint or the brand guidelines.
    *   `$blue3: #106ba3`
    *   `$gray1: #202b33`
    *   `$pt-spacing: 4px`

*   **Tier 2: Semantics (The "System" Layer)**
    This layer maps primitives to abstract concepts. This is where the "Universal Tutor" design system lives.
    *   `$tutor-action-primary: $blue3`
    *   `$tutor-surface-background: $gray1`
    *   `$tutor-grid-gap: $pt-spacing * 2`

*   **Tier 3: Component (The "Scoped" Layer)**
    Specific mappings for UI elements.
    *   `$chat-bubble-background: $tutor-surface-background`
    *   `$submit-button-color: $tutor-action-primary`

**Why this matters:**
If Palantir updates Blueprint and `$blue3` changes shade slightly, the entire app updates automatically. If the "Universal Tutor" branding changes from Blue to Purple, developers only update the mapping at Tier 2 (`$tutor-action-primary: $purple3`), and the change cascades safely to all Tier 3 components.

### 6.2 Implementation with Sass Maps

Sass maps are the ideal data structure for managing these tokens.

```scss
// _tokens.scss
$tutor-colors: (
  "action": (
    "primary": $blue3,
    "secondary": $gray3
  ),
  "feedback": (
    "correct": $green3,
    "incorrect": $red3
  )
);

// Accessor Function
@function tutor-color($category, $variant) {
  @return map.get(map.get($tutor-colors, $category), $variant);
}

// Usage
.feedback-message {
  color: tutor-color("feedback", "correct");
}
```
This programmatic approach reduces "Magic Values" (hardcoded hex codes) and enforces design consistency.

## 7. Accessibility and Interaction Design

Accessibility (Tier 4) is a non-negotiable requirement for enterprise software, mandated by legal standards (Section 508, WCAG). Blueprint provides sophisticated tools to manage this, specifically around Focus and Contrast.

### 7.1 The Focus Management Problem

A common conflict in frontend development is between Design (who dislike the default blue browser outline on clicks) and Accessibility (who require visible focus for keyboard navigation).
*   **Naive Solution:** `*:focus { outline: none; }`. This is an accessibility violation. Keyboard users lose their place on the page.
*   **Blueprint Solution:** `FocusStyleManager`.

### 7.2 Blueprint's FocusStyleManager

The `FocusStyleManager` is a JavaScript utility that monitors event types.
*   **Logic:** If the user interacts via mouse (mousedown), it adds a class (e.g., `.bp4-focus-disabled`) to the document body. If the user hits Tab, it removes that class.
*   **CSS Implementation:**
    ```scss
    body.bp4-focus-disabled :focus {
      outline: none; // Safe to hide, as user is using mouse
    }
    ```
This ensures that mouse users see a clean UI, while keyboard users immediately get high-contrast focus rings when they start tabbing. Integrating this into the "Universal Tutor" root component (`FocusStyleManager.onlyShowFocusOnTabs()`) is a "Day 1" task.

### 7.3 High Contrast Mode and forced-colors

Users with visual impairments often use Windows High Contrast Mode, which overrides all background colors to black or white.
*   **The Risk:** Buttons often rely on background color to denote boundaries. If the background is forced to black, a black button on a black background becomes invisible.
*   **The Fix:** The `@media (forced-colors: active)` query.

Blueprint includes mixins that add transparent borders to interactive elements.

```scss
@mixin high-contrast-border {
  @media (forced-colors: active) {
    border: 1px solid ButtonText; // System keyword, adapts to user theme
  }
}
```
In High Contrast mode, the transparent border becomes visible (solid color), restoring the button's boundaries. This level of detail in Blueprint's SCSS is why it is preferred for government and enterprise deployments over lighter-weight libraries.

### 7.4 WCAG Contrast Compliance

Blueprint's color palette is tuned for contrast. The standard variables (`$blue3`, `$dark-gray5`) are designed to meet WCAG AA (4.5:1) ratios when used in standard combinations (e.g., Light Gray text on Dark Gray background).

However, when customizing the "Universal Tutor" theme, the candidate must verify custom colors.
*   **Sass Helper:**
    ```scss
    // Theoretical Sass function for contrast check
    @function ensure-contrast($bg, $fg) {
       // Logic to calculate luminance and warn if ratio < 4.5
    }
    ```
While Blueprint doesn't enforce this at build time, using the browser's "Rendering" tab to emulate vision deficiencies is a required workflow step.

## 8. Integration with the "Universal Tutor" Stack

The styling system does not exist in a vacuum; it must integrate with React, D3.js, and the broader data architecture.

### 8.1 React and `className` composition

Blueprint components accept a `className` prop. The standard pattern for applying custom styles is string concatenation or the `classnames` utility library.

```typescript
import classNames from "classnames";
import { Button } from "@blueprintjs/core";
import styles from "./TutorChat.module.scss"; // CSS Modules approach

const ChatButton = ({ isActive }) => (
  <Button
    className={classNames(styles.chatButton, {
      [styles.active]: isActive
    })}
    intent="primary"
  />
);
```
This blends Blueprint's internal styles (via the Button component) with the application's scoped styles (`styles.chatButton`).

### 8.2 D3.js and SVG Styling

D3.js (Tier 4) generates SVG DOM elements. While D3 can manipulate styles directly (`.style("fill", "red")`), this bypasses the Sass theme.
*   **Best Practice:** Use D3 to assign classes, and use Sass to define the visuals.
    *   **D3:** `.attr("class", "graph-node data-point")`
    *   **Sass:**
        ```scss
        .graph-node {
          fill: $pt-intent-primary;
          transition: fill 200ms ease-in-out;
          &.data-point {
            stroke: $white;
          }
        }
        ```
This ensures that if the "Universal Tutor" switches to Dark Mode, the D3 graph updates automatically (because `$pt-intent-primary` changes definition in the dark context), keeping the visualization consistent with the UI.

### 8.3 Shadow DOM and CSS Variables

If parts of the "Universal Tutor" are encapsulated in Web Components (e.g., an embeddable widget for third-party LMS platforms), Sass variables cannot penetrate the Shadow DOM boundary.

This is where Blueprint v5's CSS variables (`--bp-intent-primary`) shine. CSS variables *do* pierce the Shadow DOM by default (inheriting from the host). This makes the v5 migration strategically important for embedding scenarios.

## 9. Comprehensive Interview Preparation

The following Q&A section provides deep, expert-level responses suitable for a Palantir systems interview.

### 9.1 Architectural Defense Questions

**Q1: "Why does Palantir/Blueprint persist with Sass when the industry has moved to CSS-in-JS? Isn't Sass 'legacy'?"**
**Answer:** "It's a decision based on the specific constraints of data-dense applications. While CSS-in-JS offers great ergonomics for component colocation, it incurs a runtime penalty—O(N) style injection cost—that becomes prohibitive when rendering thousands of elements in a Foundry-like interface. Sass compiles to static CSS, offloading the cost to the build server. This ensures that the browser's main thread is free to handle complex JavaScript logic, such as parsing the AI responses in the Universal Tutor, rather than recalculating styles. Furthermore, Sass's mature module system allows for a rigorous 'Configuration-as-Code' approach to theming that is harder to achieve with runtime libraries."

**Q2: "How would you handle a requirement for the 'Universal Tutor' to support user-customizable themes (e.g., high-contrast, color-blind safe, or branded) without causing page reloads?"**
**Answer:** "I would implement a hybrid architecture using Blueprint v5 patterns. I would define the structural styles using Sass (layout, grid, typography scale) but map the values to CSS Custom Properties (e.g., `background-color: var(--tutor-bg)`). To switch themes, I would simply update the values of these variables on the `document.documentElement` via a lightweight JavaScript service. This triggers a browser-native repaint, which is hardware accelerated and instant, avoiding the need to traverse the React component tree and re-render components as a ThemeProvider context update would."

### 9.2 Technical Implementation Questions

**Q3: "We are seeing slow build times in our CI pipeline. The profiler points to the Sass compilation step. How do you fix this?"**
**Answer:** "First, I would verify which Sass implementation we are using. If we are using the pure JavaScript `sass` package, we are bottlenecked by the V8 engine. I would migrate the build configuration (Webpack or Vite) to use `sass-embedded`, which wraps the native Dart executable and can speed up compilation by 3-10x. Second, I would audit the codebase for legacy `@import` usage, which can cause duplicate file processing, and migrate to `@use`, which processes modules once. Finally, I'd check if `quietDeps: true` is enabled to prevent the logger from writing thousands of deprecation warnings from `node_modules` to the console, which is a surprisingly common performance killer."

**Q4: "Explain how you would ensure the 'Universal Tutor' is accessible to keyboard users who are also visually impaired."**
**Answer:** "I would approach this from three angles. First, **Focus Management**: I'd initialize Blueprint's `FocusStyleManager` to ensure high-visibility focus rings appear only during keyboard navigation, preventing design pushback while ensuring compliance. Second, **Semantic Structure**: I'd ensure the app uses proper ARIA landmarks so screen readers can navigate the layout. Third, **High Contrast Support**: I would use the `@media (forced-colors: active)` query to add transparent borders to buttons and inputs. This ensures that when Windows High Contrast mode strips background colors, the interactive elements remain visible via their borders. I would test this using the Accessibility Tree inspector in Chrome and actual screen reader emulation."

**Q5: "How do you organize styles in a monorepo where multiple apps share the same design system but need slight variations?"**
**Answer:** "I would use a tiered Design Token architecture. I'd create a shared `core-design` package exporting the Sass primitives (Tier 1) and semantic maps (Tier 2). Each application (e.g., 'Tutor-Student', 'Tutor-Admin') would import these tokens but apply their own configuration layer. I would use Sass's `!default` mechanism to allow the apps to override specific variables (like `$primary-color`) *before* loading the core library. This allows for a shared codebase but distinct visual identities, managed entirely at the build configuration level."

### 9.3 Coding Challenge Strategy

**Task:** Create a Sass mixin that generates a responsive grid container that changes padding based on Blueprint's breakpoints, and supports a 'dense' mode.

```scss
// Import Blueprint variables as a module
@use "@blueprintjs/core/lib/scss/variables" as bp;

// Define the mixin
@mixin responsive-container($is-dense: false) {
  // Base Padding: 4 units (16px) standard, 2 units (8px) dense
  $base-padding: if($is-dense, bp.$pt-spacing * 2, bp.$pt-spacing * 4);
  
  padding: $base-padding;
  width: 100%;
  
  // Tablet Breakpoint
  @media (min-width: bp.$pt-breakpoint-tablet) {
    padding: $base-padding * 1.5; // Scale up
  }
  
  // Desktop Breakpoint
  @media (min-width: bp.$pt-breakpoint-desktop) {
    padding: $base-padding * 2;
    max-width: 1200px;
    margin: 0 auto; // Center content
  }
}

// Usage in component
.tutor-dashboard {
  @include responsive-container($is-dense: false);
}

.tutor-sidebar-widget {
  @include responsive-container($is-dense: true);
}
```
This code demonstrates knowledge of:
*   Blueprint Modules (`@use`).
*   Blueprint Variables (`$pt-spacing`, `$pt-breakpoint-*`).
*   Sass Logic (`if` statements).
*   Responsive Design Patterns.

## 10. Conclusion

For the "Universal Tutor" project, the styling system is a foundational architectural component that dictates the user experience. By leveraging Sass for its compile-time performance and Blueprint UI for its robust enterprise patterns, the development team can build an interface that remains fluid and responsive even under the load of massive datasets and complex AI visualizations. The path forward involves embracing the `sass-embedded` compiler for build performance, adopting CSS Variables for runtime theming flexibility, and rigorously enforcing Accessibility standards through Blueprint's specialized utilities. This combination ensures that the application meets the rigorous engineering standards expected within the Palantir ecosystem.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/04_data_layer.md
# ========================================================
# Comprehensive Analysis of Data Layer Architectures: React Query, GraphQL, and REST Integration in Palantir Foundry Enterprise Platforms

## Executive Summary

The engineering of a robust data layer constitutes the most critical architectural challenge in modern enterprise application development. For a Frontend Engineer (FDE) operating within the Palantir Foundry ecosystem, the "Data Layer" is not merely a transport mechanism for JSON payloads; it is the semantic nervous system that translates an organization's "Digital Twin"—its Ontology—into actionable, decision-centric user interfaces. This report provides an exhaustive, textbook-level analysis of the data architectures essential for the target role. It explores the dichotomy, coexistence, and convergence of REST and GraphQL paradigms, the evolution of state management from synchronous client stores to asynchronous server-state caches (React Query), and the specific implementation details of the Ontology Software Development Kit (OSDK).

Furthermore, given the candidate's background in Mathematics Education and AI/ML systems (GraphRAG, Neo4j), this document synthesizes theoretical graph concepts with practical engineering patterns. It addresses the critical performance challenges inherent in data-dense applications—a hallmark of Palantir's "Universal Tutor" and "Skywise" class projects—providing deep architectural insights into virtualization, server-side aggregation strategies, and real-time synchronization. This document serves as the authoritative reference for Group 4 of the interview preparation strategy, rigorously mapping the candidate's expertise in React, TypeScript, and Blueprint UI to the specialized demands of the Palantir stack.

## 1. Enterprise Data Architecture Principles & The Palantir Context

To engineer effective frontends for platforms like Foundry, one must first master the architectural principles governing how data flows from distributed backend systems (often massive Spark clusters, data lakes, or time-series databases) to the client browser. The industry has moved beyond simple CRUD (Create, Read, Update, Delete) operations toward semantic interaction models that prioritize data lineage, type safety, and graph traversal.

### 1.1. The Operational Context: From Data Lake to Ontology

Traditional web development often interacts directly with database rows via REST endpoints. However, Palantir Foundry introduces an intermediate semantic layer known as the **Ontology**. The Ontology maps raw technical data (tables in a data lake, stream topics, unstructured files) into business-centric concepts called **Object Types** (e.g., Student, Lesson, Aircraft) and **Link Types** (e.g., Student *takes* Lesson).

This distinction is crucial for the Data Layer architecture. The frontend does not query a "database"; it queries a "knowledge graph" of the enterprise. This requires a shift in mental models:
*   **Semantic Consistency:** Data is not just "fetched"; it is resolved against a strict schema that enforces business logic.
*   **Kinetic Actions:** Writes are not simple POST requests; they are **Actions**—transactional units of logic that may trigger side effects, validations, and write-backs to external ERP systems.
*   **Graph Traversal:** Data retrieval often involves traversing edges (Links) rather than joining tables, aligning perfectly with the candidate's experience in Neo4j and GraphRAG.

### 1.2. The Hybrid Paradigm: Coexistence of REST and GraphQL

While the industry often debates "REST vs. GraphQL" as a binary choice, enterprise platforms like Foundry invariably employ a Hybrid Architecture. The specific requirements of the "Universal Tutor" project—handling massive student datasets alongside complex knowledge graphs—necessitate understanding where each protocol excels.

*   **REST (The Control Plane):** REST is the backbone of infrastructure management. In Foundry, REST APIs are used for operations that are resource-centric and verb-oriented. Managing the lifecycle of a dataset, triggering a batch pipeline build, or configuring permission sets are inherently RESTful operations. They map cleanly to HTTP verbs (POST to create a schedule, DELETE to remove a schema) and benefit from the simplicity of HTTP status codes and caching headers.
*   **GraphQL (The Data Plane):** GraphQL is the engine of the Ontology. When a frontend application needs to display a "Student Profile" that includes their "Name" (property), their "Recent Quiz Scores" (linked objects), and the "Recommended Curriculum" (linked objects of linked objects), REST fails due to the N+1 problem. GraphQL allows the client to define a selection set that traverses this graph in a single network request. It shifts the complexity of data assembly from the client to the server, which is critical for performance in data-dense applications.

**Strategic Insight:** A successful Palantir FDE candidate must demonstrate the architectural maturity to discern which tool to use. One would use REST to upload a new video file for a lesson (a binary resource operation), but use GraphQL (via OSDK) to query the relationship between that video and the learning outcomes it satisfies (a graph operation).

### 1.3. The State Management Revolution: Client vs. Server State

A pivotal concept in modern React architecture is the strict separation of **Client State** from **Server State**. This distinction is often the defining factor between a fragile, buggy application and a robust enterprise platform.

*   **Client State:** Data that originates in the browser and is owned by the user's session. Examples include the state of a modal (open/closed), the value of a text input before submission, or the currently selected theme. This state is synchronous, local, and transient. Libraries like Redux (TIER 2) or React Context are appropriate here.
*   **Server State:** Data that is persisted remotely and is only "borrowed" by the client. Examples include the list of Students, the current metrics of an Aircraft, or the text of a Lesson. This state is asynchronous, shared (multi-user), and potentially "stale" the moment it arrives in the browser.

**The Redux Anti-Pattern:** In the previous generation of React development (c. 2016-2019), developers used Redux to manage server state. This necessitated immense boilerplate: distinct actions for `FETCH_REQUEST`, `FETCH_SUCCESS`, and `FETCH_FAILURE`; complex thunks or sagas to handle asynchronous flows; and manual logic to determine when to re-fetch data. This approach conflated caching with state management, leading to bugs where data would become stale without the UI "knowing" it needed to update.

**The Modern Solution:** Libraries like **React Query (TanStack Query)** and Apollo Client treat server data as a **Cache**, not State. They abstract the complexity of fetching, deduping, caching, and revalidating data. Palantir's modern frontend stacks heavily favor this pattern—often wrapped within the Ontology SDK (OSDK)—to manage the immense complexity of Foundry data without bloating the client-side code.

## 2. REST API Fundamentals: The Backbone of Integration

Although modern Foundry development often utilizes the OSDK abstraction, a Frontend Engineer must possess a rigorous understanding of the underlying REST principles. These fundamentals are necessary for debugging network traces, integrating with legacy systems, or interacting with the raw Foundry APIs when the SDK coverage is incomplete.

### 2.1. HTTP Methods, Semantics, and Idempotency

In the context of the "Universal Tutor" application, the correct usage of HTTP methods ensures predictability and safety in data operations.

*   **GET (Retrieve):** Used for fetching resource representations. It is safe (no side effects) and idempotent (multiple calls produce the same result). In Foundry, GET requests retrieve dataset schemas, file listings, or object details via the legacy Phonograph API.
*   **POST (Create/Process):** Used to create resources or trigger processes. It is generally non-idempotent. This is the workhorse of the Foundry Action API. When a student submits a quiz, a POST request is sent. If the network fails and the client retries, there is a risk of double-submission unless specific safeguards are in place.
*   **PUT (Replace):** Replaces a resource entirely. It is idempotent. If a teacher updates a lesson plan, a PUT request ensures that the resource state matches the payload exactly, regardless of how many times the request is sent.
*   **PATCH (Modify):** Applies a partial update. This is crucial for bandwidth efficiency in large objects. Instead of sending a full 5MB Student Profile to update a phone number, a PATCH sends only the diff.
*   **DELETE (Remove):** Removes a resource. It is idempotent (deleting a deleted resource returns success or 404, but the end state is the same).

**Deep Dive: Idempotency Keys:**
In distributed systems like Foundry, network partitions are inevitable. A "Universal Tutor" application cannot afford to assign a grade twice because of a timeout. Advanced REST patterns involve the use of an `Idempotency-Key` header.
*   **Mechanism:** The client generates a unique UUID (e.g., `req_123abc`) for a critical POST request.
*   **Server Logic:** The server checks a distributed lock or cache. If `req_123abc` has already been processed, it returns the stored response (cached 200 OK) instead of executing the logic again.
*   **Frontend implementation:** This logic is often handled by the data fetching layer (e.g., passing a uuid to the mutation function in React Query) to ensure transactional integrity.

### 2.2. Authentication flows: OAuth 2.0 and PKCE

Security is paramount in Palantir's environments. The Foundry API relies exclusively on OAuth 2.0 for authentication, rejecting simple API keys in favor of short-lived access tokens. For a React application (a "Public Client" that cannot safely store secrets), the **Authorization Code Grant with PKCE (Proof Key for Code Exchange)** is the mandatory standard.

**The PKCE Flow Breakdown:**
1.  **Code Verifier Generation:** The React app generates a random string (the `code_verifier`) and hashes it to create a `code_challenge`.
2.  **Authorization Request:** The app redirects the user to the Foundry Multipass (Identity Provider) login page, including the `code_challenge` and `method=S256`.
3.  **User Consent:** The user logs in and approves the application's scopes (e.g., `api:ontology-read`, `api:datasets-write`).
4.  **Code Exchange:** Foundry redirects back to the React app with a temporary `authorization_code`.
5.  **Token Retrieval:** The React app sends a POST request to the token endpoint with the `authorization_code` AND the original `code_verifier`.
6.  **Validation:** Foundry verifies that the `code_verifier` matches the `code_challenge` from step 2. This prevents "authorization code interception attacks."
7.  **Access:** Foundry returns an `access_token` (JWT) and a `refresh_token`.

**Token Management in the Data Layer:**
The frontend must securely handle these tokens.
*   **Storage:** Tokens should ideally be stored in memory or secure cookies, not localStorage (vulnerable to XSS).
*   **Interceptors:** A networking library (like Axios or the internal OSDK client) must configure interceptors.
    *   **Request Interceptor:** Automatically attaches `Authorization: Bearer {token}` to every outgoing call.
    *   **Response Interceptor:** Listens for `401 Unauthorized`. If detected, it pauses the queue, uses the `refresh_token` to get a new access token, updates the header, and transparently retries the original failed request. This ensures the user is never abruptly logged out.

### 2.3. Advanced Error Handling Strategies

In enterprise environments, "it failed" is insufficient information. The Data Layer must implement sophisticated error handling strategies.

*   **Status Codes as Logic:**
    *   **409 Conflict:** The object was modified by another user since fetch. The frontend should trigger a re-fetch or offer a merge resolution UI.
    *   **412 Precondition Failed:** Critical for Optimistic Concurrency Control. Used when trying to update an object with an old version ID.
    *   **429 Too Many Requests:** The API rate limit has been hit. The client must respect the `Retry-After` header.
    *   **502/503/504:** Gateway or Service Unavailable. These define "transient" errors.

*   **Exponential Backoff with Jitter:**
    When a request fails transiently, retrying immediately can overload the struggling server (the "Thundering Herd" problem). The correct strategy is **Exponential Backoff**: waiting $2^n$ seconds (1s, 2s, 4s, 8s). Adding **Jitter** (randomness) ensures that 10,000 clients don't all retry at exactly the same millisecond. React Query implements this logic internally via its `retryDelay` configuration, defaulting to a linear backoff that can be customized to exponential.

## 3. GraphQL Architecture: The Semantic Graph

The Foundry Ontology is fundamentally a graph. GraphQL provides the syntax to query this graph efficiently. Understanding the architecture of GraphQL is essential for optimizing the performance of the "Universal Tutor" application.

### 3.1. The Schema Definition and Type System

GraphQL is strongly typed. The server exposes a Schema defined in SDL (Schema Definition Language). In Foundry, this schema is auto-generated from the user-defined Ontology.

**Core Components:**
*   **Object Types:** The nodes of the graph. A `Student` type might look like this:
    ```graphql
    type Student {
      id: ID!
      name: String!
      gpa: Float
      # A link to another Object Type
      quizzes(limit: Int, orderBy: String): [Quiz!]!
    }
    ```
*   **Scalars:** Primitive types (String, Int, Float, Boolean, ID). Foundry adds custom scalars like Date, Timestamp, and Attachment (for media files).
*   **Queries:** Entry points for fetching data. `getStudent(id: ID!)` or `searchStudents(filter: StudentFilter)`.
*   **Mutations:** Entry points for modifying data. In Foundry, these map to Actions.

**Introspection:**
One of GraphQL's greatest strengths is Introspection. The client can query `__schema` to discover the entire capabilities of the API at runtime. The Palantir OSDK uses this feature (or a pre-compiled equivalent) to generate TypeScript definitions, ensuring that the frontend code is always synchronized with the backend data model.

### 3.2. Solving the N+1 Problem with Data Loaders

A common interview topic for data-dense applications is the N+1 Problem.

*   **Scenario:** You want to load a list of 50 Students and, for each student, their latest Quiz score.
*   **Naive REST:** 1 request for the list of students + 50 requests for quiz scores = 51 requests. Latency is high; the browser connection limit is saturated.
*   **GraphQL Solution:** The client sends one query:
    ```graphql
    query {
      students {
        name
        quizzes(limit: 1) { score }
      }
    }
    ```
*   **Backend Execution:** The GraphQL server typically uses a Batching strategy (often via the **DataLoader** pattern). It collects all 50 student IDs and executes a single efficient query to the underlying database (e.g., `SELECT * FROM quizzes WHERE student_id IN (...)`). It then maps the results back to the respective students.
*   **Frontend Benefit:** The FDE works with a clean, logical data structure without managing the complexity of request orchestration or `Promise.all()` arrays. This drastically reduces network overhead and improves the "Time to Interactive" metric for the dashboard.

### 3.3. Palantir's Usage: The Ontology as a Graph

In Foundry, the "Backend" is not a monolith. It is a distributed system where Objects might live in different storage engines (Elasticsearch for search, Postgres for metadata, Spark for massive batch data). The GraphQL layer acts as a **Federated Gateway**.

When a developer queries for a Student and their Quizzes:
1.  The Gateway receives the GraphQL query.
2.  It resolves the `Student` fields from the Object Storage Service (Phonograph).
3.  It resolves the `quizzes` link by querying the Link Index Service.
4.  It stitches the responses together into a unified JSON.

This architectural abstraction is what allows Palantir frontends to scale. The FDE does not need to know where the data lives; they simply query the semantic model.

## 4. React Query (TanStack Query): The State Management Engine

While GraphQL provides the protocol for data, React Query provides the engine for managing that data within the application. It is the de-facto standard for "Server State" management in the modern React stack and a critical component of the candidate's Tier 2 technology list.

### 4.1. The QueryClient and Cache Architecture

At the heart of React Query is the `QueryClient`. This is a singleton that manages the `QueryCache`, a key-value store where:
*   **Keys:** Arrays that uniquely identify data, e.g., `['student', '123']`.
*   **Values:** The data payload, plus metadata (timestamp, loading state, error state).

**The "Stale-While-Revalidate" Lifecycle:**
React Query fundamentally changes how data freshness is perceived.
1.  **Fetch:** The first time a component mounts, it fetches data.
2.  **Cache:** The result is stored in the cache and marked as "fresh" for a duration (`staleTime`).
3.  **Stale:** After `staleTime` expires, the data is marked "stale" but remains in the cache.
4.  **Revalidate:** If a component requests "stale" data, React Query returns the cached data *immediately* (fast UI) and triggers a background refetch (network request).
5.  **Update:** When the background fetch completes, the cache is updated, and the component re-renders with the new data.

This pattern makes the "Universal Tutor" dashboard feel incredibly fast. Navigating between student profiles feels instant because cached data is shown while the latest stats update silently.

### 4.2. Core Hooks and Configuration Patterns

For an expert-level interview, understanding the configuration nuances is key.

**useQuery Configuration:**
```typescript
const { data, isLoading, error } = useQuery({
  queryKey: ["student", id],
  queryFn: () => client(Student).get(id),
  // Expert Configuration:
  staleTime: 5 * 60 * 1000, // Data stays fresh for 5 minutes. No network requests will occur in this window.
  gcTime: 24 * 60 * 60 * 1000, // Garbage Collection time. Unused data remains in memory for 24 hours.
  retry: 3, // Retry failed requests 3 times.
  refetchOnWindowFocus: false, // Prevent jarring updates when switching tabs.
  enabled: !!id, // Dependent query: only run if 'id' exists.
});
```

**useMutation and Optimistic Updates:**
Mutations modify server data. To ensure a responsive UI, we can update the UI *before* the server responds.
*   **onMutate:** Cancel outgoing refetches, snapshot the previous value, and optimistically update the cache.
*   **onError:** Rollback to the snapshot if the server fails.
*   **onSettled:** Invalidate the query to ensure the cache is eventually consistent with the server.

This "Optimistic UI" pattern is crucial for actions like "Mark Lesson Complete" in the tutor app, giving the user immediate feedback.

### 4.3. Advanced Patterns: Infinite Queries and Pagination

For data-dense applications handling thousands of records, simple queries suffice. React Query provides `useInfiniteQuery` for "Load More" interfaces.
*   **Mechanism:** It manages an array of pages. The `queryFn` receives a `pageParam` (cursor or offset).
*   **Integration:** The OSDK's `.fetchPage({ nextPageToken:... })` maps perfectly to this. The `getNextPageParam` callback extracts the token from the OSDK response, enabling seamless infinite scrolling.

## 5. The Palantir Ontology SDK (OSDK): Deep Dive & Implementation

The OSDK is the proprietary bridge between the Frontend and the Foundry backend. It wraps the raw GraphQL/REST complexity into a type-safe, fluent TypeScript API. This section is the most critical for the technical portion of the interview.

### 5.1. Generative SDKs: The End of "Any"

Generic API clients return `any` or loose interfaces. The OSDK is generated from the specific Ontology of the "Universal Tutor" project.
*   **Build Process:** When the Ontology schema changes (e.g., adding `difficultyLevel` to `Quiz`), a CI/CD pipeline regenerates the SDK package (`@universal-tutor/sdk`).
*   **Result:** The frontend codebase immediately fails compilation if it tries to access a deleted property. This "Schema-First" development prevents runtime errors and enables aggressive refactoring.

### 5.2. Fluent Query API and Link Traversal

The OSDK allows developers to construct complex graph queries using a method chaining syntax that resembles SQL or LINQ.

**Example: Chained Traversal**
```typescript
import { Student } from "@universal-tutor/sdk";

// "Find the emails of all students who failed the latest Math quiz"
const emails = await client(Student)
 .where({ gradeLevel: 10 })
 .pivotTo("quizzes") // Traverse link to Quizzes
 .where({ subject: "Math", score: { $lt: 60 } }) // Filter linked objects
 .pivotTo("student") // Traverse back to Student (if model requires)
 .select(["email"]) // Fetch only specific fields
 .fetchPage();
```
**Architectural Insight:** This is not executing in the browser. The OSDK compiles this chain into a definition (likely a JSON-based AST) and sends it to the Foundry Object Set Service. The backend performs the join and filtering, returning only the final result set. This minimizes data transfer (Network I/O) and client-side processing (CPU).

### 5.3. Server-Side Aggregations

For dashboards, raw data is often unnecessary. We need metrics. Fetching 10,000 objects to calculate an average is an anti-pattern. The OSDK exposes an Aggregation API.

**Code Example:**
```typescript
const stats = await client(QuizResult)
 .groupBy(q => q.difficulty.exact())
 .aggregate(q => ({
    avgScore: q.score.avg(),
    maxScore: q.score.max(),
    total: q.score.count()
  }));
```
**Impact:** The response payload is negligible (bytes), while the compute happens on Palantir's distributed compute cluster (Spark/Flink). This is how Foundry frontends remain performant even when analyzing terabytes of data.

## 6. Performance Engineering for Data-Dense Visualization

A "Universal Tutor" system implies complex dashboards: gradebooks, learning path graphs, and activity heatmaps. Rendering this data is a primary bottleneck.

### 6.1. The DOM Bottleneck and Virtualization

The browser's DOM is slow. Rendering a table with 1,000 rows x 20 columns creates 20,000 DOM nodes. This causes high memory usage, slow style calculations, and "janky" scrolling (low FPS).

**Solution: Virtualization (Windowing)**
Virtualization renders only the items currently visible in the viewport, plus a small buffer.
*   **Mechanism:** A container div is given a massive height (e.g., 50,000px) to simulate the scrollbar. Inside, absolute positioning is used to place only the ~20 rows that correspond to the current scroll offset.
*   **Library Choice:**
    *   `react-window` / `tanstack-virtual`: Lightweight, headless solutions. Ideal for custom lists or grids where you need full control over the markup.
    *   **Ag-Grid:** The industry heavyweight. It includes virtualization out-of-the-box, along with column pinning, multi-sort, and pivoting. For "Excel-like" gradebooks in Foundry, Ag-Grid is the standard recommendation due to its feature richness and performance with 100k+ rows.

### 6.2. Canvas and WebGL for Extreme Density

If the dashboard requires visualizing a "Knowledge Graph" of 10,000 concepts and their connections (a node-link diagram), SVG and HTML are insufficient.
*   **D3.js (Data-Driven Documents):** Standard for SVG. Great for < 1,000 nodes.
*   **Canvas/WebGL:** For > 1,000 nodes, we must drop to the Canvas API or use libraries like **Cosmos** or **Deck.gl**. These render directly to the GPU context, bypassing the DOM entirely.
*   **Hybrid Approach:** Use D3 for the math (calculating forces, scales, axes) and React/Canvas for the rendering. This leverages D3's statistical power without its DOM overhead.

### 6.3. Off-Main-Thread Architecture: Web Workers

JavaScript is single-threaded. Parsing a 10MB JSON response or calculating a graph layout will freeze the UI.
*   **Pattern:** Move heavy computation to a Web Worker.
1.  **Data Fetch:** Fetch the large dataset.
2.  **Transfer:** Pass the data to the Worker (using Transferable objects like ArrayBuffer for zero-copy overhead).
3.  **Compute:** The Worker parses, filters, and calculates the layout coordinates.
4.  **Return:** The Worker sends the "render-ready" data back to the main thread.
5.  **Render:** React simply paints the pre-calculated coordinates.

## 7. Real-Time Data Architectures

Static dashboards are obsolete. If a student completes a module, the teacher's dashboard must reflect this instantly.

### 7.1. Short Polling vs. Long Polling
*   **Short Polling:** `setInterval` triggers a fetch every 10 seconds. Simple, robust, but high latency and resource wasteful.
*   **Long Polling:** The client opens a request, and the server holds it open until data is available. Better latency, but connection-heavy.

### 7.2. WebSockets and OSDK Subscriptions

Foundry supports true WebSockets for real-time event streaming.
**OSDK Subscriptions:** The OSDK provides a high-level API to subscribe to object changes.

```typescript
client(Student).subscribe({
  onObjectAdded: (obj) => queryClient.setQueryData(...),
  onObjectModified: (obj) => updateLocalCache(obj),
  onError: (err) => handleDisconnect(err)
});
```
**Architecture:**
*   **Subscription Definition:** The client sends a specific query definition to the backend (e.g., "Watch Student where classId = 'math-101'").
*   **Event Stream:** The backend (powered by a stream processor like Kafka/Flink) pushes discrete events (ADDED, UPDATED, REMOVED) to the client.

### 7.3. The "Invalidation" Pattern

Sending full object payloads over WebSockets can be bandwidth-intensive. A common enterprise pattern is **Event-Driven Invalidation**.
1.  **Event:** Server sends a lightweight message: `{"event": "UPDATE", "objectId": "123"}`.
2.  **Reaction:** The client receives this and calls `queryClient.invalidateQueries(["student", "123"])`.
3.  **Fetch:** React Query triggers a standard HTTP/OSDK fetch to get the latest data.
This ensures consistency (the HTTP fetch respects standard serialization/ACID properties) while maintaining near real-time freshness.

## 8. Resilience, Reliability, and Offline Support

In an enterprise setting, network stability cannot be assumed.

### 8.1. Offline Capabilities with Service Workers
For a "Universal Tutor" app used in schools with poor connectivity, Service Workers are vital.
*   **Caching Assets:** Workbox can cache the JS/CSS bundles.
*   **Caching Data:** React Query can persist its cache to `localStorage` or `IndexedDB`. When the app loads offline, it rehydrates the persisted state, allowing the teacher to view the last known grades.
*   **Queueing Mutations:** If a user submits a grade while offline, the app stores the mutation in a persistent queue (e.g., `redux-offline` or `tanstack-query` persistence plugins) and replays it when connectivity is restored.

### 8.2. Circuit Breakers and Fallbacks
If the "Grading Service" goes down, the entire dashboard shouldn't crash.
*   **Error Boundaries:** Wrap React components in `<ErrorBoundary>`. If the "Grades" widget crashes, catch the error and display a "Service Temporarily Unavailable" placeholder, allowing the rest of the dashboard (e.g., "Attendance") to function.
*   **Circuit Breaker:** If 5 consecutive requests to an API fail, stop sending requests for 1 minute to allow the system to recover.

## 9. Comparison Matrices

To succinctly summarize the architectural choices for the interview:

### 9.1. Data Fetching Protocols

| Feature | REST (Foundry API) | GraphQL (OSDK Underlying) |
| :--- | :--- | :--- |
| **Philosophy** | Resource-based (Nouns). | Query-based (Graph). |
| **Over-fetching** | High (Fixed payloads). | Low (Client-defined). |
| **Caching** | Excellent (HTTP standard). | Complex (Requires normalization). |
| **Versioning** | V1, V2 endpoints. | Evolution via deprecation. |
| **Palantir Use** | Pipelines, Config, Legacy. | Primary for Frontend Apps. |

### 9.2. State Management

| Feature | Redux (Client State) | React Query (Server State) |
| :--- | :--- | :--- |
| **Source of Truth** | Client / Browser. | Server / Database. |
| **Boilerplate** | High (Actions, Reducers). | Low (Hooks). |
| **Caching Logic** | Manual implementation. | Automatic (SWR). |
| **Best For** | UI State, Forms, Themes. | API Data, Lists, Search. |

## 10. Interview Preparation Module

This section maps the technical knowledge to specific interview questions likely to be asked by Palantir engineers.

### 10.1. Behavioral & Architectural Questions

**Q1: "We have a dataset of 1 million rows. How do you build a dashboard that allows filtering and sorting this data in the browser?"**
**Answer Strategy:** Reject the premise of doing it "in the browser".
*   "Loading 1 million rows client-side is an anti-pattern. I would implement **Server-Side Pagination and Filtering**. The frontend would send the filter criteria (e.g., `gpa > 3.0`) via the OSDK. The backend returns a page of results."
*   "If visualization of the entire distribution is needed, I'd use **Server-Side Aggregation** to fetch buckets (histograms) rather than raw rows."
*   "If the user must scroll the list, I'd use **Virtualization** (Ag-Grid) to render only the visible rows, coupled with an **Infinite Scroll** query pattern."

**Q2: "How would you handle real-time collaboration where two teachers grade a student simultaneously?"**
**Answer Strategy:** Focus on Concurrency Control and Optimistic UI.
*   "I would use **OSDK Subscriptions** to listen for changes. If Teacher A updates a grade, Teacher B's UI updates automatically."
*   "To prevent overwrites, I'd rely on **Optimistic Concurrency Control (OCC)**. The OSDK likely checks version numbers. If Teacher B tries to write to an old version, the server throws `412 Precondition Failed`. I would handle this error by notifying the user and refreshing the data."

**Q3: "Design the data layer for the 'Universal Tutor' Knowledge Graph."**
**Answer Strategy:** Combine GraphQL for fetching with D3/Canvas for rendering.
*   "I'd model Concepts as Object Types and Prerequisites as Links. I'd write a recursive OSDK query (or specialized backend function) to fetch the graph traversal."
*   "I'd use React Query to cache this heavy structure."
*   "For rendering, I'd use a Force-Directed Graph in D3 or Cosmos (WebGL) if the node count is high, running the simulation in a Web Worker to keep the UI thread responsive."

### 10.2. Technical Deep Dive Questions

**Q4: "Explain how you would debug a GraphQL query that is performing slowly in the dashboard."**
**Answer Strategy:**
*   "First, I'd check the Network Tab to see if it's TTFB (Time to First Byte) or Download time. High TTFB implies backend slowness."
*   "I'd analyze the query complexity. Are we nesting too deep? Are we hitting the N+1 problem on a field that lacks a DataLoader?"
*   "I'd use the React Query DevTools to ensure we aren't accidentally refetching too often (e.g., on window focus)."
*   "If the backend is slow, I'd propose adding an index to the underlying dataset properties in Foundry or moving to a pre-computed aggregation (Materialized View)."

**Q5: "Why not just use Redux for everything? It gives you full control."**
**Answer Strategy:**
*   "Redux is powerful but imperative. For server state, it forces us to reinvent the wheel: caching policies, deduping requests, garbage collection, and loading states. This creates a massive maintenance burden and surface area for bugs."
*   "React Query is declarative. We state what data we need and how fresh it should be. It handles the 'hard parts' of async state management, allowing Redux to focus on what it does best: complex, synchronous client-side state interactions."

## Conclusion

Success in the Palantir Frontend Engineering interview requires demonstrating a synthesis of theoretical computer science foundations and pragmatic enterprise engineering. By mastering the OSDK as the bridge between the semantic Ontology and the responsive React Query cache, and by deploying advanced techniques like Virtualization, Web Workers, and Optimistic Updates, the candidate proves their ability to build the "operating systems for the modern enterprise." The convergence of graph data modeling with robust, type-safe frontend tooling represents the cutting edge of this domain, and the "Universal Tutor" project serves as the ideal narrative vessel to showcase this expertise.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/05_testing_pyramid.md
# ========================================================
# Comprehensive Frontend Testing Strategies for Enterprise-Grade Data Visualization Platforms

## 1. Executive Summary

In the contemporary landscape of high-stakes software engineering, particularly within organizations such as Palantir Technologies that architect critical operating systems for global institutions, the role of frontend testing has transcended mere functional verification. It has evolved into a sophisticated discipline of risk mitigation, system reliability engineering, and operational continuity. For the aspiring Palantir Frontend Engineer, specifically one tasked with developing complex, data-dense applications like the "Universal Tutor," a mastery of the testing ecosystem is not optional—it is fundamental. The ability to architect a testing strategy that spans atomic unit logic, component integration, and end-to-end user journeys is as significant as the implementation of the features themselves.

This report provides an exhaustive analysis of the modern frontend testing landscape, tailored specifically to the technological stack of React, TypeScript, and Blueprint UI. It dissects the "Testing Pyramid" paradigm, adapting it for 2025 enterprise architectures where the boundaries between unit, integration, and end-to-end (E2E) testing are increasingly nuanced. We explore the deep technical architecture of Jest for logic verification, React Testing Library (RTL) for user-centric component interaction, and Playwright for high-fidelity browser automation.

Furthermore, this document serves as a strategic guide for the Palantir "Re-engineering" and "Decomposition" interviews. These unique assessment formats require candidates to demonstrate not just coding proficiency, but the ability to systematically debug, refactor, and stabilize legacy or buggy codebases using rigorous testing methodologies. By synthesizing theoretical frameworks with practical, code-level execution strategies, this report aims to equip the candidate with the depth of knowledge required to operate at a Senior or Principal engineering level.

## 2. The Theoretical Framework: The Testing Pyramid in 2025

The traditional Testing Pyramid, conceptualized by Mike Cohn, posits a broad base of unit tests, a middle layer of service/integration tests, and a narrow apex of UI tests. While the core principle—pushing verification to the lowest, fastest, and cheapest layer possible—remains valid, the implementation details in a modern React/TypeScript ecosystem have shifted significantly.

### 2.1 The Evolution of the Pyramid

In the context of the "Universal Tutor" application, which integrates complex AI/ML systems (LLMs, GraphRAG, Neo4j), the classic pyramid requires adaptation.

*   **Unit Tests (The Foundation - 60%):** In 2025, pure unit tests are reserved for algorithmic logic, utility functions, and complex data transformations. For a visualization app, this means testing the mathematical functions that calculate graph node positions or the reducers managing Redux state.
*   **Integration Tests (The Bulk - 30%):** With the rise of React Testing Library, "Integration" has redefined itself to mean "Component Integration." We test how a component interacts with its children and hooks, mocking only the external network layer. This provides a higher return on investment (ROI) than shallow unit tests of UI components.
*   **End-to-End Tests (The Safety Net - 10%):** Tools like Playwright have made E2E testing faster and more reliable, allowing for broader coverage than the "narrow apex" of the past. However, due to the high cost of maintenance and execution time, these are strategically deployed to cover critical user journeys (e.g., "A student submits a query, receives an LLM response, and interacts with the generated graph").

### 2.2 The Palantir "Quality Culture"

Palantir's engineering culture emphasizes "Product Reliability" and "Ownership." In an interview context, this translates to a candidate's ability to discuss trade-offs. A senior engineer knows that 100% code coverage is a vanity metric that often leads to brittle tests. Instead, the focus is on **Use Case Coverage** and **Branch Coverage** of critical paths. The expectation is that tests serve as live documentation of the system's intended behavior, enabling safe refactoring—a crucial skill for the "Re-engineering" interview.

## 3. Tier 1: Unit Testing with Jest - The Foundation

Jest remains the ubiquitous test runner for React ecosystems, but its utility in enterprise environments depends heavily on advanced configuration, particularly regarding TypeScript integration and the mocking of complex dependencies.

### 3.1 Advanced Jest Architecture and Configuration

In large-scale monorepos, the default Jest configuration often proves insufficient due to performance bottlenecks and transpilation overhead. The integration of `ts-jest` provides a robust mechanism for handling TypeScript natively, ensuring that type-checking occurs during the test phase.

#### 3.1.1 TypeScript Integration: ts-jest vs. Babel

A common architectural decision is choosing between `ts-jest` (which uses the TypeScript compiler) and `@babel/preset-typescript` (which strips types).

**Table 1: Jest TypeScript Configuration Strategies**

| Feature | ts-jest | Babel (@babel/preset-typescript) | Enterprise Implication |
| :--- | :--- | :--- | :--- |
| **Type Checking** | Runtime checking during tests. | None (transpilation only). | `ts-jest` prevents "false positives" where invalid TS code passes tests. |
| **Performance** | Slower (requires compilation). | Fast (strips types). | Babel is preferred for dev speed; `ts-jest` for CI pipelines. |
| **Features** | Supports `const enum`, namespaces. | Limited support for some TS features. | `ts-jest` allows stricter adherence to TS features used in complex domains. |
| **Debugging** | Full source map support. | Can be tricky with source maps. | `ts-jest` offers a superior debugging experience for complex algorithms. |

For the "Universal Tutor," a hybrid approach is recommended: running Babel locally for speed and `ts-jest` (or a separate `tsc` check) in CI to ensure type safety.

#### 3.1.2 Handling ESM and D3.js

The "Universal Tutor" utilizes D3.js for visualization. D3.js (version 7+) is published as pure ES Modules (ESM). Jest, running in Node.js, historically struggled with ESM.

**The Problem:** Importing D3 in a Jest test often results in `SyntaxError: Unexpected token 'export'`.

**The Solution:**
*   **Configuration:** Update `jest.config.js` to process `d3` using `transformIgnorePatterns`.
    ```javascript
    // jest.config.js
    module.exports = {
      transformIgnorePatterns: [
        "node_modules/(?!d3|d3-array|internmap|delaunator|robust-predicates)"
      ],
    };
    ```
*   **Mocking:** Alternatively, mock D3 entirely if the test is not specifically verifying the visualization rendering logic (see Section 3.2).

### 3.2 Advanced Mocking Strategies

In Palantir's "Re-engineering" interview, candidates effectively use mocking to isolate variables in buggy code.

#### 3.2.1 The Hierarchy of Mocks
*   `jest.mock()`: Hoisted to the top of the file. Used for mocking entire modules (e.g., `axios`, `react-router-dom`).
*   `jest.spyOn()`: Used to spy on object methods. Essential for window methods or prototyping `Date` or `Math.random` to ensure deterministic tests.
*   `jest.mocked()`: A TypeScript helper to enforce type safety on mocks.

**Example: Type-Safe Mocking of a Graph Service**
```typescript
import { GraphService } from './services/GraphService';
import { renderHook } from '@testing-library/react-hooks';

// 1. Mock the module
jest.mock('./services/GraphService');

// 2. Create a type-safe reference
const MockedGraphService = jest.mocked(GraphService);

test('fetches graph nodes correctly', async () => {
  // 3. Define implementation with strict typing
  MockedGraphService.getNodes.mockResolvedValue();

  //... test execution
});
```

#### 3.2.2 Timer Mocks for Real-Time Data

Real-time applications often use debouncing (e.g., search inputs) or throttling (e.g., WebSocket updates). Testing these behaviors requires precise control over the JavaScript event loop using `jest.useFakeTimers()`.

*   **Scenario:** The "Universal Tutor" shows a "Thinking..." indicator that must persist for at least 500ms to prevent UI flicker, even if the API responds instantly.
*   **Test Strategy:**
    1.  Enable fake timers.
    2.  Trigger the action.
    3.  Assert "Thinking..." is visible.
    4.  `jest.advanceTimersByTime(500)`.
    5.  Assert "Thinking..." is gone and data is visible.

### 3.3 Snapshot Testing: Usage and Abusage

Snapshot tests serialize the rendered output of a component and compare it to a stored file.

*   **The Pitfall:** Over-reliance on snapshots leads to "snapshot fatigue," where developers blindly update snapshots without reviewing changes.
*   **The Strategy:** Use snapshots for **configuration objects or graph data structures**, not for entire DOM trees.
    *   *Good:* Snapshotting the calculated layout coordinates of a D3 graph.
    *   *Bad:* Snapshotting the entire `<GraphContainer />` HTML, which breaks whenever a CSS class changes.
*   **Custom Serializers:** For data-dense apps, standard snapshots are unreadable. Configuring a custom serializer (e.g., `jest-serializer-html` or a custom JSON serializer for graph nodes) ensures that snapshots remain human-readable diffs during code review.

## 4. Tier 2: Integration Testing with React Testing Library (RTL)

RTL represents a paradigm shift from testing implementation details (like component state) to testing user-observable behavior. This aligns perfectly with the goal of building resilient enterprise applications.

### 4.1 The User-Centric Philosophy

The core tenet of RTL is: *"The more your tests resemble the way your software is used, the more confidence they can give you."*

For a Palantir Frontend Engineer, this means querying the DOM by **Roles** (button, grid, heading) and **Labels** rather than fragile CSS selectors or test-ids.

**Priority of Queries:**
1.  `getByRole`: Best for accessibility. (`screen.getByRole('button', { name: /submit/i })`)
2.  `getByLabelText`: Critical for forms.
3.  `getByPlaceholderText`: Fallback for inputs.
4.  `getByText`: Good for divs/spans.
5.  `getByTestId`: **Last Resort.** Use only for elements like overlay containers or canvas elements where semantic queries are impossible.

### 4.2 Testing Blueprint UI Components

Palantir's Blueprint UI is optimized for complex desktop interfaces. Testing it requires handling specific architectural patterns like Portals and Virtualization.

#### 4.2.1 Testing Portals (Popovers, Dialogs, Tooltips)

Blueprint renders overlays in a React Portal, appending them to `document.body` rather than the component's local DOM tree.
*   **The Challenge:** `container.querySelector` will fail to find the popover content.
*   **The Solution:** Use `screen` queries. The `screen` object binds to `document.body`, making it portal-agnostic.

**Case Study: Testing a Blueprint Popover Menu**
```typescript
test('opens context menu and selects option', async () => {
  const user = userEvent.setup();
  render(<GraphNode id="1" />);

  // 1. Right-click (contextmenu) on the node
  const node = screen.getByRole('button', { name: /Node 1/i });
  await user.pointer({ keys: '', target: node });

  // 2. Assert Portal content is present
  // Note: Blueprint Popovers have a transition delay.
  await waitFor(() => {
    expect(screen.getByRole('menu')).toBeInTheDocument();
  });

  // 3. Select option
  await user.click(screen.getByRole('menuitem', { name: /Expand Neighbors/i }));

  // 4. Assert action
  expect(mockExpandHandler).toHaveBeenCalledWith('1');
});
```

#### 4.2.2 Testing Virtualized Lists (React-Window)

Blueprint's `Table` and `react-window` render only the rows currently in the viewport.
*   **The Challenge:** Testing that "Row 1000" exists fails because it is not in the DOM.
*   **The Strategy:**
    1.  **Integration Tests:** Verify that the container renders and receives the correct data props. Do not test scrolling mechanics here.
    2.  **Mocking Geometry:** JSDOM has no layout engine (height/width are always 0). You must mock `HTMLElement.prototype.offsetHeight` and `offsetWidth` in `jest.setup.js` or per test to "trick" the virtualization library into rendering items.
    3.  **E2E for Scroll:** Delegate the actual scrolling and rendering verification to Playwright (Tier 3), which uses a real browser engine.

### 4.3 Advanced Interaction Testing: `user-event`

The `user-event` library (v14+) simulates full user interactions (hover, focus, click sequences) rather than simple DOM events.
*   **Setup:** Use `const user = userEvent.setup()` at the start of the test.
*   **Complex Interactions:**
    *   **Keyboard:** `await user.keyboard('{Shift>}a{/Shift}')` simulates typing a capital 'A'.
    *   **Upload:** `await user.upload(input, file)` simulates file selection for data import features.
    *   **Clipboard:** `await user.paste('text')` tests paste handling in code editors or inputs.

## 5. Tier 3: End-to-End Testing with Playwright

At the apex of the pyramid, Playwright has largely supplanted Cypress for enterprise-scale applications due to its architecture, speed, and reliability.

### 5.1 Playwright vs. Cypress: An Enterprise Analysis

**Table 2: Comparative Analysis for Enterprise Architectures**

| Feature | Cypress | Playwright | Verdict for Palantir Context |
| :--- | :--- | :--- | :--- |
| **Architecture** | Runs *inside* the browser (injects scripts). | Uses WebSocket/CDP (Chrome DevTools Protocol) to control browser from *outside*. | **Playwright:** Out-of-process control allows for better stability, multi-tab support, and trusted events. |
| **Language Support** | JavaScript/TypeScript only. | TS, JS, Python, Java,.NET. | **Playwright:** Python support aligns with Palantir's backend/data engineering stack. |
| **Parallelization** | Paid feature (Cypress Cloud) or complex workarounds. | Native, free sharding via CLI. | **Playwright:** Essential for keeping CI times low in massive monorepos. |
| **Browser Engines** | Chrome, Firefox, Electron. | Chromium, WebKit (Safari), Firefox. | **Playwright:** True WebKit support is critical for verifying macOS/iOS user experiences. |
| **Network Mocking** | Good intercept capabilities. | Full network interception and modification. | **Playwright:** Superior handling of advanced scenarios like aborting requests or mocking WebSocket frames. |

### 5.2 Visual Regression Testing (VRT)

For a "Data-Dense Visualization Application," functionality is insufficient; the visual representation must be accurate. Charts, heatmaps, and graph layouts are prone to regression (e.g., a CSS change breaking a D3 axis alignment).

*   **Implementation Strategy:**
    *   **Snapshot Generation:** Playwright's `expect(page).toHaveScreenshot()` captures a pixel-perfect image.
    *   **Environment Consistency:** Rendering fonts and anti-aliasing differs between macOS (dev) and Linux (CI).
        *   **Solution:** Run VRT exclusively inside Docker Containers. This ensures that the OS-level graphics libraries are identical across all environments.
    *   **Flakiness Mitigation:**
        *   **Thresholds:** Set `maxDiffPixelRatio: 0.01` to ignore microscopic rendering noise.
        *   **Masking:** Use the `mask` option to overlay black boxes on dynamic elements (timestamps, random IDs) before taking the screenshot.

### 5.3 Testing Real-Time WebSockets

The "Universal Tutor" implies real-time feedback. Playwright offers robust WebSocket interception.

**Pattern: Mocking the Tutor's Stream**
```typescript
// Playwright Test
test('displays streaming tokens from LLM', async ({ page }) => {
  // Intercept WebSocket connection
  await page.routeWebSocket('wss://api.tutor.com/stream', ws => {
    ws.onMessage(message => {
      if (message === 'INIT_SESSION') {
        // Mock the stream of tokens
        ws.send(JSON.stringify({ type: 'TOKEN', payload: 'Hello' }));
        ws.send(JSON.stringify({ type: 'TOKEN', payload: ' ' }));
        ws.send(JSON.stringify({ type: 'TOKEN', payload: 'World' }));
      }
    });
  });

  await page.goto('/tutor');
  await expect(page.locator('.tutor-response')).toHaveText('Hello World');
});
```

## 6. Specialized Testing: Data-Dense & Real-Time Applications

Testing data visualization applications introduces specific challenges that standard CRUD testing patterns do not address.

### 6.1 Testing D3.js and Canvas Visualizations

React components that wrap D3.js often render to `<svg>` or `<canvas>`.

*   **SVG Testing (RTL):** Since SVGs are DOM elements, they can be queried.
    *   **Query:** `container.querySelectorAll('circle')` to count nodes.
    *   **Attribute Assertion:** Check `cx`, `cy`, and `fill` attributes to verify data mapping to geometry.
*   **Canvas Testing (Playwright):** `<canvas>` is a black box to the DOM.
    *   **Strategy:** Visual Regression Testing is the primary tool here. Compare the rendered canvas pixels against a baseline.
    *   **Alternative:** Expose an internal data structure (e.g., `window.__GRAPH_DATA__`) in the test environment to verify the state of the canvas renderer without reading pixels.

### 6.2 Performance Testing in CI

Palantir's platforms process massive datasets. A functional pass is a failure if it introduces a 500ms render delay.

*   **Jest Profiler:** Use `jest-react-profiler` to assert on commit counts.
    ```typescript
    it('does not re-render the graph when selecting a unrelated menu', () => {
      const { rerender } = render(<Profiler id="graph" onRender={onRender}><Graph /></Profiler>);
      // Trigger unrelated state change
      rerender(<Profiler id="graph" onRender={onRender}><Graph unrelatedProp={true} /></Profiler>);
      expect(onRender).toHaveBeenCalledTimes(1); // Should remain 1 (initial render)
    });
    ```
*   **Lighthouse CI:** Integrate Lighthouse into the PR pipeline to enforce budgets on "Largest Contentful Paint" (LCP) and "Total Blocking Time" (TBT).

### 6.3 Accessibility (A11y) Testing

Government and enterprise clients often mandate strict WCAG 2.1 compliance.

*   **Unit (jest-axe):** Automate a11y checks in RTL tests.
    ```typescript
    import { axe } from 'jest-axe';
    test('login form is accessible', async () => {
      const { container } = render(<LoginForm />);
      const results = await axe(container);
      expect(results).toHaveNoViolations();
    });
    ```
*   **E2E (axe-playwright):** Scan entire pages during E2E runs to catch contrast issues and missing ARIA labels dynamically.

## 7. The Palantir Interview Context: Deconstruct & Re-engineer

Palantir's interview process is unique. It moves beyond "LeetCode" into practical engineering simulation.

### 7.1 The "Re-engineering" (Debugging) Interview

In this round, you are given a functioning but buggy codebase (often a React app) and asked to fix it.

*   **The Trap:** Jumping straight into the code to "fix" what looks wrong.
*   **The Winning Strategy:**
    1.  **Reproduce with Tests:** **Before** changing a single line of application code, write a failing test case that reproduces the reported bug. This demonstrates a rigorous, scientific mindset.
    2.  **Isolate:** Use the test to isolate the issue. Is it a logic error? A race condition? A state mutation?
    3.  **Refactor:** Fix the code.
    4.  **Verify:** The test should now pass.
    5.  **Defend:** Explain why the bug occurred and how the test prevents regression.

**Common Bug Archetypes in Interviews:**
*   **Stale Closures:** A `useEffect` or `useCallback` missing a dependency, causing it to see old state. Fix: Correct the dependency array or use `useRef` to hold mutable values.
*   **Race Conditions:** Two async requests (e.g., search queries) returning out of order. Fix: Use an `AbortController` to cancel stale requests in `useEffect`.
*   **Improper Memoization:** Objects recreated on every render causing `React.memo` components to re-render unnecessarily. Fix: `useMemo` or stable object references.

### 7.2 The "Decomposition" Interview

This is a system design interview focused on breaking down a vague problem (e.g., "Build the Universal Tutor frontend").

*   **Testing as a Design Principle:** When designing the architecture, explicitly mention **how** you would test it.
*   **Candidate:** "I would separate the Graph Rendering Engine from the React Component layer. This allows us to unit test the graph layout algorithms in pure TypeScript (Jest) without the overhead of the DOM, while using Storybook and Playwright to test the visual component."
*   **Impact:** This shows you design for maintainability, a key Palantir value.

## 8. Enterprise Quality Patterns

### 8.1 Test Data Management: Factories vs. Fixtures

Hard-coding data in tests leads to brittleness.
*   **Fixtures:** Static JSON files. Good for network mocks but can become stale.
*   **Factories (e.g., `fishery` or `rosie`):** Dynamic functions that generate data. Preferred for enterprise.

```typescript
// UserFactory.ts
export const UserFactory = Factory.define<User>(({ sequence }) => ({
  id: `user-${sequence}`,
  name: 'John Doe',
  permissions: ['read'],
}));

// In Test
const admin = UserFactory.build({ permissions: ['admin'] });
```

### 8.2 Flakiness Prevention

Flaky tests are the enemy of CI/CD.
*   **Deterministic Selectors:** Never use `setTimeout`. Use `findBy` (which waits) or `await waitFor(() => expect(...))`.
*   **Isolation:** Ensure every test cleans up its state. `react-testing-library` does this automatically for the DOM, but you must manually reset mocks (`jest.resetAllMocks()`) and local storage.
*   **Network Stability:** In E2E tests, never hit real 3rd party APIs. Mock everything using `page.route` in Playwright to ensure 100% deterministic network behavior.

## 9. Comprehensive Interview Q&A Repository

**Q1: "How would you test a Blueprint Table with 10,000 rows?"**
**A:** "I would tier the testing. **Unit/Integration (Jest/RTL):** I'd test the `CellRenderer` logic in isolation to ensure data is formatted correctly. I'd mock the virtualization provider (like `react-window`) to verify the table receives the correct data array, without trying to render 10k DOM nodes in JSDOM. **E2E (Playwright):** I'd use visual regression to check the initial render of the first 20 rows. I would then script a scroll action and verify that new rows appear in the DOM and that the memory footprint doesn't spike, ensuring no memory leaks in the virtualization logic."

**Q2: "You have a flaky test that fails 1 in 10 times. How do you debug it?"**
**A:** "I'd start by inspecting the failure logs for patterns—is it time-dependent? I'd look for implicit waits or fixed `setTimeout` calls and replace them with event-driven `waitFor` assertions. I'd check for test pollution—is a previous test modifying a global singleton or local storage that isn't being reset? Finally, I'd use Playwright's 'Trace Viewer' to step through the failed run execution to see if a network request is resolving later than expected, causing a race condition."

**Q3: "How do you test a component that uses a WebSocket connection?"**
**A:** "For unit tests, I would mock the WebSocket client class (or hook) to return a subject/observable. I can then push messages into that subject and assert the component updates. For E2E tests in Playwright, I would use `page.routeWebSocket` to intercept the connection and simulate the server sending messages, including edge cases like connection drops or malformed JSON, to verify error handling UI."

**Q4: "What is the difference between `fireEvent` and `userEvent` in RTL?"**
**A:** "`fireEvent` dispatches a synthetic DOM event directly to the element. It's fast but unrealistic. `userEvent` simulates the full browser interaction lifecycle. For example, `userEvent.click` triggers hover, mousedown, focus, mouseup, and click. I always prefer `userEvent` because it catches bugs that `fireEvent` misses, such as clicking on a button that is disabled or covered by a transparent overlay."

**Q5: "How would you ensure your testing strategy scales with a monorepo?"**
**A:** "I would implement **Test Sharding** in CI to run tests in parallel across multiple machines. I would use **Affected Test Execution** (via tools like Nx or Turborepo) to only run tests for projects that have changed in the current PR. I would also strictly enforce the Testing Pyramid, ensuring the majority of tests are fast unit tests, keeping the slow E2E suite focused on critical paths to prevent the CI pipeline from becoming a bottleneck."

**Q6: "How do you test for Accessibility?"**
**A:** "I integrate `jest-axe` into the unit test suite to catch low-hanging fruit like missing labels or contrast issues at the component level. In the E2E suite, I inject `axe-core` to scan full pages in their rendered state. I also advocate for manual testing using screen readers (NVDA/VoiceOver) for complex interactive flows, as automated tools only catch about 30-40% of a11y issues."

**Q7: "Should we test implementation details?"**
**A:** "No. Testing implementation details (like checking the internal state of a component or the name of a private method) creates brittle tests that break every time we refactor code, even if the feature still works. We should test public interfaces and observable behavior—what the user sees and interacts with. This is the core philosophy of React Testing Library."

**Q8: "How do you mock a ResizeObserver in Jest?"**
**A:** "JSDOM doesn't support `ResizeObserver`. I would create a mock implementation in `setupTests.ts` that implements `observe`, `unobserve`, and `disconnect`. To test the responsive behavior, I would expose a callback from the mock that allows my test to manually trigger a 'resize' event with specific dimensions, verifying that the component responds correctly."

**Q9: "When would you use Snapshot testing?"**
**A:** "Sparingly. I use them for configuration objects, complex static data structures, or verifying that a graph visualization library outputs the correct SVG path data. I avoid using them for full React component trees, as they become 'noise' during code reviews and developers tend to update them without reading the diffs."

**Q10: "How do you test a canvas-based graph visualization?"**
**A:** "Since canvas is just a bitmap to the DOM, I can't query nodes. I would use Visual Regression Testing with Playwright to compare screenshots against a baseline. For interaction testing (e.g., clicking a node), I would rely on the component exposing a coordinate map or a hidden accessibility layer (HTML overlay) that mirrors the graph structure, allowing me to click specific coordinates."

**Q11: "Explain TDD and how you apply it."**
**A:** "Test-Driven Development involves writing the test before the code: Red (fail), Green (pass), Refactor. I apply it strictly for complex algorithmic logic (e.g., data transformation for a chart) because it forces me to clarify the API and edge cases upfront. For UI components, I'm more pragmatic; I often sketch the component first to stabilize the DOM structure, then write RTL tests to verify interactions."

**Q12: "How do you handle authentication in E2E tests?"**
**A:** "I avoid logging in through the UI for every test, as it's slow. Instead, I programmatically request an auth token from the backend API in a `beforeAll` hook (or `global-setup` in Playwright) and inject this token into the browser's `localStorage` or cookies context. This allows tests to start immediately in the authenticated state."

**Q13: "What is mutation testing?"**
**A:** "Mutation testing (using tools like Stryker) modifies your source code (e.g., changing `+` to `-` or `true` to `false`) and runs your tests. If the tests still pass, the mutant 'survived,' indicating a gap in your test coverage. It's a way to test the quality of your tests, ensuring they are actually asserting meaningful behavior."

**Q14: "How do you mock a module that is a default export?"**
**A:** "In Jest, I use `jest.mock('./module', () => ({ __esModule: true, default: jest.fn() }))`. This explicitly tells Jest to treat the mock as an ES module with a default export, preventing type errors and ensuring imports work as expected."

**Q15: "How do you test a custom React Hook?"**
**A:** "I use `renderHook` from `@testing-library/react-hooks` (or the core library in React 18+). This allows me to call the hook in a test environment without creating a dummy component. I can assert on the `result.current` value and use `act()` to trigger state updates within the hook."

## 10. Conclusion

Mastering the testing pyramid is not merely about learning syntax; it is about adopting a mindset of rigorous verification and systematic problem-solving. For a Palantir Frontend Engineer, this means leveraging Jest for logic, React Testing Library for accessibility and user interaction, and Playwright for system-wide integrity. By synthesizing these tools with advanced strategies for mocking, virtualization, and performance profiling, an engineer can ensure that complex, data-driven applications like the "Universal Tutor" remain reliable, performant, and maintainable in the face of evolving requirements and massive scale. This expertise is the differentiator in the Palantir interview process, transforming a coding solution from "functional" to "production-ready."

### Assessment Ratings
*   **Learning Curve:** 3/5 (Jest/RTL are standard; Playwright/Mocking adds depth)
*   **Interview Frequency:** 5/5 (Debugging/Re-engineering is 100% guaranteed)
*   **Palantir Criticality:** 5/5 (Quality is paramount; "It works on my machine" is unacceptable)
*   **Depth Required:** 4/5 (Must understand why things fail, not just syntax; deep knowledge of the Event Loop and DOM is required for advanced debugging)


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/06_build_tooling.md
# ========================================================
# Enterprise Build Infrastructure: Webpack, Vite, and Gradle Integration at Scale

## 1. Introduction: The Strategic Role of Build Infrastructure in Enterprise Engineering

In the domain of modern software engineering, particularly within environments as complex and data-centric as Palantir Technologies, the build system is not merely a utility for transpilation; it is the foundational infrastructure that governs **developer velocity**, **application performance**, and **deployment reliability**. For a Frontend Engineer, especially one operating at the intersection of AI/ML systems and enterprise-grade user interfaces, mastery of build tooling is a non-negotiable competency. The transformation of raw source code—comprising TypeScript, React components, SCSS modules, and heavy visualization libraries—into deployable, performant artifacts involves a sophisticated orchestration of **dependency resolution**, **graph traversal**, and **optimization algorithms**.

This report provides an exhaustive analysis of the three pillars of build infrastructure relevant to the Palantir ecosystem:
1.  **Webpack:** The incumbent enterprise standard responsible for the vast majority of legacy and stable production builds.
2.  **Vite:** The modern challenger offering a paradigm shift in development experience through unbundled serving.
3.  **Gradle:** The unifying orchestrator that bridges the gap between the frontend JavaScript ecosystem and Palantir’s Java-based backend services.

The analysis is specifically calibrated for a candidate with a background in Mathematics and AI/ML, drawing parallels between **graph theory concepts** inherent in build algorithms and the candidate’s expertise in GraphRAG and Neo4j systems. Furthermore, it integrates the specific context of the "Universal Tutor" project, demonstrating how advanced build configurations can solve latency and visualization performance challenges inherent in intelligent tutoring systems.

The operational reality at Palantir requires "full-stack awareness." Frontend code does not exist in a vacuum; it is often co-located within massive **monorepos**, built alongside Java microservices, and packaged into hermetic Docker containers for deployment in air-gapped or secure environments. Consequently, this report transcends standard frontend tooling to encompass the integration patterns—such as the "**Frontend-in-Backend**" build model—that define the engineering culture of the target organization. By synthesizing insights from Palantir’s open-source footprint, including the Blueprint UI toolkit and custom Gradle plugins, this document serves as a comprehensive technical guide for navigating the architectural decisions and interview inquiries related to build tooling.

## 2. Webpack: The Enterprise Architecture of Compilation

Despite the ascendancy of newer tools, Webpack remains the bedrock of enterprise frontend development. Its ubiquity in Palantir’s job descriptions and its foundational role in the Blueprint library necessitate a deep, almost academic understanding of its internal mechanics. Webpack is best understood not just as a bundler, but as a **static module definition compiler** that constructs a dependency graph of an application and emits one or more bundles.

### 2.1 Core Architectural Concepts and Graph Theory

At its core, Webpack operates on principles of graph theory, a concept familiar to a candidate specializing in GraphRAG. The application is treated as a **directed graph** where files are nodes and import statements are edges.

#### 2.1.1 The Compilation Lifecycle and Tapable Instances

Webpack’s architecture is event-driven, built upon a core library called `Tapable`. This allows the system to be highly extensible via plugins. The compilation process follows a specific lifecycle that the candidate must understand to debug complex build failures or optimize performance:

1.  **Initialization:** Webpack reads the configuration file (`webpack.config.js`) and merges it with default options. It initializes the `Compiler` object, which represents the fully configured environment.
2.  **Entry Resolution:** The process begins at the configured entry point (e.g., `src/index.tsx`). Webpack uses a Resolver library (typically `enhanced-resolve`) to locate the file on the file system. This resolution process is configurable via `resolve.alias` and `resolve.extensions`, crucial for mapping module paths in monorepos.
3.  **Module Factory and Graph Building:** For the entry file, Webpack creates a `Module` object. It then performs the following recursive steps:
    *   **Load:** The content of the file is read.
    *   **Transform:** If the file matches a `module.rule` (e.g., a `.tsx` file), the corresponding **Loaders** are executed to transform the source code (e.g., TypeScript to JavaScript).
    *   **Parse:** The transformed source is parsed into an Abstract Syntax Tree (AST). Webpack analyzes the AST to identify dependencies (`import` statements, `require` calls, dynamic `import()` calls).
    *   **Resolve Dependencies:** Each identified dependency is resolved to a file path, creating a new node in the dependency graph. The process repeats recursively until the entire graph is traversed.
4.  **Sealing and Chunking:** Once the graph is complete, the compilation is "sealed." The optimization phase begins, where the graph is broken down into **Chunks**. This involves algorithms for graph partitioning to ensure optimal bundle sizes (e.g., separating vendor code from application code via `SplitChunksPlugin`).
5.  **Emission:** Finally, the compiler emits the assets (JavaScript bundles, CSS files, images) to the output directory.

#### 2.1.2 Functional Programming in Loaders

Loaders in Webpack function as pure transformation functions. They take the source of a resource file as a parameter and return the new source.
*   **Chaining Mechanism:** Loaders are executed in reverse order (right-to-left or bottom-to-top). For example, a rule for SCSS files in Blueprint might define `use: ['style-loader', 'css-loader', 'sass-loader']`.
    1.  First, `sass-loader` compiles SCSS to CSS.
    2.  Second, `css-loader` interprets `@import` and `url()` like `require/import` and resolves them.
    3.  Third, `style-loader` injects the CSS into the DOM via a `<style>` tag (in development).

**Candidate Application:** In the "Universal Tutor," handling data-dense visualizations might require loading raw shader files (`.glsl`) for WebGL rendering. The candidate would need to configure a `raw-loader` or a specialized `shader-loader` to treat these files as importable strings within the TypeScript code.

### 2.2 Deep Dive: Palantir’s Blueprint Webpack Configuration

Analyzing the **Blueprint repository** reveals how Palantir structures its build logic. Unlike simple projects that place a massive `webpack.config.js` in the root, Blueprint employs a sophisticated, abstracted build system.

#### 2.2.1 Abstraction via `webpack-build-scripts`

References to `@blueprintjs/webpack-build-scripts` indicate that Palantir abstracts common build logic into a shared package. This is a critical enterprise pattern that ensures consistency across the monorepo. Instead of duplicating configuration for `packages/core`, `packages/datetime`, and `packages/table`, a shared function generates the standard configuration.

*   **Standardization of Entry and Output:** The abstraction ensures that all packages adhere to a strict CommonJS/ESM output structure, which is vital for consumers of the library.
*   **TypeScript Integration:** Historically, Blueprint used `awesome-typescript-loader` but has likely migrated to `ts-loader` or `babel-loader` with `@babel/preset-typescript`. The distinction is important:
    *   `ts-loader`: Performs type checking during the build. This is safe but slow.
    *   `babel-loader`: Transpiles only (removes types). This is fast but requires a separate process (like `tsc --noEmit` or `fork-ts-checker-webpack-plugin`) to ensure type safety.

**Insight:** For a data-dense application like "Universal Tutor," relying solely on `babel-loader` for the main build thread is recommended to maintain developer velocity, while offloading type checking to a parallel process or CI step.

#### 2.2.2 Handling Styles and Assets in a Library

Blueprint is heavily dependent on Sass. The build system must compile SCSS not just into a JavaScript bundle, but also into standalone `.css` files for consumers who do not use Webpack.
*   `MiniCssExtractPlugin`: For production builds, styles are extracted into separate CSS files rather than injected into the DOM. This prevents a "Flash of Unstyled Content" (FOUC) and allows for parallel loading of CSS and JS resources.
*   **Asset Inlining:** Icons in Blueprint are often inlined as SVG paths to avoid HTTP requests. However, for the "Universal Tutor" which might use thousands of distinct graphical elements for graph nodes, the candidate must decide between **inlining** (bloats bundle, fewer requests) and **external loading** (smaller bundle, more requests/latency).

### 2.3 Optimization Strategies for Data-Dense Applications

Optimization in Webpack is not a checkbox; it is a continuous process of analyzing and refining the bundle generation strategy. For an application integrating GraphRAG and Neo4j visualizations, the bundle size can easily explode if not managed rigorously.

#### 2.3.1 Tree Shaking and Side Effects Analysis

Tree shaking is the process of eliminating dead code. It relies on the static analysis of ES2015 module syntax (`import` and `export`).

**The `sideEffects` Flag:** This `package.json` property is the most powerful tool for tree shaking. By marking a package as `"sideEffects": false`, the developer explicitly tells Webpack that if an imported module is not used, it can be safely removed without breaking the application.
*   **Blueprint Usage:** Blueprint packages explicitly declare side effects (e.g., `["**/*.css"]`). This tells Webpack to preserve CSS imports but aggressively shake unused JavaScript components.
*   **Candidate Context:** The "Universal Tutor" likely uses D3.js. Importing `import * as d3 from 'd3'` brings in the entire library. A tree-shakable import `import { forceSimulation } from 'd3-force'` coupled with proper `sideEffects` configuration ensures that modules like `d3-geo` or `d3-chord` are excluded from the final bundle.

#### 2.3.2 Algorithm for `SplitChunksPlugin`

Webpack 5’s `SplitChunksPlugin` uses specific heuristics to determine how to split code:
*   `MinSize`: The minimum size (in bytes) for a chunk to be generated (default 20kb).
*   `MaxSize`: A threshold where Webpack will attempt to split a chunk if it exceeds this size.
*   `Cache Groups`: This allows defining custom rules. For "Universal Tutor," creating a specific cache group for `neo4j-driver` and `d3` is advisable. These libraries change infrequently compared to application code. Segregating them into a long-lived vendor chunk ensures that users returning to the application do not re-download these heavy dependencies.

| Optimization Technique | Mechanism | Impact on "Universal Tutor" |
| :--- | :--- | :--- |
| **Tree Shaking** | AST analysis to remove unused exports | Reduces size of D3/UI libraries by excluding unused widgets |
| **Code Splitting** | Separates code into async chunks | Loads "Graph Visualization" route only when requested |
| **Scope Hoisting** | Concatenates modules into a single closure | Reduces function execution overhead in complex graph logic |
| **Persistent Caching** | Serializes build state to disk | Drastically reduces cold-start build times for large AI codebases |

#### 2.3.3 Performance Profiling

To optimize, one must first measure. The **Webpack Bundle Analyzer** generates an interactive treemap of the bundle content.
*   **Strategy:** The candidate should describe running this analysis to identify unexpected heavyweights (e.g., a momentary `lodash` import pulling in the entire library).
*   **Speed Measure Plugin:** This tool breaks down the time spent in each loader and plugin, helping to identify if a specific transformation (like image compression) is the bottleneck in build times.

## 3. Vite: The Modern Paradigm and Migration Strategy

While Webpack offers granular control, **Vite** offers velocity. Palantir’s interest in Vite acknowledges the industry shift towards unbundled development environments that leverage the modern capabilities of browsers (ES Modules).

### 3.1 Architecture: Unbundled Dev Server vs. Bundled Production

Vite fundamentally differs from Webpack by decoupling the development experience from the production build process.

#### 3.1.1 The "No-Bundle" Philosophy (Development)

In Webpack, changing a single file triggers a re-bundling process (albeit optimized via HMR). In Vite, the source code is served over native ESM.
*   **Request-Driven Compilation:** When the browser requests `import { Graph } from './Graph.tsx'`, the Vite server intercepts this request, compiles that specific file using **esbuild**, and returns it.
*   **Esbuild Performance:** Esbuild is written in **Go** and compiles TypeScript to JavaScript 10-100x faster than the JavaScript-based compilers used by Webpack.
*   **Relevance to AI/ML:** For the "Universal Tutor," which likely involves heavy logic for processing LLM streams, the rapid feedback loop provided by Vite prevents the developer from waiting for compilation during iterative logic tuning.

#### 3.1.2 Rollup for Production

For production builds, Vite utilizes **Rollup**.
*   **Why Bundle for Prod?** Despite HTTP/2 multiplexing, unbundled apps can still suffer from network waterfall issues due to deep dependency trees. Rollup provides highly efficient bundling, tree-shaking, and code-splitting to produce optimized static assets.
*   **Universal Build Consistency:** A common risk with Vite is the discrepancy between the dev environment (esbuild) and prod environment (Rollup). The candidate must be aware that obscure bugs can arise from differences in how these two tools handle edge cases in CommonJS interop or dynamic imports.

### 3.2 Migration Strategy: Webpack to Vite

Migrating a legacy Blueprint application to Vite is a complex task that tests a candidate's understanding of both systems. This is a high-probability interview topic given Palantir's mix of legacy and modern systems.

#### 3.2.1 Handling Environment Variables
*   **Webpack:** Uses `DefinePlugin` or `dotenv-webpack` to inject `process.env.API_URL`.
*   **Vite:** Exposes variables via `import.meta.env`.
*   **Migration:** The candidate would need to update all source code to use the new syntax or configure a Vite plugin to alias `process.env` for backward compatibility.

#### 3.2.2 CommonJS Interoperability
*   **The Issue:** Vite is ESM-first. Many older libraries in the React ecosystem are distributed only as CommonJS.
*   **Dependency Pre-Bundling:** Vite solves this by scanning dependencies on startup and pre-bundling CommonJS modules into ESM using `esbuild`. This is stored in `node_modules/.vite`. For a complex app like "Universal Tutor," explicitly configuring `optimizeDeps.include` might be necessary for libraries that are dynamically imported or hidden from static analysis.

#### 3.2.3 Glob Imports
*   **Webpack:** `require.context` is a proprietary feature often used to auto-load files (e.g., loading all translation files or all visualization modules).
*   **Vite:** Replaces this with standard `import.meta.glob`.
*   **Refactoring:** The candidate must describe how they would refactor `require.context('./locales', true, /\.json$/)` to `import.meta.glob('./locales/*.json')`.

### 3.3 Comparative Analysis: Webpack vs. Vite

| Feature | Webpack (Enterprise Stable) | Vite (Modern Agile) | Palantir Context |
| :--- | :--- | :--- | :--- |
| **Dev Server** | Bundles entirely/incrementally | Native ESM (Unbundled) | Webpack for Blueprint/Legacy; Vite for new internal tools |
| **Language Support** | Via Loaders (Babel/TS) | Esbuild (native TS support) | Vite offers superior TS performance |
| **Production Build** | Webpack Compiler | Rollup | Webpack allows deeper customization of chunking |
| **Config Complexity** | High (Boilerplate heavy) | Low (Opinionated defaults) | Webpack preferred for highly custom enterprise constraints |
| **Federation** | Native (Module Federation) | Plugin-based (Experimental) | Webpack essential if using Federation Architecture |

## 4. Gradle: The Orchestrator of the Full-Stack Monorepo

While Webpack and Vite handle the JavaScript layer, **Gradle** is the unifying force in Palantir’s infrastructure. A Frontend Engineer at Palantir is distinguished by their ability to navigate `build.gradle` files and understand how the frontend artifact fits into the Java-centric deployment pipeline.

### 4.1 The "Frontend-in-Backend" Build Pattern

In typical startup environments, the frontend and backend are often separate repositories built by separate CI jobs. At Palantir, hermeticity and monorepo cohesion are prioritized. The frontend often lives as a sub-project within a Gradle multi-project build.

#### 4.1.1 The Orchestration Flow

When a developer runs `./gradlew build` at the root of the repository:
1.  **Dependency Graph:** Gradle builds a graph of all tasks. It sees that the `backend:jar` task depends on the `frontend:compile` task (if resources are embedded) or that they are independent parallel tasks.
2.  **Frontend Delegation:** Gradle reaches the frontend sub-project. It doesn't know how to run TypeScript, so it delegates this to the `com.palantir.npm-run` plugin.
    *   This plugin executes `npm install` (only if `package.json` changed, utilizing Gradle's input/output caching).
    *   It then executes `npm run build` (which triggers Webpack/Vite).
3.  **Artifact collection:** The resulting `dist/` folder is treated as a build artifact, potentially zipped into a JAR or prepared for Dockerization.

### 4.2 Palantir’s Open Source Gradle Plugins

Knowledge of these specific plugins demonstrates deep research into Palantir’s engineering blog and open-source contributions.

#### 4.2.1 `com.palantir.npm-run`

This plugin provides a Gradle DSL for executing npm commands.
*   **Mechanism:** It manages a local installation of Node.js and Yarn/Npm within the build directory. This ensures **hermetic builds**: the build does not rely on the version of Node installed on the developer's laptop or the CI agent. It downloads and uses a precise version defined in the configuration.
*   **Caching:** It integrates with Gradle's build cache. If the inputs (`src/`, `package.json`) haven't changed, Gradle marks the task as `UP-TO-DATE` and skips the heavy Webpack build entirely.

#### 4.2.2 `com.palantir.docker`

Palantir applications are deployed as containers. The `com.palantir.docker` plugin allows developers to define Docker images within `build.gradle`.

```groovy
docker {
    name "${project.name}:${project.version}"
    files 'dist' // Copies the Webpack output to Docker context
    dockerfile file('Dockerfile')
}
```
**Strategic Value:** This keeps the versioning of the Docker image synchronized with the Git commit and the semantic version of the backend services, ensuring traceability from code to container.

#### 4.2.3 `com.palantir.baseline`

This plugin enforces code quality. While primarily for Java, it often includes configurations or hooks for enforcing formatting (via Spotless) across the repository. It represents the "strict" engineering culture where linting errors are build failures, not warnings.

### 4.3 Integrating Nx with Gradle

For massive monorepos, Gradle’s analysis of JavaScript dependencies can be coarse. Palantir and other large enterprises often integrate **Nx** to handle the granular dependency graph of the frontend while Gradle handles the macro orchestration.
*   **The `@nx/gradle` Plugin:** This plugin allows Nx to understand the Gradle project structure. It enables commands like `nx affected:build`, which can intelligently determine that a change in a shared TypeScript interface library should trigger a rebuild of the dependent Java backend (if code generation is involved) or vice versa.
*   **Optimization:** This hybrid approach combines Gradle's backend prowess with Nx's computation caching for JavaScript, resulting in significantly faster CI times.

## 5. Enterprise Patterns: Monorepos, Micro-Frontends, and CI/CD

### 5.1 Monorepo Management

The "Universal Tutor" project, if scaled to Palantir's level, would likely reside in a monorepo containing the core logic, the visualization library, and specific deployments for different user types.
*   **Dependency Hoisting:** Tools like **pnpm** (used in Blueprint) hoist dependencies to a shared root `node_modules`. This saves massive amounts of disk space and ensures that `react` is a singleton across the repository, preventing the "doppelganger" problem where multiple React instances cause hook failures.
*   **Release Management:** Palantir uses **Lerna** (or Lerna-Lite) in Blueprint to manage versioning. When a change is made to `packages/core`, Lerna detects the dependency chain and updates the version of dependent packages automatically.

### 5.2 Micro-Frontends and Module Federation

Palantir's Foundry is a platform composed of many applications (Slate, Workshop, Contour). This architecture is the prime use case for **Webpack 5 Module Federation**.
*   **Concept:** Module Federation allows a JavaScript application to dynamically load code from another application at runtime.
*   **Architecture for "Universal Tutor":**
    *   **Host:** The main application shell (navigation, auth, global context).
    *   **Remote 1:** The "Chat Interface" (LLM interaction).
    *   **Remote 2:** The "Knowledge Graph" (Neo4j visualization).
*   **Benefit:** The "Graph" team can deploy a new version of their visualization engine without forcing the "Chat" team to rebuild and redeploy the entire platform.
*   **Shared State:** Critical libraries (React, Redux, Blueprint) are shared as singletons. If both Remotes use React 18, it is loaded only once. If versions differ, Module Federation handles the fallback (loading the specific version needed).

### 5.3 CI/CD Optimization

In a repo with thousands of developers, build time is money.
*   **Incremental Builds:** Using Gradle's and Nx's caching means that if a developer changes a README file, the CI pipeline skips the heavy build tasks.
*   **Docker Layer Caching:** The Dockerfile structure is critical.
    *   *Inefficient:* `COPY.. -> RUN npm install`. (Any file change invalidates the install cache).
    *   *Optimized:* `COPY package.json. -> RUN npm install -> COPY...`. This preserves the `node_modules` layer unless dependencies actually change.

## 6. Applied Context: The "Universal Tutor" Project

This section explicitly connects the candidate's personal project to the enterprise concepts discussed.

### 6.1 Building High-Performance Visualizations with Web Workers

For the "Universal Tutor," rendering a Neo4j graph with thousands of nodes using D3.js can freeze the main thread.
*   **Build Solution:** The candidate should configure Webpack/Vite to use **Web Workers**.
*   **Mechanism:** Offload the force-directed graph calculation (physics simulation) to a worker.
*   **Implementation:** Use `worker-loader` (Webpack) or `new Worker(new URL(...))` (Vite/Standard). The build tool bundles the worker code into a separate file and handles the path resolution correctly.

### 6.2 Handling LLM Streaming and Proxies

The application likely streams data from an LLM API.
*   **Dev Server Proxy:** To avoid CORS issues during development, the Vite/Webpack config should include a proxy setup forwarding `/api` requests to the Python backend (e.g., FastAPI).

```typescript
// vite.config.ts
server: {
  proxy: {
    '/api': {
      target: 'http://localhost:8000',
      changeOrigin: true,
      rewrite: (path) => path.replace(/^\/api/, '')
    }
  }
}
```

### 6.3 Polyfilling for Modern AI Libraries

Some AI libraries (like LangChain.js) might rely on Node.js internals (crypto, stream, path) that are not present in the browser.
*   **Webpack 5 Issue:** Webpack 5 stopped polyfilling Node core modules by default.
*   **Solution:** The candidate may need to install `stream-browserify`, `crypto-browserify`, etc., and configure `resolve.fallback` in `webpack.config.js` to enable these libraries to run in the browser client.

## 7. Interview Q&A and Evaluation Matrix

### 7.1 Comparison Matrix

| Feature | Webpack | Vite | Gradle (Frontend Context) |
| :--- | :--- | :--- | :--- |
| **Primary Role** | Static Module Bundler | Dev Server + Bundler | Build Automation Orchestrator |
| **Development Speed** | Slower (Bundle-based HMR) | Instant (ESM-based HMR) | N/A (Delegates to npm/yarn) |
| **Configuration** | Complex, verbose, highly flexible | Opinionated, simple, plugin-based | Groovy/Kotlin DSL |
| **Ecosystem** | Massive, mature loader system | Growing, Rollup-compatible | JVM-centric, plugin-extensible |
| **Palantir Use Case** | Legacy apps, Blueprint, Federation | New internal tools, rapid prototyping | CI/CD pipeline, backend integration |
| **Hermeticity** | Depends on environment | Depends on environment | High (via `npm-run` plugin) |

### 7.2 Strategic Interview Questions

**Q1: "Our Blueprint library build is taking too long. How would you debug and optimize it?"**
**Answer:** "I would start by profiling the build using `webpack-bundle-analyzer` to identify large dependencies and `speed-measure-webpack-plugin` to find slow loaders. For Blueprint specifically, checking if we are transpiling SCSS unnecessarily or if TypeScript type checking is blocking the main thread would be key. I would suggest moving type checking to a separate process (`fork-ts-checker`) and using persistent filesystem caching (Webpack 5) to speed up cold starts."

**Q2: "Explain how you would architect the build system for 'Universal Tutor' if it were integrated into Palantir Foundry."**
**Answer:** "I would treat the Tutor as a micro-frontend using Module Federation. This allows it to be developed independently but loaded dynamically into the Foundry shell. I would use a monorepo structure with Gradle orchestrating the build to ensure the Python backend and React frontend versions are synchronized. The frontend would be containerized using `com.palantir.docker` to ensure a consistent deployment artifact."

**Q3: "Why does Palantir use `com.palantir.npm-run` instead of just running `npm install` in the CI script?"**
**Answer:** "It ensures hermeticity. Relying on the CI agent's pre-installed Node version introduces variability and 'works on my machine' bugs. The Gradle plugin downloads a specific, deterministic version of Node and Yarn local to the project, ensuring that the build environment is identical across all developer machines and CI servers."

**Q4: "We are migrating a legacy Webpack app to Vite. What are the biggest risks?"**
**Answer:** "The biggest risks are differences in module resolution and environment variables. Webpack-specific features like `require.context` won't work and need refactoring to `import.meta.glob`. Also, older CommonJS dependencies might break in Vite's strict ESM environment, requiring pre-bundling configuration. Finally, we need to ensure the production build (Rollup) behaves identically to the dev build (esbuild), as subtle bugs can emerge from the different compilers."

**Q5: "How does Tree Shaking work, and why might it fail in a complex application?"**
**Answer:** "Tree shaking relies on static analysis of import/export statements to remove unused code. It fails if the bundler thinks a file has 'side effects' (e.g., modifying global prototypes or CSS injection). If `package.json` doesn't strictly define `"sideEffects": false`, Webpack will conservatively include everything to prevent breaking the app. Dynamic imports or CommonJS `require()` calls also defeat tree shaking."

**Q6: "How do you handle 'dependency hell' in a large monorepo?"**
**Answer:** "By enforcing a 'Single Version Policy.' All packages in the monorepo must use the same version of shared libraries like React or Lodash. Tools like pnpm workspaces help enforce this by hoisting dependencies and using strict linking. If we need different versions, we must carefully manage peer dependencies or use build-time aliasing, but this should be a last resort."

**Q7: "In 'Universal Tutor', how do you ensure the heavy Neo4j driver doesn't slow down the initial page load?"**
**Answer:** "I utilize **Code Splitting**. I use dynamic `import()` syntax for the graph visualization components. This tells Webpack/Vite to create a separate chunk for Neo4j and D3, which is only loaded over the network when the user actually navigates to the graph view. I would also place these libraries in a separate vendor chunk cache group to ensure they are cached long-term by the browser."

**Q8: "Describe the 'Frontend in Backend' build pattern."**
**Answer:** "It's a pattern where the frontend build is wrapped as a task within the backend's build system (typically Gradle or Maven). This allows for a single build command to produce a deployable artifact containing both the API service and the static UI assets. It simplifies CI/CD pipelines but can couple the build times of the two stacks."

**Q9: "What is the role of `tapable` in Webpack?"**
**Answer:** "`Tapable` is the core library that exposes the lifecycle hooks (hooks like `compile`, `emit`, `done`) of the Compiler and Compilation. It allows plugins to 'tap' into these stages to modify the build graph, inject assets, or report status. Understanding Tapable is essential for writing custom plugins."

**Q10: "How do you handle environment-specific configuration (Dev vs. Prod vs. Staging) in a hermetic build?"**
**Answer:** "We should avoid 'baking in' environment variables at build time if possible. Instead, we should build a single Docker artifact ('Build Once, Deploy Anywhere') and inject configuration at runtime, perhaps by having the `index.html` load a `config.js` file that is generated by the container entrypoint or served by Nginx based on the current environment."

## 8. Conclusion

The build system is the nexus where code quality, developer experience, and deployment reliability converge. For a Palantir Frontend Engineer, proficiency extends beyond configuring a bundler; it requires an architectural mindset to orchestrate complex dependencies across languages and environments. By demonstrating mastery of Webpack's graph mechanics for the Blueprint ecosystem, Vite's modern velocity for new tools, and Gradle's hermetic integration for the broader backend infrastructure, the candidate positions themselves not just as a coder, but as a systems engineer capable of delivering the next generation of data-dense, mission-critical applications like the "Universal Tutor." This technical depth is the hallmark of the engineering culture at Palantir.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/07_version_control.md
# ========================================================
# Strategic Version Control and Collaborative Engineering for Palantir Candidates

## 1. The Strategic Imperative of Version Control in High-Stakes Engineering

In the domain of mission-critical software development—where deployed systems often support national defense, disaster response, and complex financial decision-making—version control transcends its traditional role as a mere backup utility. For an organization like Palantir Technologies, the Git repository serves as the **immutable ledger of truth**, the primary mechanism for asynchronous collaboration across global time zones, and the first line of defense in supply chain security. For a candidate positioning themselves as a Frontend Engineer with a specialized background in AI/ML systems and Mathematics Education, proficiency in these workflows is not optional; it is a foundational competency that determines one's ability to operate within Palantir’s unique **"Dev" (Product)** and **"Delta" (Forward Deployed)** ecosystem.

This report provides an exhaustive analysis of the version control and collaboration landscape required for the target role. It synthesizes advanced technical mechanics with the cultural philosophies that drive engineering decisions at Palantir. We will explore how the "Universal Tutor" project—a complex amalgamation of React frontends, GraphRAG backends, and Neo4j databases—must be managed within a monolithic repository structure, secured through enterprise-grade cryptographic signing, and evolved through a rigorous, classless code review process.

### 1.1 The Palantir Engineering Culture: Dev vs. Delta

To master collaboration at Palantir, one must first understand the bifurcation of its engineering force and how git serves as the unifying language between two distinct operational modes: Product Engineering ("Dev") and Forward Deployed Engineering ("Delta" or FDSE).

#### 1.1.1 The Product Engineer (Dev) Archetype

Product engineers focus on creating **scalable, generalized platforms** such as Foundry, Gotham, and Apollo. Their work environment is characterized by long-term horizons, deep abstraction, and rigorous stability guarantees. In this context, version control is used to enforce architectural purity.
*   **Workflow:** Heavy reliance on Continuous Integration (CI), monolithic repositories (monorepos), and **trunk-based development** to ensure that the "main" branch remains deployable at all times.
*   **Code Review Focus:** Reviews prioritize maintainability, API consistency, and preventing technical debt that could impact hundreds of downstream customers.
*   **Universal Tutor Context:** A "Dev" working on the "Universal Tutor" would focus on building the reusable Blueprint UI components that visualize the knowledge graph, ensuring these components perform efficiently whether rendering 10 nodes or 10,000 nodes.

#### 1.1.2 The Forward Deployed Engineer (Delta) Archetype

Forward Deployed Software Engineers (FDSEs) embed directly with customers to solve specific, often urgent, operational problems using Palantir's platforms. Their work is characterized by high autonomy, rapid iteration, and pragmatic problem-solving.
*   **Workflow:** FDSEs may work in "forked" realities or short-lived feature branches to hack together custom integrations. They often face the challenge of merging these custom "hacks" back into the core product or maintaining them as bespoke plugins.
*   **Code Review Focus:** Speed to value, operational correctness, and handling dirty real-world data.
*   **Universal Tutor Context:** An FDSE might modify the "Universal Tutor" frontend to work with a specific university's legacy authentication system or to visualize a unique, unstructured dataset provided by a research lab on a tight deadline.

#### 1.1.3 The Collaboration Friction and Resolution

The intersection of these two cultures often occurs in the **Pull Request (PR)**. An FDSE might submit a PR to the core "Universal Tutor" repository that adds a critical feature for a client but violates the strict styling or architectural guidelines of the Dev team. Understanding this dynamic is crucial for the interview. The candidate must demonstrate the ability to navigate this friction—advocating for the customer's need (Delta) while respecting the codebase's integrity (Dev). This often involves **"decomposing"** the problem: separating the client-specific logic into a configuration layer while merging the generic capability into the core platform.

### 1.2 The "Classless" Code Review Philosophy

Palantir adheres to a **"classless" code review culture**. This concept is vital for a candidate with a Mathematics Education background, as it parallels the pedagogical principle that truth is independent of authority. In a classless review system, the validity of code is judged solely on its merit, not the tenure of its author. A junior engineer is expected to review and critique the code of a principal architect if they spot a logical flaw or an edge case.

**Cultural Implications for the Interview:**
*   **Mentorship:** Code review is the primary vehicle for mentorship. The candidate should frame their experience with code reviews not just as error-catching, but as a bidirectional learning channel.
*   **Legibility:** The primary metric for code quality is "legibility." Code is read far more often than it is written. The Mathematics Education background supports this; just as a mathematical proof must be elegant and followable to be valid, code must be lucid.
*   **Triviality:** While some teams enforce reviews for every single commit, others set a "triviality threshold." However, in regulated environments (common for Palantir), even trivial changes require an audit trail. The candidate must show awareness that "trivial" changes (e.g., a CSS color shift) can have non-trivial consequences (e.g., accessibility violations).

### 1.3 Security as a First-Class Citizen

In the era of software supply chain attacks (e.g., SolarWinds, XZ Utils), version control security is paramount. Palantir’s clients include intelligence agencies and financial institutions where data leakage or code injection could be catastrophic.
*   **Signed Commits:** Every commit must be cryptographically signed (GPG/SSH) to prove authorship. This prevents "spoofing" where a malicious actor pushes code that appears to come from a trusted developer.
*   **Secret Scanning:** Pre-commit hooks and server-side scans prevent high-entropy strings (API keys, private keys) from entering the repository history. If a secret is committed, the history must be scrubbed, and the credential rotated immediately.

## 2. Advanced Git Mechanics for the "Universal Tutor"

For a Frontend Engineer working on a data-dense application like "Universal Tutor," basic `git add/commit/push` loops are insufficient. The complexity of managing a stack that includes React frontends, Python AI/ML services, and Neo4j database schemas necessitates a mastery of the **Directed Acyclic Graph (DAG)** that underpins Git.

### 2.1 The Directed Acyclic Graph (DAG) and History Manipulation

Git does not store "differences"; it stores snapshots of the entire file system, compressed and linked via SHA-1 hashes. Each commit points to its parent(s), forming a DAG. Understanding this structure is essential for advanced history manipulation, which is frequently tested in technical interviews.

#### 2.1.1 Interactive Rebase: Curating the Narrative

A messy commit history (e.g., "fix typo", "try again", "wip") obscures the intent of a code change. Before submitting a PR for the "Universal Tutor" frontend, the candidate should use interactive rebase to curate the history into atomic, semantic units.

**Scenario:** The candidate has developed a new D3.js visualization for the GraphRAG component. The local history looks like this:
*   `a1b2c`: Implement basic D3 force graph
*   `d4e5f`: Fix CSS centering bug
*   `g7h8i`: Update TypeScript interfaces for graph nodes
*   `j0k1l`: Fix typo in variable name
*   `m2n3o`: Optimize rendering performance

**The Operation:**
Running `git rebase -i HEAD~5` opens an editor. The candidate should restructure this to tell a coherent story:
*   **Pick** `a1b2c` (The core feature).
*   **Squash** `d4e5f` into `a1b2c` (The fix belongs with the feature).
*   **Pick** `g7h8i` (A separate, distinct change to the type system).
*   **Fixup** `j0k1l` into `a1b2c` (Typos are noise).
*   **Pick** `m2n3o` (Performance optimization is a distinct logical step).

**Result:** A clean, 3-commit series that reviewers can digest easily. This demonstrates respect for the reviewer's time and cognitive load.

#### 2.1.2 The Fixup and Autosquash Workflow

A "Nuanced" workflow that signals seniority is the use of `--fixup`. Instead of manually squashing commits later, the developer commits corrections immediately targeting the flawed commit.

**Workflow:**
1.  Developer notices a bug in commit `a1b2c` (Implement basic D3 force graph).
2.  Developer fixes the bug and runs: `git commit --fixup a1b2c`.
3.  This creates a special commit marker.
4.  When ready to push, run: `git rebase -i --autosquash origin/main`.
5.  Git automatically reorders and marks the fixup commit to be squashed into its target.

This workflow is particularly powerful in code review cycles. If a reviewer requests a change to the second commit in a PR, the author can add a fixup commit targeting that specific hash, ensuring the history remains clean without rewriting it manually every time.

### 2.2 Surgical Operations: Cherry-Pick and Reflog

#### 2.2.1 Cherry-Picking across Branches

In a complex project like "Universal Tutor," a bug fix deployed to a "release" branch often needs to be ported back to the "main" development branch (or vice versa).
*   **Command:** `git cherry-pick <commit-hash>`
*   **Risk Management:** Cherry-picking duplicates the commit (creating a new hash), which can confuse history if branches are eventually merged. It is best used for hotfixes where the branches have permanently diverged or for backporting specific fixes to LTS (Long Term Support) versions.

**Interview Question:** "You have a hotfix on the release branch. How do you get it into main?"
**Answer:** "I would ideally merge `release` into `main` to preserve the graph. However, if the branches have diverged significantly, I would cherry-pick the specific commit, ensuring I resolve any conflicts carefully and document the backport in the commit message."

#### 2.2.2 Reflog: The Safety Net

The `git reflog` is the "undo button" for git. It records every time the `HEAD` reference changes, even for actions that are not part of the project history (like checking out commits, resetting, or rebasing).

*   **Disaster Scenario:** During a rebase of the Neo4j integration branch, the candidate accidentally runs `git reset --hard origin/main`, wiping out 3 days of unpushed work.
*   **Recovery:**
    1.  `git reflog` shows:
        *   `84h20d HEAD@{0}: reset: moving to origin/main`
        *   `73j19c HEAD@{1}: commit: Implement Neo4j connectivity`
    2.  `git reset --hard HEAD@{1}` restores the state to before the accidental reset.

Demonstrating knowledge of `reflog` shows the interviewer that the candidate is fearless in manipulating history because they know how to recover.

### 2.3 Automated Regression Hunting: Git Bisect

Given the "AI/ML systems expert" background, the candidate is likely familiar with debugging complex non-deterministic systems. `git bisect` is the tool for finding deterministic bugs in the code history using a binary search algorithm ($O(\log n)$).

**Scenario:** A regression has appeared in the "Universal Tutor" where the GraphRAG component causes a memory leak after 10 minutes of usage. The last known good version was v2.4.0 (100 commits ago).

#### 2.3.1 Manual Bisection
1.  `git bisect start`
2.  `git bisect bad` (Current HEAD is bad).
3.  `git bisect good v2.4.0`.
4.  Git checks out the midpoint commit.
5.  The candidate runs the app, tests for the leak.
6.  If leaky: `git bisect bad`. If clean: `git bisect good`.
7.  Repeat until the culprit is found.

#### 2.3.2 Automated Bisection (The "10x" Approach)

Manual bisection is tedious. The advanced candidate writes a script to automate the detection.

**Script (`test-leak.sh`):**
```bash
#!/bin/bash
# Build the frontend
npm run build
# Run a specific Jest test designed to stress memory
npm test -- --testNamePattern="GraphRAG Memory Stability"
# Exit code 0 = Good, 1 = Bad
```
**Command:**
```bash
git bisect run ./test-leak.sh
```
**Handling Broken Builds:** In a monorepo, some historical commits might not build due to unrelated issues. The script can return exit code 125, telling `git bisect` to skip that commit and try a neighbor. This nuance is critical for working in large, active repositories.

### 2.4 Managing Large Files (Git LFS)

The "Universal Tutor" likely involves large ML models or datasets. Git is poor at handling large binaries.
*   **Solution:** `git-lfs` (Large File Storage). It stores the actual binary content in a separate blob store (like S3) and commits a text pointer to the git repo.
*   **Implication:** When cloning, the developer only downloads the pointers. The binaries are downloaded lazily or on demand, preventing the `.git` folder from bloating to gigabytes. This is essential for the "data-dense" requirement of the role.

## 3. Enterprise Branching and Workflow Strategy

The choice of branching strategy dictates the rhythm of collaboration. For Palantir, the tension between stability and velocity informs the choice between Git Flow and Trunk-Based Development.

### 3.1 Trunk-Based Development (TBD) vs. Git Flow

#### 3.1.1 Git Flow: The Traditional Model
Git Flow uses two long-lived branches: `main` (production) and `develop` (integration). Features are branched off `develop` and merged back. Releases are cut from `develop` into release branches, then merged to `main`.
*   **Pros:** Strict control, clear release artifacts.
*   **Cons:** "Merge hell" occurs when long-lived feature branches diverge significantly from `develop`. It discourages Continuous Integration (CI) because code sits in branches for weeks.
*   **Palantir Context:** While some legacy or strictly versioned on-premise products might use variations of this, it is generally considered too slow for modern SaaS.

#### 3.1.2 Trunk-Based Development: The Modern Standard
Developers work on short-lived branches (or directly on trunk) and merge to `main` multiple times a day.
*   **Pros:** Conflicts are small and resolved immediately. The codebase is always in a releasable state.
*   **Cons:** Requires rigorous automated testing and Feature Flags.
*   **Palantir Context:** This aligns with the "Dev" culture of continuous delivery. It allows the "Universal Tutor" to evolve rapidly.

**Interview Answer Formulation:**
"For a project like Universal Tutor, I advocate for **Trunk-Based Development**. It minimizes the integration gap. We avoid merge conflicts by merging small batches of code daily. Stability is maintained not by long-lived branches, but by comprehensive CI/CD pipelines and Feature Flags."

### 3.2 Feature Flags (Dark Launching)

Feature flags are the technological enabler for TBD. They allow code to be deployed (on the server) but not released (visible to users).

**Implementation in Blueprint UI:**
```typescript
import { Classes } from "@blueprintjs/core";

const GraphComponent = () => {
    // Check flag status (could be Redux, Context, or API call)
    const isNewGraphEnabled = useFeatureFlag("universal-tutor-graph-v2");

    if (isNewGraphEnabled) {
        return <GraphRAGVisualizerV2 />;
    }
    return <LegacyGraphVisualizer />;
};
```
This allows the candidate to merge the `GraphRAGVisualizerV2` code into `main` even if it is only 50% complete, as long as the flag is off. This prevents the need for a long-lived feature branch.

### 3.3 Conflict Resolution Strategies

#### 3.3.1 Technical Resolution: Rebase vs. Merge
When a conflict arises:
*   **Merge:** Preserves history exactly as it happened. Result: "Diamond" merge bubbles in the history.
*   **Rebase:** Rewrites history to place local changes on top of the updated upstream. Result: Linear history.
*   **Preference:** Palantir generally prefers a **linear history** for feature branches before merging to `main`. This makes bisecting and reading logs significantly easier. The candidate should `git rebase main` their feature branch to resolve conflicts locally before pushing.

#### 3.3.2 Social Resolution
Conflicts in logic (e.g., Developer A refactored the Auth module while Developer B was adding a Login feature) require communication.
*   **Interview Response:** "If I encounter a semantic conflict, I don't just blindly choose 'ours' or 'theirs.' I look at the git blame/history to identify the other author. I reach out (Slack/Zoom) to understand their intent. If they are an FDSE hacking a fix for a client, I need to understand if my refactor breaks their deployment. We might decide to pair-program the resolution."

## 4. Monorepo Architecture & Performance

The "Universal Tutor" is described as a system with React frontends, AI/ML backends, and data layers. In modern enterprise engineering, these are often co-located in a Monorepo.

### 4.1 The Case for Monorepos at Palantir
*   **Atomic Commits:** A change to the API schema (backend) and the React component consuming it (frontend) can be committed in a single atomic transaction. This prevents version skew where the frontend breaks because the backend was updated first.
*   **Code Sharing:** TypeScript interfaces for the "Universal Tutor" domain model can be shared between the React frontend and the Node.js/Python backend (if using TS/Python type generation), ensuring type safety across the stack.
*   **Unified Tooling:** One linting configuration, one build pipeline.

### 4.2 Handling Scale: Sparse Checkout and Cone Mode

As the monorepo grows (gigabytes of history, thousands of files), `git status` becomes slow.
*   **Sparse Checkout:** Allows the developer to have a working directory that only contains a subset of the files.
*   **Cone Mode:** An optimization in Git that restricts sparse checkout patterns to directories, significantly speeding up performance.

**Workflow for the Candidate:**
"When I onboard to the massive Universal Tutor monorepo, I don't need the legacy Java Swing components or the raw training datasets. I use sparse checkout:"
```bash
git sparse-checkout init --cone
git sparse-checkout set packages/tutor-ui packages/graph-rag-service
```
This keeps the local footprint light while maintaining access to the full repository history.

### 4.3 Build System Integration: Gradle and Nx

The tech stack lists Gradle. In a polyglot monorepo, the build system must be smart.
*   **Gradle:** Excellent for Java/Kotlin backends. It supports incremental builds and build caching. If the "Universal Tutor" backend is Java, Gradle manages the dependency graph.
*   **Nx:** Often used for the JavaScript/TypeScript side. It can coexist with Gradle. Nx builds a dependency graph of the JS packages.
*   **Task Avoidance:** Both tools support "affected" commands.
    *   `nx affected:test`: Only run tests for projects that have changed or depend on changed projects.
    This is critical for CI/CD performance. If the candidate changes a CSS file in the frontend, the CI should not run the 2-hour ML model training pipeline.

## 5. GitHub Enterprise Ecosystem

Palantir utilizes GitHub Enterprise. Proficiency here goes beyond basic PRs into compliance and automation.

### 5.1 CODEOWNERS: Compliance as Code

The `CODEOWNERS` file is a governance mechanism. It forces specific teams to review changes to specific file paths.

**Structure:**
```
# Default owners for everything
*                   @palantir/tutor-core-team

# Frontend team owns UI
packages/ui/        @palantir/frontend-leads

# Security team must review all auth logic
packages/auth/      @palantir/security-team

# Documentation
/docs/              @palantir/tech-writers
```
*   **Nuance:** The last matching pattern wins. If a file is in `packages/auth/`, the security team owns it, overriding the frontend leads. This ensures that a frontend engineer cannot accidentally introduce a vulnerability in the auth module without security sign-off.

### 5.2 Semantic Release and Conventional Commits

To support continuous delivery, release versioning is automated.
*   **Conventional Commits:**
    *   `fix: resolve graph rendering artifact` -> Triggers Patch Release (v1.0.1)
    *   `feat: add D3 force simulation` -> Triggers Minor Release (v1.1.0)
    *   `feat!: drop support for IE11` -> Triggers Major Release (v2.0.0)
*   **Workflow:** A GitHub Action runs on merge to main. It analyzes the commit messages, calculates the next version, generates the `CHANGELOG.md`, tags the commit, and publishes the package to the internal npm registry. This removes human error ("forgetting to bump the version").

### 5.3 CI/CD Integration (GitHub Actions)

The PR workflow is the primary quality gate.
*   **Status Checks:** Commits cannot be merged unless status checks pass. These include:
    *   **Lint:** ESlint/Prettier check.
    *   **Test:** Jest/Cypress tests.
    *   **Build:** Ensuring the code compiles.
    *   **License Scan:** Checking for banned open-source licenses.
*   **Branch Protection:** The `main` branch is protected.
    *   Require linear history (no merge commits).
    *   Require 2 approving reviews (one from CODEOWNERS).
    *   Require signed commits.

### 5.4 Security: Secret Scanning and GPG Signing

*   **Secret Scanning:** Palantir's "Universal Tutor" likely connects to LLM providers (OpenAI, Anthropic). API keys must never be committed. GitHub Advanced Security scans pushes for these patterns. If found, the push is rejected. If found in history, the secret is considered compromised.
*   **GPG/SSH Signing:** To prevent identity spoofing, the candidate must configure their local git to sign commits.
    ```bash
    gpg --full-generate-key
    git config --global user.signingkey <KEYID>
    git config --global commit.gpgsign true
    ```
*   **Troubleshooting:** If the GPG key expires or the email doesn't match the GitHub account, the commit shows "Unverified." The candidate must know how to update keys and potentially re-sign commits (`git commit --amend -S`).

## 6. Behavioral Mastery & Interview Preparation

The "Behavioral" and "Decomposition" interviews at Palantir are where technical skills meet cultural fit. The candidate must demonstrate they can navigate the high-autonomy, high-responsibility environment.

### 6.1 Deconstructing the "Difficult Code Review" Question

**Question:** "Tell me about a time you had a difficult code review or conflict."
*   **The Trap:** Blaming the other person or focusing only on technical correctness.
*   **The "Palantir" Answer Strategy (STAR):**
    *   **Situation:** "On the Universal Tutor project, I submitted a PR to optimize the GraphRAG rendering using a new WebGL library. It was a complex change (50+ files)."
    *   **Task:** "The lead engineer blocked the PR, arguing that the library was too heavy and that we should optimize the existing D3 implementation instead. We were at a stalemate."
    *   **Action:** "Instead of arguing in the PR comments (which lacks bandwidth), I scheduled a 30-minute whiteboard session. I acknowledged their concern about bundle size (Dev mindset). I presented benchmarks showing that D3 could not handle the 10k+ node scale required by our new client (Delta mindset). We agreed on a compromise: I would implement the WebGL solution but lazily load the library so it didn't impact initial page load."
    *   **Result:** "The feature merged, the client was happy with performance, and the core platform remained lean. I documented the decision in an ADR (Architecture Decision Record) for future reference."
*   **Analysis:** This shows empathy, data-driven decision making, and constructive conflict resolution.

### 6.2 Managing "Dev vs. Delta" Tensions

**Question:** "You are an FDSE. You need a feature in the Blueprint UI to close a deal by Friday. The Core Dev team says the feature is on the roadmap for next quarter. What do you do?"
*   **Answer Strategy:**
    1.  **Assess Impact:** Is this truly a blocker? Can I use a workaround?
    2.  **Fork/Patch:** "I would implement the feature locally in the client's deployment or a fork to unblock the deal (Delta speed)."
    3.  **Upstream:** "I would simultaneously open a PR or RFC with the Core team to contribute this feature back properly. I would commit to owning the maintenance of the patch until it is properly integrated."
*   **Anti-Pattern:** "I would just complain to management" or "I would hack it in and forget about it." (This creates technical debt).

### 6.3 System Design (Decomp): Version Control for ML

**Question:** "How would you design the version control strategy for the Universal Tutor, considering it has code, data, and models?"
*   **Answer Elements:**
    *   **Code:** Git Monorepo (React/Python).
    *   **Data/Models:** Git LFS or DVC (Data Version Control). "We shouldn't store 5GB model weights in git. We store DVC pointer files. The actual weights live in S3."
    *   **Coordination:** "We use CI pipelines to ensure that a change to the Model Architecture code triggers a retraining run or a validation run against the versioned dataset."

### 6.4 Table: Interview Question Bank & Scoring Guide

| Category | Question | Key Competencies Assessed | Optimal Response Vectors |
| :--- | :--- | :--- | :--- |
| **Mechanics** | "You accidentally committed a secret to main. What do you do?" | Panic response, Technical depth (BFG/Filter-repo), Security awareness. | 1. Revoke the secret immediately. <br> 2. Rewrite history (BFG repo-cleaner) to remove the commit. <br> 3. Force push (with team comms). <br> 4. Audit logs for usage. |
| **Workflow** | "Why might we choose Trunk-Based Development over Git Flow for Blueprint?" | Understanding of CI/CD, Release velocity. | TBD reduces merge complexity, enforces smaller batches, and relies on automated testing. Git Flow slows down feedback loops. |
| **Collaboration** | "A junior engineer submits a massive 2000-line PR. How do you review it?" | Mentorship, Empathy, Process standards. | Don't review it. Kindly ask them to break it down into atomic commits/PRs. Explain why (risk, reviewability). Offer to pair on the decomposition. |
| **Conflict** | "You disagree with a senior architect on a PR. They are pushing back." | "Classless" review culture, Data-driven argument. | Respectfully dissent. Build a POC or benchmark to prove your point. If still stuck, agree to disagree and commit (if non-critical) or escalate to a neutral third party. |
| **Tooling** | "How do you handle merge conflicts in `package-lock.json`?" | Granular tool knowledge. | Delete the lockfile conflict markers. Run `npm install` to regenerate it based on the resolved `package.json`. Never manually edit the hash map. |

## 7. Conclusion: The Integrated Engineer

Success in the Palantir interview process for a Frontend Engineer requires more than just knowing React and TypeScript. It demands a holistic engineering mindset where Version Control is the central nervous system of collaboration.

The candidate's background in Mathematics Education provides a unique advantage: the ability to explain complex logic clearly and the understanding that rigorous proof (code review/testing) is essential for truth. By combining this with the technical mastery of Advanced Git (bisect, rebase, reflog) and the strategic understanding of Palantir’s "Dev vs. Delta" culture, the candidate can position themselves not just as a coder, but as a high-impact engineer capable of navigating the complex, high-stakes environment of data intelligence.

The "Universal Tutor" is not just a project; it is the proving ground. Every git bisect run to fix a regression, every git rebase to clean up a PR, and every nuanced code review comment is a demonstration of the candidate's readiness to deploy software that powers the world's most critical institutions.

## 8. Quick Reference: Critical Commands and Patterns for "Universal Tutor"

| Category | Command / Pattern | Specific Use Case in "Universal Tutor" |
| :--- | :--- | :--- |
| **History Cleanup** | `git rebase -i HEAD~n` | Squash "WIP" commits in the D3 visualization feature branch before PR. |
| **Auto-Fix** | `git commit --fixup <sha>` | Quickly address PR feedback on the specific GraphRAG commit without manual squashing. |
| **Regression Hunt** | `git bisect run ./test-leak.sh` | Automatically find which commit introduced a memory leak in the WebSocket handler. |
| **Disaster Undo** | `git reflog` -> `git reset --hard HEAD@{n}` | Restore the `feature/neo4j-connector` branch after a failed merge attempt. |
| **Monorepo** | `git sparse-checkout set packages/frontend` | Clone only the frontend UI code, ignoring the massive ML training data backend. |
| **Porting** | `git cherry-pick <sha>` | Apply a critical accessibility fix from `main` to the `release/v1.0` branch for a client. |
| **Security** | `git secrets --scan` | Verify no API keys for the LLM service are present in the local commit history. |
| **Syncing** | `git pull --rebase origin main` | Update local feature branch with latest main changes without creating a merge bubble. |

This playbook serves as the definitive guide for mastering the Version Control & Collaboration domain for the Palantir interview.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/coding/palantir-fde-learning/knowledge_bases/08_advanced_capabilities.md
# ========================================================
# Advanced Frontend Engineering Architectures for Mission-Critical Data Environments

## 1. The Operational Paradigm: Engineering for High-Stakes Intelligence

The role of a Frontend Engineer at Palantir Technologies differs fundamentally from typical commercial web development. While the broader industry often prioritizes search engine optimization, marketing-driven metrics, and mobile-first responsive design, the engineering culture within Palantir centers on building **"operating systems for the modern enterprise"**. Platforms like Foundry and Gotham are designed to ingest, integrate, and visualize massive, heterogeneous datasets—ranging from financial transaction logs to satellite telemetry—to facilitate high-stakes decision-making.

In this context, the frontend is not merely a presentation layer; it is a critical interface for **human-computer interaction** where latency, data integrity, and information density are paramount. The user persona is typically an analyst or operator working in a high-stress environment, often requiring the simultaneous visualization of tens of thousands of data points to detect patterns, anomalies, or threats. Consequently, the technical requirements shift from "user engagement" to **cognitive ergonomics** and **system reliability**.

The architectural challenges inherent in this domain necessitate a mastery of performance optimization that extends deep into the browser's rendering engine. Engineers must navigate the trade-offs between **retained-mode graphics (SVG)** and **immediate-mode rendering (Canvas/WebGL)**, manage memory in long-lived single-page applications (SPAs), and implement robust **offline capabilities** for air-gapped or disconnected environments. Furthermore, the strict adherence to **accessibility standards (WCAG 2.1, Section 508)** is not optional but a contractual and operational necessity for government and defense clients.

This report provides a rigorous technical analysis of the skills and architectural patterns required to succeed in this environment. It dissects the **Blueprint UI** ecosystem, the **Plottable.js** visualization library, and advanced browser capabilities like **Web Workers** and **SharedArrayBuffers**, providing a comprehensive guide to system design in data-intensive frontend engineering.

## 2. The Blueprint UI Ecosystem: Composition, Types, and Accessibility

The foundation of Palantir’s frontend architecture is **Blueprint**, a React-based UI toolkit developed explicitly for desktop applications that require complex, data-dense interfaces. Unlike Material UI or Bootstrap, which often prioritize mobile touch targets and generous whitespace, Blueprint is engineered for density. It provides a comprehensive set of interactive components—from date range pickers to hierarchical trees—that allow developers to compose intricate workflows without reinventing fundamental interaction patterns.

### 2.1 TypeScript and Strict Interface Contracts

Blueprint is written in **TypeScript**, reflecting a broader engineering philosophy that values type safety and contract enforcement. In large-scale applications like Foundry, where the frontend codebase can span millions of lines, TypeScript serves as a critical refactoring tool and documentation source. The library utilizes strict **interfaces** to define component props, ensuring that data passed from the ontology layer to the presentation layer conforms to expected shapes.

For example, the separation of concerns in Blueprint is enforced through specific prop interfaces. A `Button` component does not simply accept arbitrary HTML attributes loosely; it defines precise interfaces for `intent` (visual signaling of severity), `icon`, and `text`. This strictness prevents "prop explosion" and encourages developers to use the library's defined API surface, reducing the risk of regression during updates.

### 2.2 Deep Dive into Accessibility (a11y) Architecture

One of the most distinguishing features of Blueprint—and a critical topic for interview preparation—is its rigorous approach to accessibility. Accessibility in this context is not merely about supporting screen readers; it is about ensuring the application remains usable under high-cognitive-load scenarios and for operators who rely heavily on keyboard navigation for speed.

#### 2.2.1 The `FocusStyleManager` Utility

Standard browser focus rings (the blue outline around active elements) can be visually distracting in a dense dashboard, yet they are essential for keyboard navigation. Blueprint resolves this conflict through the `FocusStyleManager`. This utility programmatically detects the user's interaction mode.

*   **Mouse Interaction:** If the user clicks an element, the manager suppresses the focus outline, maintaining a clean visual aesthetic.
*   **Keyboard Interaction:** If the user presses the Tab key, the manager enables focus styles, ensuring that the active element is clearly visible.

This behavior, activated via `FocusStyleManager.onlyShowFocusOnTabs()`, represents a sophisticated understanding of user intent, balancing visual clarity with functional accessibility.

#### 2.2.2 ARIA Integration and Prop Interfaces

Blueprint components are designed to enforce semantic HTML and proper ARIA (Accessible Rich Internet Applications) attributes. A common anti-pattern in React development is the creation of icon-only buttons without accessible labels. Blueprint mitigates this by exposing specific props for accessibility.

**Table 1: Blueprint Component Accessibility Props**

| Component | Key Accessibility Props | Architectural Purpose |
| :--- | :--- | :--- |
| **Button / AnchorButton** | `aria-label`, `aria-expanded`, `aria-haspopup` | Provides an accessible name when `text` prop is empty (icon-only). Manages state communication for dropdowns. |
| **InputGroup** | `inputRef`, `aria-label` (on input) | Allows passing ARIA attributes directly to the underlying `<input>` element rather than the wrapper `<div>`. |
| **Overlay / Dialog** | `canEscapeKeyClose`, `enforceFocus` | Manages focus trapping within modals to prevent tab navigation from escaping to the background application. |
| **Menu / MenuItem** | `role="menu"`, `role="menuitem"` | Ensures screen readers perceive the list of links as a structured navigation menu rather than a generic list. |

The `aria-label` prop is particularly critical. In the absence of a visible text label, the `aria-label` provides the string that screen readers announce. Blueprint’s design assumes that if a developer removes the `text` prop to create a compact toolbar button, they must supply an `aria-label` to maintain compliance with WCAG 2.1 standards.

### 2.3 Portal Rendering and Overlay Management

Complex applications often require elements to "break out" of their parent containers (stacking contexts) to appear on top of other content. Blueprint handles this via the `Overlay` and `Portal` components. A `Portal` renders its children into a new DOM node that exists outside the current component hierarchy—typically appended directly to the `document.body`.

This architectural pattern solves z-index, overflow-clipping, and positioning issues inherent in deeply nested DOM structures. However, it introduces complexity regarding event bubbling and focus management. Blueprint’s `Overlay` component automatically manages:
*   **Focus Trapping:** Ensuring that when a modal opens, keyboard focus is constrained to that modal until it closes.
*   **Scroll Locking:** Preventing the background page from scrolling while the overlay is active.
*   **Backdrop Interaction:** Handling clicks on the backdrop to dismiss the overlay.

The `useOverlayStack` hook allows for the coordination of multiple stacked overlays, ensuring that the Escape key only dismisses the topmost overlay, preserving the state of those beneath it.

## 3. Data Visualization Architecture: D3.js and Plottable.js

While React excels at managing DOM elements for UI controls, it is often insufficiently performant or expressive for complex data visualization. **D3.js (Data-Driven Documents)** is the industry standard for mapping data to visual representations using SVG. However, D3’s imperative API conflicts with React’s declarative model. Palantir’s solution to this friction is **Plottable.js**, a library of modular chart components built on top of D3.

### 3.1 The "Composition over Configuration" Philosophy

Most charting libraries (e.g., Chart.js, Highcharts) operate on a "Configuration" paradigm: the developer passes a massive JSON object describing every aspect of the chart. While easy to start, this approach becomes brittle when customization is required. Plottable.js adopts a "**Composition**" paradigm. A chart is not a single object but a collection of distinct Components (Plots, Axes, Legends, Labels) wired together programmatically.

#### 3.1.1 The Table Layout Engine

One of the hardest problems in D3 is layout—specifically, ensuring that a Y-axis and a chart align correctly regardless of the length of the axis labels. Plottable solves this by implementing a layout engine inspired by HTML tables. Components are arranged in a grid (a `Table`), where rows and columns effectively manage space distribution.

**Example Architecture:**
```javascript
// Compositional approach in Plottable
var xScale = new Plottable.Scales.Linear();
var yScale = new Plottable.Scales.Linear();
var xAxis = new Plottable.Axes.Numeric(xScale, "bottom");
var yAxis = new Plottable.Axes.Numeric(yScale, "left");
var plot = new Plottable.Plots.Line()
   .x(d => d.x, xScale)
   .y(d => d.y, yScale);

// Layout logic separated from rendering logic
var table = new Plottable.Components.Table([yAxis, plot],
  [null, xAxis]);
table.renderTo("svg#chart");
```
This decoupling allows developers to substitute components easily—swapping a Line plot for a Bar plot requires changing only the plot instantiation, not the layout logic or scale definitions.

### 3.2 Scales, Datasets, and Reactivity

Plottable’s architecture centers on **Scales** and **Datasets** as the primary sources of truth.
*   **Scales:** These map data domains (input values) to screen ranges (pixels). Crucially, a single Scale instance can be shared across multiple plots. If the domain of the scale changes (e.g., via a pan interaction), every component linked to that scale updates automatically. This enables effortless synchronization of multi-chart dashboards.
*   **Datasets:** Data is wrapped in `Dataset` objects. Unlike D3’s direct data binding, Plottable’s Datasets provide a mechanism to notify listeners of data changes. When `dataset.data(newData)` is called, the library triggers an optimized update cycle, repainting only the affected components.

### 3.3 Integrating D3 with React: The Reconciliation Challenge

When using raw D3 within React (outside of Plottable), engineers face the "**Two Owners**" problem: both React and D3 want to control the DOM. There are three primary integration patterns:
1.  **React as Container (Black Box):** React renders a `<div>` or `<svg>` and passes a ref to a `useEffect` hook. Inside the hook, D3 takes full control, entering, updating, and exiting nodes imperatively. This allows the use of D3 transitions but bypasses React’s Virtual DOM diffing.
2.  **React as Renderer (Faux DOM):** D3 is used only for math—calculating path data strings (`d` attributes) or scale positions. React renders the actual `<path>` and `<circle>` elements. This is "idiomatic" React but incurs a performance penalty when rendering thousands of nodes, as React must reconcile each element.
3.  **Hybrid Virtualization:** For massive datasets, React handles the container and virtualization (rendering only visible elements), while D3 handles the math for the specific visible subset.

For enterprise-grade applications, the Black Box approach is often preferred for complex, animated visualizations to avoid the overhead of React’s reconciliation cycle on every frame of an animation.

## 4. Rendering Performance: Breaking the 100k Point Barrier

A recurring requirement in Palantir’s domain is the visualization of massive datasets—scatter plots of 100,000 entities or time-series data spanning decades. The choice of rendering technology (SVG, Canvas, or WebGL) is the single most important architectural decision in these scenarios.

### 4.1 Comparative Analysis of Rendering Technologies

**Table 2: Browser Rendering Technologies**

| Feature | SVG (Retained Mode) | Canvas (Immediate Mode) | WebGL (Hardware Accelerated) |
| :--- | :--- | :--- | :--- |
| **Object Model** | DOM Nodes (Vector). Each point is an element. | Raster Bitmap. Single DOM element. | Raster via GPU Shaders. Single DOM element. |
| **Performance Limit** | ~1k - 5k elements. | ~10k - 100k elements. | ~1M - 10M+ elements. |
| **Memory Overhead** | High. Browser maintains state/event listeners for every node. | Low. Only the pixel buffer is stored. | Low. Data stored in GPU buffers. |
| **Interaction** | Native DOM events (`onClick`, `onHover`). | Manual coordinate mapping (Raycasting). | Complex raycasting/color-picking. |
| **Styling** | CSS. | Canvas Context API. | GLSL Shaders. |
| **Use Case** | Interactive, low-density charts. Accessibility required. | Real-time tickers, heatmaps, medium density. | Geospatial maps, 3D models, massive scatter plots. |

#### 4.1.1 The SVG Bottleneck

SVG is vector-based and resolution-independent, making it ideal for crisp text and lines. However, because each data point is a DOM node, the browser must calculate layout and styles for every element. As the number of nodes increases, the time required for "Recalculate Style" and "Layout" phases explodes, leading to frame drops during interactions like zooming.

#### 4.1.2 The Canvas Alternative

HTML5 Canvas uses an "immediate mode" rendering model. The developer issues draw commands (e.g., `ctx.fillRect`), which modify a pixel buffer. Once drawn, the browser "forgets" the object. This eliminates the DOM overhead, allowing for the rendering of tens of thousands of points at 60fps. However, interaction becomes difficult; detecting which circle the mouse is hovering over requires mathematical spatial indexing (e.g., Quadtrees) rather than simple event listeners.

#### 4.1.3 WebGL and Hardware Acceleration

For datasets exceeding 100,000 points, even CPU-based Canvas rendering can become a bottleneck. WebGL moves the processing to the Graphics Processing Unit (GPU), which is optimized for parallel operations. Libraries like Deck.gl or D3FC leverage WebGL to render millions of points. The complexity cost is high: developers must manage buffers, textures, and shaders, and data transfer between the CPU and GPU can become a new bottleneck if not managed correctly.

### 4.2 Algorithmic Optimization: Downsampling with LTTB

Rendering 1 million points on a screen that is only 1,000 pixels wide is not only performant-prohibitive but also visually useless—multiple data points will map to the same pixel. **Downsampling** is the process of reducing the dataset size while preserving its visual characteristics.

The industry-standard algorithm for this is **Largest-Triangle-Three-Buckets (LTTB)**. Unlike simple decimation (taking every n-th point), which can miss critical peaks and valleys, LTTB divides the dataset into buckets and selects the point in each bucket that forms the largest effective triangle area with the selected points in the adjacent buckets.

1.  Divide the data into buckets based on the target resolution (e.g., 1,000 buckets for a 1,000px chart).
2.  Select the first and last data points to anchor the chart.
3.  Iterate through buckets: for each bucket, calculate the triangle formed by the previously selected point, the current point candidate, and the average of the next bucket. Pick the candidate that maximizes this triangle's area.

Implementing LTTB (often in a Web Worker) allows the frontend to process raw datasets of millions of rows into a lightweight array of ~1,000 points that acts as a visually indistinguishable proxy, enabling performant rendering even with SVG.

## 5. Concurrency and Data Processing: Web Workers and Shared Memory

The browser's main thread is responsible for executing JavaScript, performing layout, and painting pixels. A "**Long Task**" (any task taking >50ms) on the main thread will cause the UI to freeze, leading to a degraded user experience (jank). In data-intensive applications, operations like parsing large JSON files, filtering arrays, or computing layouts must be offloaded.

### 5.1 Web Workers and the Serialization Cost

**Web Workers** allow scripts to run in background threads. However, standard communication with workers relies on `postMessage`, which uses the Structured Clone Algorithm to copy data. For a 100MB dataset, the time taken to copy the data to the worker and copy the result back can exceed the time taken to process it.

### 5.2 SharedArrayBuffer (SAB) and Atomics

To solve the serialization bottleneck, modern browsers support `SharedArrayBuffer`. This object represents a generic, fixed-length raw binary data buffer that can be shared between the main thread and workers **without copying**.

*   **Zero-Copy Sharing:** Both threads hold a reference to the same memory block.
*   **Typed Arrays:** Data is accessed via views (e.g., `Int32Array`, `Float64Array`) mapped to the buffer.
*   **Synchronization with Atomics:** Because multiple threads can access the SAB simultaneously, race conditions are a risk. The `Atomics` object provides static methods (e.g., `Atomics.add`, `Atomics.load`, `Atomics.store`, `Atomics.wait`) to ensure that read/write operations are indivisible and thread-safe.

**Implementation Example:**
A worker can process a massive array of numbers (e.g., applying a filter or aggregation) stored in a `SharedArrayBuffer` while the main thread waits or performs other tasks. When the worker finishes, it uses `postMessage` merely to signal completion, not to transfer data.

**Security Requirements (Cross-Origin Isolation):**
Due to Spectre/Meltdown vulnerabilities, browsers restrict `SharedArrayBuffer` availability. To use it, the application must be served with specific headers:
*   `Cross-Origin-Opener-Policy: same-origin`
*   `Cross-Origin-Embedder-Policy: require-corp`
This isolates the browsing context, ensuring that the page cannot load cross-origin resources (like images from a CDN) unless those resources explicitly opt-in.

## 6. Real-Time Architectures: WebSockets and Streaming

Applications like Gotham require real-time situational awareness. The traditional HTTP request/response model (polling) is inefficient for high-frequency updates due to header overhead and latency.

### 6.1 WebSocket Implementation Patterns

**WebSockets** provide a persistent, full-duplex communication channel over a single TCP connection.
*   **Connection Lifecycle:** React integration involves complex state management. A robust implementation (or a hook like `react-use-websocket`) must handle connection establishment, error trapping, and automatic reconnection with exponential backoff (e.g., wait 1s, 2s, 4s before retrying) to prevent server flooding during outages.
*   **Multiplexing:** Rather than opening a new socket for every chart, a single socket connection should act as a pipe for all application messages, with a dispatcher routing data to specific components based on message types or subscription IDs.

### 6.2 Throttling and Rendering Strategies

A common pitfall is connecting a high-frequency WebSocket stream directly to React's `setState`. If the server pushes 100 updates per second, triggering 100 React reconciliation cycles will crash the browser.

**Optimization Strategies:**
1.  **Buffering:** Incoming messages are pushed into a mutable buffer (e.g., a standard JavaScript Array or Map) outside the React render cycle.
2.  **Throttling/Batching:** A `requestAnimationFrame` loop or a throttled function (e.g., using `lodash.throttle`) checks the buffer every 16ms (60fps) or 100ms. If data exists, it triggers a single state update with the aggregated data.
3.  **Bypassing React:** For extreme frequency (e.g., live signal processing), the WebSocket handler can write directly to a Canvas element or a mutable ref, bypassing React state entirely to avoid the reconciliation overhead.

## 7. Offline Capability and Service Workers

In field operations, network connectivity is intermittent. A "**Service Worker**" acts as a programmable network proxy, sitting between the web application and the browser's network layer.

### 7.1 Caching Strategies

Service Workers intercept network requests and can serve responses from a local cache.
*   **Stale-While-Revalidate:** The app serves the cached version immediately (fastest LCP), while simultaneously fetching the latest version from the network to update the cache for next time. Ideal for non-critical resources like user avatars.
*   **Cache First:** Ideal for static assets (JS bundles, CSS, fonts). The worker looks in the cache; if found, it returns it. If not, it fetches from the network.
*   **Network First:** Ideal for critical operational data. The worker tries to fetch fresh data; if the network fails (offline), it falls back to the most recent cached version.

### 7.2 Background Sync and IndexedDB

For handling user actions while offline (e.g., submitting a report), standard caching is insufficient.
*   **IndexedDB:** A low-level API for client-side storage of significant amounts of structured data, including files/blobs. It allows the application to store the entire application state locally.
*   **Background Sync:** The Service Worker can register for a "sync" event. When connectivity returns, the browser wakes up the Service Worker (even if the tab is closed) to execute queued network requests, ensuring that offline edits are eventually consistent with the server.

## 8. System Design Scenarios: Decomposition and Architecture

The "Decomposition" interview tests the ability to synthesize these technologies into a coherent system.

**Scenario A: Real-Time Geospatial Asset Tracker**
*   **Problem:** Design a dashboard tracking 50,000 moving assets on a map in real-time.
*   **Analysis:**
    *   **Rendering:** 50k points exceeds SVG limits. Use WebGL (e.g., Mapbox GL JS or Deck.gl) for rendering. Use Quadtrees for spatial indexing to handle hover interactions (finding the point under the mouse) efficiently.
    *   **Data Transport:** Use WebSockets for streaming updates. Transmit Deltas (only changed fields) rather than full objects to save bandwidth. Use Protocol Buffers instead of JSON to reduce payload size.
    *   **State Management:** Use a Web Worker to parse incoming Protobuf messages and update a SharedArrayBuffer. The main thread reads from this buffer to update the WebGL layer, decoupling data processing from rendering.

**Scenario B: High-Density Log Analysis Tool**
*   **Problem:** A tool to search and visualize 10 million log lines in the browser.
*   **Analysis:**
    *   **Rendering:** You cannot render 1M DOM nodes. Use **Virtualization** (e.g., `react-window`) to render only the rows visible in the viewport.
    *   **Search/Filtering:** Performing a regex search on 1M strings on the main thread will freeze the UI. Offload the text search to a Web Worker. The worker returns the indices of matching lines to the main thread.
    *   **Visualization:** To show an error frequency histogram over the 1M lines, calculate the bins in the Web Worker and render the result using Canvas (or Plottable.js if the bin count is low).

## 9. Conclusion

The engineering challenges at Palantir require a shift in mindset from "building pages" to "building systems." The Frontend Engineer must be a polyglot, fluent not just in React and TypeScript, but in the lower-level mechanics of the browser.

Success relies on a hierarchy of competencies:
1.  **Correctness:** Leveraging TypeScript to enforce rigorous data contracts across the stack.
2.  **Performance:** Understanding the rendering pipeline to choose between SVG, Canvas, and WebGL, and utilizing Web Workers and SharedArrayBuffers to keep the main thread unblocked.
3.  **Resilience:** Designing Offline-First architectures using Service Workers and IndexedDB to ensure mission continuity.
4.  **Inclusivity:** deeply integrating Accessibility standards through Blueprint's specialized tooling to serve all users effectively.

By mastering these architectural patterns, engineers can construct interfaces that do not merely display data but empower users to derive intelligence from chaos.


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/test_result_schema.py
# ========================================================

import sys
import os
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.schemas.result import JobResult, Artifact
from scripts.ontology.manager import ObjectManager

def test_result_persistence():
    print("🧪 Testing JobResult Persistence...")
    
    # 1. Instantiate
    result = JobResult(
        job_id="test-job-001",
        status="SUCCESS",
        output_artifacts=[
            Artifact(path="/tmp/test.txt", description="Test Artifact")
        ],
        metrics={"latency": 50}
    )
    
    print(f"Object Created: {result}")
    
    # 2. Save via Manager
    manager = ObjectManager()
    manager.save(result)
    
    print("Saved to DB.")
    
    # 3. Retrieve
    # We need to query by ID. Result ID is auto-generated (UUIDv7)
    obj_id = result.id
    print(f"Retrieving ID: {obj_id}")
    
    retrieved = manager.get(JobResult, obj_id)
    
    if retrieved and retrieved.job_id == "test-job-001":
        print("✅ SUCCESS: Object retrieved and matches.")
    else:
        print(f"❌ FAILURE: Retrieved object is {retrieved}")

if __name__ == "__main__":
    test_result_persistence()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/e2e/test_full_integration.py
# ========================================================
"""
ODA V3.0 - Full Integration E2E Test
=====================================

"Trust, but Verify" - Validates the complete workflow:

    [LLM Output] 
         ↓
    [Plan Parser] → Pydantic Validation
         ↓
    [Kernel] → ActionRegistry Lookup
         ↓
    [GovernanceEngine] → Metadata Inspection
         ↓
    [ProposalRepository] → SQLite Persistence
         ↓
    [Admin Approval] → State Transition
         ↓
    [Kernel Executor] → Action Execution
         ↓
    [Verification] → DB State Check

Run with: pytest tests/e2e/test_full_integration.py -v --asyncio-mode=auto -s
"""

from __future__ import annotations

import asyncio
import json
import tempfile
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

# ODA Core Imports
from scripts.ontology.ontology_types import OntologyObject, utc_now
from scripts.ontology.objects.proposal import (
    Proposal,
    ProposalPriority,
    ProposalStatus,
    InvalidTransitionError,
)
from scripts.ontology.actions import (
    ActionContext,
    ActionRegistry,
    ActionResult,
    ActionType,
    EditOperation,
    EditType,
    RequiredField,
    AllowedValues,
    LogSideEffect,
    register_action,
    action_registry,
)
from scripts.ontology.storage.database import Database, initialize_database
from scripts.ontology.storage.proposal_repository import (
    ProposalRepository,
    ProposalNotFoundError,
)


# =============================================================================
# MOCK LLM CLIENT
# =============================================================================

class MockLLMClient:
    """
    Simulates LLM responses for testing.
    Returns structured Plan data matching the expected schema.
    """
    
    def __init__(self, responses: List[Dict[str, Any]] = None):
        self.responses = responses or []
        self.call_count = 0
        self.last_prompt = None
    
    async def generate(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate a mock LLM response."""
        self.last_prompt = prompt
        self.call_count += 1
        
        # Return pre-configured response or default
        if self.call_count <= len(self.responses):
            return self.responses[self.call_count - 1]
        
        # Default: Generate a deployment plan
        return {
            "objective": "Deploy checkout service to production",
            "jobs": [
                {
                    "job_id": "job-001",
                    "title": "Health Check",
                    "action_type": "check_health",
                    "params": {"service": "checkout"},
                    "priority": "high"
                },
                {
                    "job_id": "job-002", 
                    "title": "Deploy to Production",
                    "action_type": "deploy_service",
                    "params": {
                        "service_name": "checkout",
                        "version": "2.0.0",
                        "environment": "production"
                    },
                    "priority": "critical"
                }
            ]
        }


# =============================================================================
# MOCK ACTION DEFINITIONS (for isolated testing)
# =============================================================================

class MockActionRegistry:
    """Isolated action registry for testing."""
    
    def __init__(self):
        self._actions: Dict[str, type] = {}
    
    def register(self, action_cls: type) -> type:
        self._actions[action_cls.api_name] = action_cls
        return action_cls
    
    def get(self, api_name: str) -> Optional[type]:
        return self._actions.get(api_name)
    
    def list_actions(self) -> List[str]:
        return list(self._actions.keys())
    
    def get_hazardous_actions(self) -> List[str]:
        return [
            name for name, cls in self._actions.items()
            if getattr(cls, "requires_proposal", False)
        ]
    
    def get_metadata(self, api_name: str):
        # Mock metadata retrieval
        cls = self.get(api_name)
        if not cls: return None
        from scripts.ontology.actions import ActionMetadata
        return ActionMetadata(
            requires_proposal=getattr(cls, "requires_proposal", False),
            is_dangerous=getattr(cls, "is_dangerous", False),
            description=""
        )


# Test Actions
class CheckHealthAction(ActionType[OntologyObject]):
    """Safe action - executes immediately."""
    api_name = "check_health"
    object_type = OntologyObject
    requires_proposal = False
    
    submission_criteria = [RequiredField("service")]
    side_effects = [LogSideEffect()]
    
    async def apply_edits(self, params, context):
        return None, [EditOperation(
            edit_type=EditType.MODIFY,
            object_type="HealthCheck",
            object_id=f"health-{params['service']}",
            changes={"status": "healthy", "checked_at": utc_now().isoformat()}
        )]


class DeployServiceAction(ActionType[OntologyObject]):
    """Hazardous action - requires proposal approval."""
    api_name = "deploy_service"
    object_type = OntologyObject
    requires_proposal = True  # ⚠️ HAZARDOUS
    
    submission_criteria = [
        RequiredField("service_name"),
        RequiredField("version"),
        RequiredField("environment"),
        AllowedValues("environment", ["staging", "production"]),
    ]
    side_effects = [LogSideEffect()]
    
    async def apply_edits(self, params, context):
        return None, [EditOperation(
            edit_type=EditType.CREATE,
            object_type="Deployment",
            object_id=f"deploy-{params['service_name']}-{params['version']}",
            changes={
                "service": params["service_name"],
                "version": params["version"],
                "environment": params["environment"],
                "deployed_at": utc_now().isoformat(),
                "deployed_by": context.actor_id,
            }
        )]


# =============================================================================
# GOVERNANCE ENGINE
# =============================================================================

class GovernanceEngine:
    """
    Enforces governance policies based on action metadata.
    No hardcoded action names - purely metadata-driven.
    """
    
    def __init__(self, registry: MockActionRegistry):
        self.registry = registry
    
    def check_execution_policy(self, action_type: str) -> str:
        """
        Evaluate governance policy for an action.
        
        Returns:
            - "ALLOW_IMMEDIATE": Safe to execute immediately
            - "REQUIRE_PROPOSAL": Needs approval
            - "DENY": Unknown or forbidden action
        """
        meta = self.registry.get_metadata(action_type)
        if not meta:
            return "DENY"
        
        if meta.requires_proposal:
            return "REQUIRE_PROPOSAL"
        
        return "ALLOW_IMMEDIATE"


# =============================================================================
# INTEGRATION KERNEL
# =============================================================================

class IntegrationKernel:
    """
    The Generic Ontology-Driven Kernel.
    
    - Parses LLM output into structured jobs
    - Routes through GovernanceEngine
    - Creates Proposals for hazardous actions
    - Executes approved proposals
    """
    
    def __init__(
        self,
        llm: MockLLMClient,
        registry: MockActionRegistry,
        repo: ProposalRepository,
    ):
        self.llm = llm
        self.registry = registry
        self.governance = GovernanceEngine(registry)
        self.repo = repo
        self.execution_log: List[Dict[str, Any]] = []
    
    async def process_prompt(self, prompt: str) -> Dict[str, Any]:
        """
        Process a user prompt through the full pipeline.
        
        Returns:
            Summary of processing results
        """
        results = {
            "prompt": prompt,
            "jobs_processed": 0,
            "executed_immediately": [],
            "proposals_created": [],
            "denied": [],
        }
        
        # 1. Get plan from LLM
        plan = await self.llm.generate(prompt)
        
        # 2. Process each job
        for job in plan.get("jobs", []):
            action_type = job.get("action_type")
            parameters = job.get("params", {}) # fixed: was parameters in doc but params in mock
            
            # 3. Evaluate governance
            decision = self.governance.check_execution_policy(action_type)
            
            if decision == "ALLOW_IMMEDIATE":
                # Safe action - execute immediately
                result = await self._execute_action(action_type, parameters)
                results["executed_immediately"].append({
                    "action": action_type,
                    "result": result,
                })
                
            elif decision == "REQUIRE_PROPOSAL":
                # Hazardous action - create proposal
                proposal = await self._create_proposal(action_type, parameters)
                results["proposals_created"].append({
                    "action": action_type,
                    "proposal_id": proposal.id,
                    "status": proposal.status.value,
                })
                
            else:  # DENY
                results["denied"].append({
                    "action": action_type,
                    "reason": "Unknown action type",
                })
            
            results["jobs_processed"] += 1
        
        return results
    
    async def _execute_action(
        self,
        action_type: str,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Execute an action and return result."""
        action_cls = self.registry.get(action_type)
        action = action_cls()
        context = ActionContext(actor_id="kernel")
        
        result = await action.execute(parameters, context)
        
        self.execution_log.append({
            "action": action_type,
            "timestamp": utc_now().isoformat(),
            "success": result.success,
        })
        
        return result.to_dict()
    
    async def _create_proposal(
        self,
        action_type: str,
        parameters: Dict[str, Any]
    ) -> Proposal:
        """Create and persist a proposal for hazardous action."""
        proposal = Proposal(
            action_type=action_type,
            payload=parameters,
            priority=ProposalPriority.HIGH,
            created_by="kernel",
        )
        proposal.submit()
        await self.repo.save(proposal, actor_id="kernel")
        
        return proposal
    
    async def execute_approved_proposals(self) -> List[Dict[str, Any]]:
        """
        Find and execute all approved proposals.
        Called by the kernel's main loop.
        """
        executed = []
        
        # Use find_by_status
        approved = await self.repo.find_by_status(ProposalStatus.APPROVED)
        
        for proposal in approved:
            action_cls = self.registry.get(proposal.action_type)
            
            if action_cls is None:
                continue
            
            # Execute the action
            result = await self._execute_action(
                proposal.action_type,
                proposal.payload
            )
            
            # Mark proposal as executed
            await self.repo.execute(
                proposal.id,
                executor_id="kernel",
                result=result # fixed: result is already a dict from _execute_action
            )
            
            executed.append({
                "proposal_id": proposal.id,
                "action": proposal.action_type,
                "result": result,
            })
        
        return executed


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
async def test_db() -> Database:
    """Create a temporary test database."""
    with tempfile.TemporaryDirectory() as tmpdir:
        db_path = Path(tmpdir) / "test_integration.db"
        db = Database(db_path)
        await db.initialize()
        yield db


@pytest.fixture
async def repo(test_db: Database) -> ProposalRepository:
    """Create repository with test database."""
    return ProposalRepository(test_db)


@pytest.fixture
def test_registry() -> MockActionRegistry:
    """Create isolated test registry with actions."""
    registry = MockActionRegistry()
    registry.register(CheckHealthAction)
    registry.register(DeployServiceAction)
    return registry


@pytest.fixture
def mock_llm() -> MockLLMClient:
    """Create mock LLM client."""
    return MockLLMClient()


@pytest.fixture
async def kernel(
    mock_llm: MockLLMClient,
    test_registry: MockActionRegistry,
    repo: ProposalRepository,
) -> IntegrationKernel:
    """Create integration kernel with all dependencies."""
    return IntegrationKernel(mock_llm, test_registry, repo)


# =============================================================================
# E2E TEST SCENARIOS
# =============================================================================

class TestFullIntegrationWorkflow:
    """
    Full E2E integration tests validating the complete pipeline.
    """
    
    @pytest.mark.asyncio
    async def test_scenario_1_safe_action_executes_immediately(
        self,
        kernel: IntegrationKernel,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Safe action should execute without proposal.
        """
        # Configure LLM to return safe action
        mock_llm.responses = [{
            "objective": "Check service health",
            "jobs": [
                {
                    "job_id": "job-001",
                    "action_type": "check_health",
                    "params": {"service": "api-gateway"},
                }
            ]
        }]
        
        # Process
        result = await kernel.process_prompt("서비스 상태 확인해줘")
        
        # Verify
        assert result["jobs_processed"] == 1
        assert len(result["executed_immediately"]) == 1
        assert len(result["proposals_created"]) == 0
        assert result["executed_immediately"][0]["action"] == "check_health"
        assert result["executed_immediately"][0]["result"]["success"] is True
    
    @pytest.mark.asyncio
    async def test_scenario_2_hazardous_action_creates_proposal(
        self,
        kernel: IntegrationKernel,
        repo: ProposalRepository,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Hazardous action should create proposal.
        """
        # Configure LLM
        mock_llm.responses = [{
            "objective": "Deploy to production",
            "jobs": [
                {
                    "job_id": "job-001",
                    "action_type": "deploy_service",
                    "params": {
                        "service_name": "checkout",
                        "version": "2.0.0",
                        "environment": "production"
                    },
                }
            ]
        }]
        
        # Process
        result = await kernel.process_prompt("운영 배포해줘")
        
        # Verify kernel result
        assert result["jobs_processed"] == 1
        assert len(result["executed_immediately"]) == 0
        assert len(result["proposals_created"]) == 1
        
        proposal_info = result["proposals_created"][0]
        assert proposal_info["action"] == "deploy_service"
        assert proposal_info["status"] == "pending"
        
        # Verify DB persistence
        proposal_id = proposal_info["proposal_id"]
        saved_proposal = await repo.find_by_id(proposal_id)
        
        assert saved_proposal is not None
        assert saved_proposal.status == ProposalStatus.PENDING
        assert saved_proposal.action_type == "deploy_service"
        assert saved_proposal.payload["service_name"] == "checkout"
    
    @pytest.mark.asyncio
    async def test_scenario_3_unknown_action_denied(
        self,
        kernel: IntegrationKernel,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Unknown action should be denied.
        """
        mock_llm.responses = [{
            "objective": "Hack the system",
            "jobs": [
                {
                    "job_id": "job-001",
                    "action_type": "hack_system",
                    "params": {},
                }
            ]
        }]
        
        result = await kernel.process_prompt("시스템 해킹해줘")
        
        assert result["jobs_processed"] == 1
        assert len(result["executed_immediately"]) == 0
        assert len(result["proposals_created"]) == 0
        assert len(result["denied"]) == 1
        assert result["denied"][0]["action"] == "hack_system"
    
    @pytest.mark.asyncio
    async def test_scenario_4_full_governance_workflow(
        self,
        kernel: IntegrationKernel,
        repo: ProposalRepository,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Complete governance workflow.
        """
        # Step 1: Create proposal via kernel
        mock_llm.responses = [{
            "objective": "Deploy to production",
            "jobs": [
                {
                    "job_id": "job-001",
                    "action_type": "deploy_service",
                    "params": {
                        "service_name": "payment-service",
                        "version": "3.0.0",
                        "environment": "production"
                    },
                }
            ]
        }]
        
        result = await kernel.process_prompt("운영 배포해줘")
        proposal_id = result["proposals_created"][0]["proposal_id"]
        
        # Verify PENDING
        proposal = await repo.find_by_id(proposal_id)
        assert proposal.status == ProposalStatus.PENDING
        
        # Step 2: Admin approval
        await repo.approve(
            proposal_id,
            reviewer_id="admin-001",
            comment="Deployment approved after review"
        )
        
        # Verify APPROVED
        proposal = await repo.find_by_id(proposal_id)
        assert proposal.status == ProposalStatus.APPROVED
        assert proposal.reviewed_by == "admin-001"
        
        # Step 3: Kernel executes approved proposals
        executed = await kernel.execute_approved_proposals()
        
        # Verify execution
        assert len(executed) == 1
        assert executed[0]["proposal_id"] == proposal_id
        assert executed[0]["result"]["success"] is True
        
        # Step 4: Verify EXECUTED in DB
        proposal = await repo.find_by_id(proposal_id)
        assert proposal.status == ProposalStatus.EXECUTED
        assert proposal.executed_at is not None
        assert proposal.execution_result is not None
    
    @pytest.mark.asyncio
    async def test_scenario_5_mixed_actions_workflow(
        self,
        kernel: IntegrationKernel,
        repo: ProposalRepository,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Mix of safe, hazardous, and unknown actions.
        """
        mock_llm.responses = [{
            "objective": "Complex deployment",
            "jobs": [
                {
                    "job_id": "job-001",
                    "action_type": "check_health",
                    "params": {"service": "api"},
                },
                {
                    "job_id": "job-002",
                    "action_type": "deploy_service",
                    "params": {
                        "service_name": "api",
                        "version": "1.0.0",
                        "environment": "staging"
                    },
                },
                {
                    "job_id": "job-003",
                    "action_type": "unknown_action",
                    "params": {},
                },
                {
                    "job_id": "job-004",
                    "action_type": "check_health",
                    "params": {"service": "db"},
                },
            ]
        }]
        
        result = await kernel.process_prompt("복합 배포 작업")
        
        # Verify counts
        assert result["jobs_processed"] == 4
        assert len(result["executed_immediately"]) == 2  # Two check_health
        assert len(result["proposals_created"]) == 1     # One deploy_service
        assert len(result["denied"]) == 1                # One unknown
        
        # Verify specific results
        executed_actions = [e["action"] for e in result["executed_immediately"]]
        assert executed_actions.count("check_health") == 2
        
        assert result["proposals_created"][0]["action"] == "deploy_service"
        assert result["denied"][0]["action"] == "unknown_action"
    
    @pytest.mark.asyncio
    async def test_scenario_6_proposal_rejection_workflow(
        self,
        kernel: IntegrationKernel,
        repo: ProposalRepository,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Proposal gets rejected.
        """
        # Create proposal
        mock_llm.responses = [{
            "objective": "Risky deployment",
            "jobs": [
                {
                    "job_id": "job-001",
                    "action_type": "deploy_service",
                    "params": {
                        "service_name": "critical-service",
                        "version": "0.0.1-alpha",
                        "environment": "production"
                    },
                }
            ]
        }]
        
        result = await kernel.process_prompt("위험한 배포")
        proposal_id = result["proposals_created"][0]["proposal_id"]
        
        # Reject
        await repo.reject(
            proposal_id,
            reviewer_id="admin-001",
            reason="Version too unstable for production"
        )
        
        # Verify REJECTED
        proposal = await repo.find_by_id(proposal_id)
        assert proposal.status == ProposalStatus.REJECTED
        assert "unstable" in proposal.review_comment
        
        # Verify kernel doesn't execute rejected proposals
        executed = await kernel.execute_approved_proposals()
        assert len(executed) == 0
        
        # Verify terminal state - can't approve after rejection
        with pytest.raises(InvalidTransitionError):
            await repo.approve(proposal_id, "admin-002")
    
    @pytest.mark.asyncio
    async def test_scenario_7_audit_trail_verification(
        self,
        kernel: IntegrationKernel,
        repo: ProposalRepository,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Verify complete audit trail in database.
        """
        # Full workflow
        mock_llm.responses = [{
            "objective": "Audited deployment",
            "jobs": [
                {
                    "job_id": "job-001",
                    "action_type": "deploy_service",
                    "params": {
                        "service_name": "audit-service",
                        "version": "1.0.0",
                        "environment": "production"
                    },
                }
            ]
        }]
        
        # Create
        result = await kernel.process_prompt("배포 with audit")
        proposal_id = result["proposals_created"][0]["proposal_id"]
        
        # Approve
        await repo.approve(proposal_id, "admin-001", "Approved")
        
        # Execute
        await kernel.execute_approved_proposals()
        
        # Get history
        _, history = await repo.get_with_history(proposal_id)
        
        # Verify audit trail
        assert len(history) >= 3
        
        actions = [h.action for h in history]
        assert "created" in actions or "bulk_saved" in actions
        assert "approved" in actions
        assert "executed" in actions
        
        # Verify chronological order
        timestamps = [h.timestamp for h in history]
        assert timestamps == sorted(timestamps)
    
    @pytest.mark.asyncio
    async def test_scenario_8_concurrent_proposals(
        self,
        kernel: IntegrationKernel,
        repo: ProposalRepository,
        mock_llm: MockLLMClient,
    ):
        """
        Scenario: Multiple concurrent proposals.
        """
        # Create multiple proposals concurrently
        async def create_proposal(service_name: str):
            mock_client = MockLLMClient([{
                "objective": f"Deploy {service_name}",
                "jobs": [
                    {
                        "job_id": "job-001",
                        "action_type": "deploy_service",
                        "params": {
                            "service_name": service_name,
                            "version": "1.0.0",
                            "environment": "production"
                        },
                    }
                ]
            }])
            
            local_kernel = IntegrationKernel(mock_client, kernel.registry, repo)
            return await local_kernel.process_prompt(f"Deploy {service_name}")
        
        # Create 5 proposals concurrently
        results = await asyncio.gather(*[
            create_proposal(f"service-{i}") for i in range(5)
        ])
        
        # Verify all created
        assert all(len(r["proposals_created"]) == 1 for r in results)
        
        # Verify unique IDs
        proposal_ids = [r["proposals_created"][0]["proposal_id"] for r in results]
        assert len(set(proposal_ids)) == 5
        
        # Verify all pending
        pending = await repo.find_pending()
        assert len(pending) == 5


# =============================================================================
# EXECUTION LOG TESTS
# =============================================================================

class TestExecutionLogging:
    """Tests for kernel execution logging."""
    
    @pytest.mark.asyncio
    async def test_execution_log_populated(
        self,
        kernel: IntegrationKernel,
        mock_llm: MockLLMClient,
    ):
        """Verify execution log captures all executed actions."""
        mock_llm.responses = [{
            "jobs": [
                {"action_type": "check_health", "params": {"service": "a"}}, # params
                {"action_type": "check_health", "params": {"service": "b"}},
            ]
        }]
        
        await kernel.process_prompt("Check services")
        
        assert len(kernel.execution_log) == 2
        assert all(log["action"] == "check_health" for log in kernel.execution_log)
        assert all(log["success"] is True for log in kernel.execution_log)


# =============================================================================
# DATABASE INTEGRITY TESTS
# =============================================================================

class TestDatabaseIntegrity:
    """Tests for database consistency and integrity."""
    
    @pytest.mark.asyncio
    async def test_wal_mode_enabled(self, test_db: Database):
        """Verify WAL mode is active for concurrency."""
        row = await test_db.fetchone("PRAGMA journal_mode;")
        assert row[0] == "wal"
    
    @pytest.mark.asyncio
    async def test_proposal_version_increments(
        self,
        repo: ProposalRepository,
    ):
        """Verify optimistic locking works."""
        proposal = Proposal(
            action_type="test_action",
            created_by="test"
        )
        proposal.submit()
        
        await repo.save(proposal)
        v1 = (await repo.find_by_id(proposal.id)).version
        
        await repo.approve(proposal.id, "admin")
        v2 = (await repo.find_by_id(proposal.id)).version
        
        assert v2 > v1


if __name__ == "__main__":
    pytest.main([
        __file__,
        "-v",
        "--asyncio-mode=auto",
        "-s",
        "--tb=short",
    ])


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/e2e/test_monolith.py
# ========================================================

"""
Orion ODA V3 - Monolithic Integration Test
=========================================
Verifies that the API properly serves both JSON endpoints and Static HTML.
"""

import sys
import pytest
from fastapi.testclient import TestClient

# Ensure path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.api.main import app

client = TestClient(app)

def test_api_health():
    """Verify API endpoint returns JSON."""
    response = client.get("/api/v1/proposals")
    assert response.status_code == 200
    assert isinstance(response.json(), list)

def test_static_root():
    """Verify Root URL serves Index HTML."""
    response = client.get("/")
    assert response.status_code == 200
    assert "text/html" in response.headers["content-type"]
    assert "Orion ODA" in response.text

def test_spa_routing():
    """Verify Deep Link serves Index HTML (SPA Catch-All)."""
    response = client.get("/dashboard/settings/profile")
    assert response.status_code == 200
    assert "text/html" in response.headers["content-type"]
    assert "Orion ODA" in response.text
    
def test_api_not_found():
    """Verify API 404 is NOT swallowed by SPA Catch-All."""
    response = client.get("/api/v1/non_existent_resource")
    assert response.status_code == 404
    assert response.json()["code"] == "NOT_FOUND"

def test_security_headers():
    """Verify Middleware injection."""
    response = client.get("/")
    assert "Strict-Transport-Security" in response.headers
    assert "Content-Security-Policy" in response.headers


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/e2e/test_oda_v3_scenarios.py
# ========================================================
"""
ODA V3.0 End-to-End Test Scenarios
==================================

Tests the complete workflow of the Ontology-Driven Architecture:
1. Object Lifecycle (Create → Modify → Archive → Delete)
2. Action Execution (Validation → Commit → Side Effects)
3. Proposal Governance (Draft → Pending → Approve/Reject → Execute)
4. Router Intelligence (Local vs Relay routing decisions)
5. Concurrent Operations (Race condition handling)

Run with: pytest tests/e2e/test_oda_v3_scenarios.py -v --asyncio-mode=auto
"""

from __future__ import annotations

import asyncio
import json
import tempfile
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Dict, List
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

# Import ODA V3 modules
from scripts.ontology.ontology_types import (
    Cardinality,
    Link,
    ObjectStatus,
    OntologyObject,
    PropertyType,
    generate_object_id,
)
from scripts.ontology.objects.proposal import (
    InvalidTransitionError,
    Proposal,
    ProposalPriority,
    ProposalStatus,
    VALID_TRANSITIONS,
)
from scripts.ontology.actions import (
    ActionContext,
    ActionRegistry,
    ActionResult,
    ActionType,
    AllowedValues,
    CustomValidator,
    EditOperation,
    EditType,
    LogSideEffect,
    MaxLength,
    RequiredField,
    ValidationError,
    action_registry,
    register_action,
)
from scripts.llm.ollama_client import (
    HybridLLMService,
    HybridRouter,
    OllamaClient,
    OllamaResponse,
    RouterConfig,
    RoutingDecision,
    RouteTarget,
)


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
def system_context() -> ActionContext:
    """Create a system-level action context."""
    return ActionContext.system()


@pytest.fixture
def user_context() -> ActionContext:
    """Create a user action context."""
    return ActionContext(
        actor_id="user-001",
        correlation_id="test-correlation-123",
        metadata={"source": "pytest"}
    )


@pytest.fixture
def admin_context() -> ActionContext:
    """Create an admin action context."""
    return ActionContext(
        actor_id="admin-001",
        metadata={"role": "administrator"}
    )


@pytest.fixture
def router_config() -> RouterConfig:
    """Create a test router configuration."""
    return RouterConfig(
        word_threshold=30,
        sentence_threshold=3,
        critical_keywords=["delete", "deploy", "production", "database"],
        technical_terms=["api", "microservice"],
        ollama_base_url="http://localhost:11434",
        ollama_model="llama3.2",
        ollama_timeout=10.0,
        ollama_max_retries=1,
    )


@pytest.fixture
def temp_config_file(router_config: RouterConfig) -> Path:
    """Create a temporary config file."""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        f.write(router_config.model_dump_json())
        return Path(f.name)


# =============================================================================
# SCENARIO 1: ONTOLOGY OBJECT LIFECYCLE
# =============================================================================

class TestOntologyObjectLifecycle:
    """Test OntologyObject creation, modification, and deletion."""
    
    def test_object_creation_generates_uuid(self):
        """Verify that new objects get unique UUIDs."""
        obj1 = OntologyObject()
        obj2 = OntologyObject()
        
        assert obj1.id != obj2.id
        assert len(obj1.id) == 36  # UUID format
        assert obj1.version == 1
        assert obj1.status == ObjectStatus.ACTIVE
    
    def test_object_audit_fields_populated(self):
        """Verify audit fields are set on creation."""
        before = datetime.now(timezone.utc)
        obj = OntologyObject(created_by="agent-001")
        after = datetime.now(timezone.utc)
        
        assert obj.created_by == "agent-001"
        assert before <= obj.created_at <= after
        assert obj.updated_at == obj.created_at
    
    def test_touch_updates_version_and_timestamp(self):
        """Verify touch() increments version and updates timestamp."""
        obj = OntologyObject()
        original_version = obj.version
        original_updated_at = obj.updated_at
        
        # Small delay to ensure timestamp difference
        import time
        time.sleep(0.01)
        
        obj.touch(updated_by="modifier-001")
        
        assert obj.version == original_version + 1
        assert obj.updated_at > original_updated_at
        assert obj.updated_by == "modifier-001"
    
    def test_soft_delete_sets_status(self):
        """Verify soft_delete() changes status to DELETED."""
        obj = OntologyObject()
        assert obj.is_active
        
        obj.soft_delete(deleted_by="admin-001")
        
        assert obj.status == ObjectStatus.DELETED
        assert not obj.is_active
        assert obj.updated_by == "admin-001"
    
    def test_archive_sets_status(self):
        """Verify archive() changes status to ARCHIVED."""
        obj = OntologyObject()
        
        obj.archive(archived_by="system")
        
        assert obj.status == ObjectStatus.ARCHIVED
        assert not obj.is_active


# =============================================================================
# SCENARIO 2: LINK TYPE VALIDATION
# =============================================================================

class TestLinkTypeDefinition:
    """Test Link type definitions and cardinality."""
    
    def test_link_creation_with_cardinality(self):
        """Verify Link accepts valid cardinality values."""
        link = Link(
            target=OntologyObject,
            link_type_id="parent_child",
            cardinality=Cardinality.ONE_TO_MANY,
        )
        
        assert link.cardinality == Cardinality.ONE_TO_MANY
        assert link.link_type_id == "parent_child"
    
    def test_link_type_id_validation(self):
        """Verify link_type_id must be snake_case."""
        # Valid
        Link(target=OntologyObject, link_type_id="valid_link_id")
        
        # Invalid (contains space)
        with pytest.raises(ValueError, match="snake_case"):
            Link(target=OntologyObject, link_type_id="invalid link")
    
    def test_all_cardinality_values(self):
        """Verify all Cardinality enum values."""
        assert Cardinality.ONE_TO_ONE.value == "1:1"
        assert Cardinality.ONE_TO_MANY.value == "1:N"
        assert Cardinality.MANY_TO_MANY.value == "N:N"


# =============================================================================
# SCENARIO 3: PROPOSAL STATE MACHINE
# =============================================================================

class TestProposalStateMachine:
    """Test Proposal lifecycle and state transitions."""
    
    def test_proposal_creation_defaults_to_draft(self):
        """Verify new proposals start in DRAFT status."""
        proposal = Proposal(
            action_type="create_task",
            created_by="agent-001"
        )
        
        assert proposal.status == ProposalStatus.DRAFT
        assert not proposal.is_terminal
    
    def test_valid_transition_draft_to_pending(self):
        """Verify DRAFT → PENDING transition works."""
        proposal = Proposal(action_type="test", created_by="x")
        
        proposal.submit()
        
        assert proposal.status == ProposalStatus.PENDING
        assert proposal.is_pending_review
    
    def test_valid_transition_pending_to_approved(self):
        """Verify PENDING → APPROVED transition works."""
        proposal = Proposal(action_type="test", created_by="x")
        proposal.submit()
        
        proposal.approve(reviewer_id="admin-001", comment="LGTM")
        
        assert proposal.status == ProposalStatus.APPROVED
        assert proposal.reviewed_by == "admin-001"
        assert proposal.review_comment == "LGTM"
        assert proposal.reviewed_at is not None
        assert proposal.can_execute
    
    def test_valid_transition_pending_to_rejected(self):
        """Verify PENDING → REJECTED transition works."""
        proposal = Proposal(action_type="test", created_by="x")
        proposal.submit()
        
        proposal.reject(reviewer_id="admin-001", reason="Not ready")
        
        assert proposal.status == ProposalStatus.REJECTED
        assert proposal.is_terminal
    
    def test_valid_transition_approved_to_executed(self):
        """Verify APPROVED → EXECUTED transition works."""
        proposal = Proposal(action_type="test", created_by="x")
        proposal.submit()
        proposal.approve(reviewer_id="admin-001")
        
        proposal.execute(result={"success": True})
        
        assert proposal.status == ProposalStatus.EXECUTED
        assert proposal.is_terminal
        assert proposal.executed_at is not None
        assert proposal.execution_result == {"success": True}
    
    def test_invalid_transition_draft_to_approved(self):
        """Verify DRAFT → APPROVED is blocked."""
        proposal = Proposal(action_type="test", created_by="x")
        
        with pytest.raises(InvalidTransitionError) as exc_info:
            proposal.approve(reviewer_id="admin-001")
        
        assert "draft" in str(exc_info.value).lower()
        assert "approved" in str(exc_info.value).lower()
    
    def test_invalid_transition_rejected_to_approved(self):
        """Verify REJECTED → APPROVED is blocked (terminal state)."""
        proposal = Proposal(action_type="test", created_by="x")
        proposal.submit()
        proposal.reject(reviewer_id="admin-001", reason="No")
        
        with pytest.raises(InvalidTransitionError):
            proposal.approve(reviewer_id="admin-002")
    
    def test_cancel_from_multiple_states(self):
        """Verify cancellation works from non-terminal states."""
        # From DRAFT
        p1 = Proposal(action_type="test", created_by="x")
        p1.cancel(canceller_id="user-001", reason="Changed mind")
        assert p1.status == ProposalStatus.CANCELLED
        
        # From PENDING
        p2 = Proposal(action_type="test", created_by="x")
        p2.submit()
        p2.cancel(canceller_id="user-001")
        assert p2.status == ProposalStatus.CANCELLED
        
        # From APPROVED (before execution)
        p3 = Proposal(action_type="test", created_by="x")
        p3.submit()
        p3.approve(reviewer_id="admin-001")
        p3.cancel(canceller_id="user-001")
        assert p3.status == ProposalStatus.CANCELLED
    
    def test_approve_requires_reviewer_id(self):
        """Verify approve() requires reviewer_id."""
        proposal = Proposal(action_type="test", created_by="x")
        proposal.submit()
        
        with pytest.raises(ValueError, match="reviewer_id"):
            proposal.approve(reviewer_id="")
    
    def test_reject_requires_reason(self):
        """Verify reject() requires reason."""
        proposal = Proposal(action_type="test", created_by="x")
        proposal.submit()
        
        with pytest.raises(ValueError, match="reason"):
            proposal.reject(reviewer_id="admin-001", reason="")
    
    def test_audit_log_generation(self):
        """Verify audit log contains all relevant fields."""
        proposal = Proposal(
            action_type="deploy_service",
            payload={"service": "checkout"},
            created_by="agent-001",
            priority=ProposalPriority.HIGH,
        )
        proposal.submit()
        proposal.approve(reviewer_id="admin-001", comment="Approved")
        
        audit = proposal.to_audit_log()
        
        assert audit["proposal_id"] == proposal.id
        assert audit["action_type"] == "deploy_service"
        assert audit["status"] == "approved"
        assert audit["priority"] == "high"
        assert audit["reviewed_by"] == "admin-001"


# =============================================================================
# SCENARIO 4: SUBMISSION CRITERIA VALIDATION
# =============================================================================

class TestSubmissionCriteria:
    """Test ActionType submission criteria validators."""
    
    def test_required_field_passes(self, system_context):
        """Verify RequiredField passes for non-empty value."""
        validator = RequiredField("title")
        
        result = validator.validate({"title": "My Task"}, system_context)
        
        assert result is True
    
    def test_required_field_fails_empty(self, system_context):
        """Verify RequiredField fails for empty string."""
        validator = RequiredField("title")
        
        with pytest.raises(ValidationError) as exc_info:
            validator.validate({"title": ""}, system_context)
        
        assert "required" in str(exc_info.value).lower()
    
    def test_required_field_fails_missing(self, system_context):
        """Verify RequiredField fails for missing key."""
        validator = RequiredField("title")
        
        with pytest.raises(ValidationError):
            validator.validate({}, system_context)
    
    def test_allowed_values_passes(self, system_context):
        """Verify AllowedValues passes for valid value."""
        validator = AllowedValues("priority", ["low", "medium", "high"])
        
        result = validator.validate({"priority": "high"}, system_context)
        
        assert result is True
    
    def test_allowed_values_fails(self, system_context):
        """Verify AllowedValues fails for invalid value."""
        validator = AllowedValues("priority", ["low", "medium", "high"])
        
        with pytest.raises(ValidationError) as exc_info:
            validator.validate({"priority": "urgent"}, system_context)
        
        assert "allowed values" in str(exc_info.value).lower()
    
    def test_max_length_passes(self, system_context):
        """Verify MaxLength passes for short string."""
        validator = MaxLength("title", 100)
        
        result = validator.validate({"title": "Short title"}, system_context)
        
        assert result is True
    
    def test_max_length_fails(self, system_context):
        """Verify MaxLength fails for long string."""
        validator = MaxLength("title", 10)
        
        with pytest.raises(ValidationError) as exc_info:
            validator.validate({"title": "This is a very long title"}, system_context)
        
        assert "max length" in str(exc_info.value).lower()
    
    def test_custom_validator_passes(self, system_context):
        """Verify CustomValidator with passing function."""
        validator = CustomValidator(
            name="EvenNumber",
            validator_fn=lambda p, c: p.get("count", 0) % 2 == 0,
            error_message="Count must be even"
        )
        
        result = validator.validate({"count": 4}, system_context)
        
        assert result is True
    
    def test_custom_validator_fails(self, system_context):
        """Verify CustomValidator with failing function."""
        validator = CustomValidator(
            name="EvenNumber",
            validator_fn=lambda p, c: p.get("count", 0) % 2 == 0,
            error_message="Count must be even"
        )
        
        with pytest.raises(ValidationError) as exc_info:
            validator.validate({"count": 3}, system_context)
        
        assert "even" in str(exc_info.value).lower()


# =============================================================================
# SCENARIO 5: ACTION EXECUTION FLOW
# =============================================================================

class TestActionExecution:
    """Test ActionType execution with validation and side effects."""
    
    @pytest.fixture
    def mock_action_class(self):
        """Create a mock ActionType for testing."""
        
        class MockAction(ActionType[OntologyObject]):
            api_name = "mock_action"
            object_type = OntologyObject
            submission_criteria = [
                RequiredField("name"),
                MaxLength("name", 50),
            ]
            side_effects = [LogSideEffect()]
            
            async def apply_edits(self, params, context):
                obj = OntologyObject(created_by=context.actor_id)
                edit = EditOperation(
                    edit_type=EditType.CREATE,
                    object_type="OntologyObject",
                    object_id=obj.id,
                    changes=params,
                )
                return obj, [edit]
        
        return MockAction
    
    @pytest.mark.asyncio
    async def test_successful_execution(self, mock_action_class, user_context):
        """Verify successful action execution flow."""
        action = mock_action_class()
        
        result = await action.execute(
            params={"name": "Test Object"},
            context=user_context
        )
        
        assert result.success is True
        assert result.action_type == "mock_action"
        assert len(result.created_ids) == 1
        assert len(result.edits) == 1
        assert result.edits[0].edit_type == EditType.CREATE
    
    @pytest.mark.asyncio
    async def test_validation_failure(self, mock_action_class, user_context):
        """Verify action fails on validation error."""
        action = mock_action_class()
        
        result = await action.execute(
            params={"name": ""},  # Empty - will fail RequiredField
            context=user_context
        )
        
        assert result.success is False
        assert "criteria" in result.error.lower() or "validation" in result.error.lower()
        assert "validation_errors" in result.error_details
    
    @pytest.mark.asyncio
    async def test_side_effects_execute_after_commit(self, mock_action_class, user_context):
        """Verify side effects run after successful commit."""
        action = mock_action_class()
        
        with patch.object(LogSideEffect, 'execute', new_callable=AsyncMock) as mock_effect:
            result = await action.execute(
                params={"name": "Test"},
                context=user_context
            )
            
            assert result.success is True
            mock_effect.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_side_effects_not_run_on_failure(self, mock_action_class, user_context):
        """Verify side effects don't run on validation failure."""
        action = mock_action_class()
        
        with patch.object(LogSideEffect, 'execute', new_callable=AsyncMock) as mock_effect:
            result = await action.execute(
                params={"name": ""},  # Will fail
                context=user_context
            )
            
            assert result.success is False
            mock_effect.assert_not_called()


# =============================================================================
# SCENARIO 6: ACTION REGISTRY
# =============================================================================

class TestActionRegistry:
    """Test ActionRegistry registration and lookup."""
    
    def test_register_and_get(self):
        """Verify action registration and retrieval."""
        registry = ActionRegistry()
        
        class TestAction(ActionType[OntologyObject]):
            api_name = "test_action"
            object_type = OntologyObject
            
            async def apply_edits(self, params, context):
                return None, []
        
        registry.register(TestAction)
        
        retrieved = registry.get("test_action")
        assert retrieved is TestAction
    
    def test_list_actions(self):
        """Verify listing registered actions."""
        registry = ActionRegistry()
        
        class Action1(ActionType[OntologyObject]):
            api_name = "action_1"
            object_type = OntologyObject
            async def apply_edits(self, params, context): return None, []
        
        class Action2(ActionType[OntologyObject]):
            api_name = "action_2"
            object_type = OntologyObject
            async def apply_edits(self, params, context): return None, []
        
        registry.register(Action1)
        registry.register(Action2)
        
        actions = registry.list_actions()
        assert "action_1" in actions
        assert "action_2" in actions
    
    def test_get_hazardous_actions(self):
        """Verify filtering hazardous actions."""
        registry = ActionRegistry()
        
        class SafeAction(ActionType[OntologyObject]):
            api_name = "safe_action"
            object_type = OntologyObject
            requires_proposal = False
            async def apply_edits(self, params, context): return None, []
        
        class HazardousAction(ActionType[OntologyObject]):
            api_name = "hazardous_action"
            object_type = OntologyObject
            requires_proposal = True
            async def apply_edits(self, params, context): return None, []
        
        registry.register(SafeAction)
        registry.register(HazardousAction)
        
        hazardous = registry.get_hazardous_actions()
        assert "hazardous_action" in hazardous
        assert "safe_action" not in hazardous


# =============================================================================
# SCENARIO 7: HYBRID ROUTER INTELLIGENCE
# =============================================================================

class TestHybridRouter:
    """Test HybridRouter routing decisions."""
    
    def test_simple_query_routes_local(self, router_config):
        """Verify simple queries route to LOCAL."""
        router = HybridRouter(router_config)
        
        decision = router.route("What is 2 + 2?")
        
        assert decision.target == RouteTarget.LOCAL
        assert decision.complexity_score < router_config.word_threshold
    
    def test_critical_keyword_routes_relay(self, router_config):
        """Verify critical keywords trigger RELAY routing."""
        router = HybridRouter(router_config)
        
        decision = router.route("Delete all user data")
        
        assert decision.target == RouteTarget.RELAY
        assert "delete" in decision.triggered_keywords
    
    def test_complex_query_routes_relay(self, router_config):
        """Verify complex queries route to RELAY."""
        router = HybridRouter(router_config)
        
        # Generate a long, complex query
        complex_query = " ".join(["word"] * 100)
        decision = router.route(complex_query)
        
        assert decision.target == RouteTarget.RELAY
        assert "complexity" in decision.reason.lower()
    
    def test_explicit_local_marker(self, router_config):
        """Verify [LOCAL] marker forces local routing."""
        router = HybridRouter(router_config)
        
        # Even with critical keyword, LOCAL marker overrides
        decision = router.route("[LOCAL] Deploy to production")
        
        assert decision.target == RouteTarget.LOCAL
        assert "explicit" in decision.reason.lower()
    
    def test_explicit_relay_marker(self, router_config):
        """Verify [RELAY] marker forces relay routing."""
        router = HybridRouter(router_config)
        
        decision = router.route("[RELAY] Simple question")
        
        assert decision.target == RouteTarget.RELAY
        assert "explicit" in decision.reason.lower()
    
    def test_technical_terms_increase_complexity(self, router_config):
        """Verify technical terms increase complexity score."""
        router = HybridRouter(router_config)
        
        # Without technical terms
        d1 = router.route("Set up the system")
        
        # With technical terms
        d2 = router.route("Set up the api microservice")
        
        assert d2.complexity_score > d1.complexity_score
    
    def test_routing_decision_contains_metrics(self, router_config):
        """Verify RoutingDecision includes metrics."""
        router = HybridRouter(router_config)
        
        decision = router.route("Create a task for the team")
        
        assert "word_count" in decision.metrics
        assert "sentence_count" in decision.metrics
        assert "threshold" in decision.metrics


# =============================================================================
# SCENARIO 8: ROUTER CONFIGURATION
# =============================================================================

class TestRouterConfiguration:
    """Test RouterConfig loading and validation."""
    
    def test_default_config(self):
        """Verify default configuration values."""
        config = RouterConfig()
        
        assert config.word_threshold == 50
        assert config.sentence_threshold == 5
        assert "delete" in config.critical_keywords
        assert config.ollama_model == "llama3.2"
    
    def test_config_from_json_file(self, temp_config_file):
        """Verify loading config from JSON file."""
        config = RouterConfig.from_file(temp_config_file)
        
        assert config.word_threshold == 30  # From fixture
    
    def test_config_validation(self):
        """Verify config validation constraints."""
        # Valid
        RouterConfig(word_threshold=100)
        
        # Invalid (below minimum)
        with pytest.raises(ValueError):
            RouterConfig(word_threshold=5)
    
    def test_config_to_file(self, router_config):
        """Verify saving config to file."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            path = Path(f.name)
        
        router_config.to_file(path)
        
        loaded = RouterConfig.from_file(path)
        assert loaded.word_threshold == router_config.word_threshold


# =============================================================================
# SCENARIO 9: OLLAMA CLIENT
# =============================================================================

class TestOllamaClient:
    """Test OllamaClient functionality."""
    
    @pytest.mark.asyncio
    async def test_health_check_mocked(self, router_config):
        """Verify health check with mocked response."""
        client = OllamaClient(router_config)
        
        with patch('httpx.AsyncClient.get', new_callable=AsyncMock) as mock_get:
            mock_get.return_value = MagicMock(status_code=200)
            
            result = await client.health_check()
            
            assert result is True
        
        await client.close()
    
    @pytest.mark.asyncio
    async def test_generate_mocked(self, router_config):
        """Verify generate with mocked response."""
        client = OllamaClient(router_config)
        
        mock_response = MagicMock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "response": "The answer is 4",
            "model": "llama3.2",
            "done": True,
            "total_duration": 1000000000,
        }
        mock_response.raise_for_status = MagicMock()
        
        with patch('httpx.AsyncClient.post', new_callable=AsyncMock) as mock_post:
            mock_post.return_value = mock_response
            
            response = await client.generate("What is 2 + 2?")
            
            assert response.content == "The answer is 4"
            assert response.model == "llama3.2"
            assert response.duration_seconds == 1.0
        
        await client.close()


# =============================================================================
# SCENARIO 10: CONCURRENT OPERATIONS
# =============================================================================

class TestConcurrentOperations:
    """Test thread safety and concurrent access."""
    
    @pytest.mark.asyncio
    async def test_concurrent_proposal_submissions(self):
        """Verify multiple proposals can be submitted concurrently."""
        proposals = [
            Proposal(action_type=f"action_{i}", created_by=f"agent-{i}")
            for i in range(10)
        ]
        
        async def submit_proposal(p: Proposal):
            await asyncio.sleep(0.01)  # Simulate async work
            p.submit()
            return p
        
        results = await asyncio.gather(*[submit_proposal(p) for p in proposals])
        
        assert all(p.status == ProposalStatus.PENDING for p in results)
        assert len(set(p.id for p in results)) == 10  # All unique IDs
    
    @pytest.mark.asyncio
    async def test_concurrent_object_creation(self):
        """Verify concurrent object creation generates unique IDs."""
        async def create_object():
            await asyncio.sleep(0.001)
            return OntologyObject()
        
        objects = await asyncio.gather(*[create_object() for _ in range(100)])
        
        ids = [obj.id for obj in objects]
        assert len(set(ids)) == 100  # All unique


# =============================================================================
# SCENARIO 11: INTEGRATION TEST
# =============================================================================

class TestFullIntegration:
    """Full integration test of the ODA workflow."""
    
    @pytest.mark.asyncio
    async def test_full_governance_workflow(self, user_context, admin_context):
        """Test complete proposal governance workflow."""
        # 1. Create a hazardous action proposal
        proposal = Proposal(
            action_type="deploy_to_production",
            payload={"service": "checkout", "version": "2.0.0"},
            created_by=user_context.actor_id,
            priority=ProposalPriority.HIGH,
        )
        
        # 2. Submit for review
        proposal.submit(submitter_id=user_context.actor_id)
        assert proposal.is_pending_review
        
        # 3. Admin reviews and approves
        proposal.approve(
            reviewer_id=admin_context.actor_id,
            comment="Verified deployment plan"
        )
        assert proposal.can_execute
        
        # 4. Execute the action
        proposal.execute(
            executor_id="system",
            result={"deployment_id": "deploy-123", "status": "success"}
        )
        
        # 5. Verify final state
        assert proposal.is_terminal
        assert proposal.status == ProposalStatus.EXECUTED
        assert proposal.execution_result["status"] == "success"
        
        # 6. Verify audit trail
        audit = proposal.to_audit_log()
        assert audit["reviewed_by"] == admin_context.actor_id
        assert audit["status"] == "executed"


# =============================================================================
# RUN TESTS
# =============================================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v", "--asyncio-mode=auto"])


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/e2e/test_proposal_repository.py
# ========================================================
"""
ODA V3.0 - ProposalRepository Test Suite
========================================

Tests for Proposal persistence layer:
1. CRUD operations
2. Optimistic locking
3. History tracking
4. Query filtering
5. Bulk operations
6. Governance helpers (approve/reject/execute)

Run with: pytest tests/e2e/test_proposal_repository.py -v --asyncio-mode=auto
"""

from __future__ import annotations

import asyncio
import tempfile
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import AsyncGenerator

import pytest

from scripts.ontology.objects.proposal import (
    InvalidTransitionError,
    Proposal,
    ProposalPriority,
    ProposalStatus,
)
from scripts.ontology.storage.database import Database, initialize_database
from scripts.ontology.storage.proposal_repository import (
    OptimisticLockError,
    PaginatedResult,
    ProposalNotFoundError,
    ProposalQuery,
    ProposalRepository,
)


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
async def db() -> AsyncGenerator[Database, None]:
    """Create a temporary database for testing."""
    with tempfile.TemporaryDirectory() as tmpdir:
        db_path = Path(tmpdir) / "test_ontology.db"
        database = Database(db_path)
        await database.initialize()
        yield database


@pytest.fixture
async def repo(db: Database) -> ProposalRepository:
    """Create a repository with the test database."""
    return ProposalRepository(db)


@pytest.fixture
def sample_proposal() -> Proposal:
    """Create a sample proposal."""
    return Proposal(
        action_type="deploy_service",
        payload={"service": "checkout", "version": "2.0.0"},
        created_by="agent-001",
        priority=ProposalPriority.HIGH,
    )


@pytest.fixture
def submitted_proposal() -> Proposal:
    """Create a submitted proposal."""
    proposal = Proposal(
        action_type="delete_task",
        payload={"task_id": "task-123"},
        created_by="agent-002",
    )
    proposal.submit()
    return proposal


# =============================================================================
# CRUD TESTS
# =============================================================================

class TestProposalCRUD:
    """Test basic CRUD operations."""
    
    @pytest.mark.asyncio
    async def test_save_and_find_by_id(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test saving and retrieving a proposal."""
        await repo.save(sample_proposal)
        
        found = await repo.find_by_id(sample_proposal.id)
        
        assert found is not None
        assert found.id == sample_proposal.id
        assert found.action_type == "deploy_service"
        assert found.payload["service"] == "checkout"
        assert found.created_by == "agent-001"
        assert found.priority == ProposalPriority.HIGH
    
    @pytest.mark.asyncio
    async def test_find_by_id_not_found(self, repo: ProposalRepository):
        """Test finding non-existent proposal."""
        found = await repo.find_by_id("non-existent-id")
        
        assert found is None
    
    @pytest.mark.asyncio
    async def test_update_proposal(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test updating an existing proposal."""
        await repo.save(sample_proposal)
        
        # Modify and save again
        sample_proposal.submit()
        await repo.save(sample_proposal)
        
        found = await repo.find_by_id(sample_proposal.id)
        
        assert found.status == ProposalStatus.PENDING
        assert found.version == 2  # Version incremented
    
    @pytest.mark.asyncio
    async def test_soft_delete(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test soft deleting a proposal."""
        await repo.save(sample_proposal)
        
        result = await repo.delete(sample_proposal.id, actor_id="admin-001")
        
        assert result is True
        
        # Should still exist but be marked deleted
        found = await repo.find_by_id(sample_proposal.id)
        # Note: soft delete updates the proposal's status
    
    @pytest.mark.asyncio
    async def test_hard_delete(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test hard deleting a proposal."""
        await repo.save(sample_proposal)
        
        result = await repo.delete(sample_proposal.id, actor_id="admin-001", hard_delete=True)
        
        assert result is True
        
        # Should not exist
        found = await repo.find_by_id(sample_proposal.id)
        assert found is None
    
    @pytest.mark.asyncio
    async def test_delete_not_found(self, repo: ProposalRepository):
        """Test deleting non-existent proposal."""
        result = await repo.delete("non-existent", actor_id="admin-001")
        
        assert result is False


# =============================================================================
# OPTIMISTIC LOCKING TESTS
# =============================================================================

class TestOptimisticLocking:
    """Test optimistic locking for concurrent access."""
    
    @pytest.mark.asyncio
    async def test_version_increment(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test that version increments on each save."""
        assert sample_proposal.version == 1
        
        await repo.save(sample_proposal)
        found = await repo.find_by_id(sample_proposal.id)
        assert found.version == 1
        
        found.submit()
        await repo.save(found)
        
        found2 = await repo.find_by_id(sample_proposal.id)
        assert found2.version == 2
    
    @pytest.mark.asyncio
    async def test_concurrent_modification_detected(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test that concurrent modifications are detected."""
        await repo.save(sample_proposal)
        
        # Simulate two concurrent reads
        instance1 = await repo.find_by_id(sample_proposal.id)
        instance2 = await repo.find_by_id(sample_proposal.id)
        
        # First update succeeds
        instance1.submit()
        await repo.save(instance1)
        
        # Second update should fail (version mismatch)
        instance2.submit()
        
        with pytest.raises(OptimisticLockError) as exc_info:
            await repo.save(instance2)
        
        assert exc_info.value.expected_version == 2
        assert exc_info.value.actual_version == 2


# =============================================================================
# QUERY TESTS
# =============================================================================

class TestProposalQueries:
    """Test query operations."""
    
    @pytest.mark.asyncio
    async def test_find_by_status(self, repo: ProposalRepository):
        """Test finding proposals by status."""
        # Create proposals in different statuses
        draft = Proposal(action_type="action1", created_by="agent-001")
        pending = Proposal(action_type="action2", created_by="agent-001")
        pending.submit()
        
        await repo.save(draft)
        await repo.save(pending)
        
        # Query by status
        draft_results = await repo.find_by_status(ProposalStatus.DRAFT)
        pending_results = await repo.find_by_status(ProposalStatus.PENDING)
        
        assert len(draft_results) == 1
        assert draft_results[0].action_type == "action1"
        
        assert len(pending_results) == 1
        assert pending_results[0].action_type == "action2"
    
    @pytest.mark.asyncio
    async def test_find_pending_shortcut(self, repo: ProposalRepository, submitted_proposal: Proposal):
        """Test find_pending convenience method."""
        await repo.save(submitted_proposal)
        
        pending = await repo.find_pending()
        
        assert len(pending) == 1
        assert pending[0].id == submitted_proposal.id
    
    @pytest.mark.asyncio
    async def test_find_by_action_type(self, repo: ProposalRepository):
        """Test finding proposals by action type."""
        p1 = Proposal(action_type="deploy_service", created_by="agent-001")
        p2 = Proposal(action_type="deploy_service", created_by="agent-002")
        p3 = Proposal(action_type="delete_task", created_by="agent-001")
        
        await repo.save(p1)
        await repo.save(p2)
        await repo.save(p3)
        
        deploy_results = await repo.find_by_action_type("deploy_service")
        
        assert len(deploy_results) == 2
    
    @pytest.mark.asyncio
    async def test_find_by_creator(self, repo: ProposalRepository):
        """Test finding proposals by creator."""
        p1 = Proposal(action_type="action1", created_by="agent-001")
        p2 = Proposal(action_type="action2", created_by="agent-001")
        p3 = Proposal(action_type="action3", created_by="agent-002")
        
        await repo.save(p1)
        await repo.save(p2)
        await repo.save(p3)
        
        agent1_results = await repo.find_by_creator("agent-001")
        
        assert len(agent1_results) == 2
    
    @pytest.mark.asyncio
    async def test_paginated_query(self, repo: ProposalRepository):
        """Test paginated query with filters."""
        # Create 15 proposals
        for i in range(15):
            p = Proposal(action_type=f"action_{i}", created_by="agent-001")
            if i % 2 == 0:
                p.submit()
            await repo.save(p)
        
        # Query with pagination
        query = ProposalQuery(
            created_by="agent-001",
            limit=5,
            offset=0,
        )
        
        result = await repo.query(query)
        
        assert isinstance(result, PaginatedResult)
        assert len(result.items) == 5
        assert result.total == 15
        assert result.has_more is True
        
        # Next page
        query.offset = 5
        result2 = await repo.query(query)
        
        assert len(result2.items) == 5
        assert result2.offset == 5
    
    @pytest.mark.asyncio
    async def test_query_with_status_filter(self, repo: ProposalRepository):
        """Test query with status filter."""
        for i in range(10):
            p = Proposal(action_type=f"action_{i}", created_by="agent-001")
            if i < 5:
                p.submit()
            await repo.save(p)
        
        query = ProposalQuery(status=ProposalStatus.PENDING)
        result = await repo.query(query)
        
        assert result.total == 5
        assert all(p.status == ProposalStatus.PENDING for p in result.items)
    
    @pytest.mark.asyncio
    async def test_count_by_status(self, repo: ProposalRepository):
        """Test counting proposals by status."""
        for i in range(10):
            p = Proposal(action_type=f"action_{i}", created_by="agent-001")
            if i < 3:
                pass  # DRAFT
            elif i < 7:
                p.submit()  # PENDING
            else:
                p.submit()
                p.approve(reviewer_id="admin-001")  # APPROVED
            await repo.save(p)
        
        counts = await repo.count_by_status()
        
        assert counts.get("draft", 0) == 3
        assert counts.get("pending", 0) == 4
        assert counts.get("approved", 0) == 3


# =============================================================================
# HISTORY TESTS
# =============================================================================

class TestProposalHistory:
    """Test history tracking."""
    
    @pytest.mark.asyncio
    async def test_history_on_create(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test history entry created on insert."""
        await repo.save(sample_proposal, actor_id="agent-001")
        
        history = await repo.get_history(sample_proposal.id)
        
        assert len(history) == 1
        assert history[0].action == "created"
        assert history[0].actor_id == "agent-001"
    
    @pytest.mark.asyncio
    async def test_history_on_update(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test history entries for updates."""
        await repo.save(sample_proposal)
        
        sample_proposal.submit()
        await repo.save(sample_proposal, comment="Submitting for review")
        
        history = await repo.get_history(sample_proposal.id)
        
        assert len(history) == 2
        assert history[1].action == "updated"
        assert history[1].comment == "Submitting for review"
    
    @pytest.mark.asyncio
    async def test_get_with_history(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test retrieving proposal with history."""
        await repo.save(sample_proposal)
        sample_proposal.submit()
        await repo.save(sample_proposal)
        
        proposal, history = await repo.get_with_history(sample_proposal.id)
        
        assert proposal is not None
        assert proposal.id == sample_proposal.id
        assert len(history) == 2
    
    @pytest.mark.asyncio
    async def test_history_tracks_status_transitions(self, repo: ProposalRepository, submitted_proposal: Proposal):
        """Test that history tracks status changes."""
        await repo.save(submitted_proposal)
        
        # Approve
        await repo.approve(submitted_proposal.id, "admin-001", "Looks good")
        
        # Execute
        await repo.execute(submitted_proposal.id, executor_id="system", result={"success": True})
        
        history = await repo.get_history(submitted_proposal.id)
        
        # Should have: created, approved, executed
        assert len(history) == 3
        
        assert history[1].action == "approved"
        assert history[1].previous_status == "pending"
        assert history[1].new_status == "approved"
        
        assert history[2].action == "executed"
        assert history[2].previous_status == "approved"
        assert history[2].new_status == "executed"


# =============================================================================
# GOVERNANCE HELPER TESTS
# =============================================================================

class TestGovernanceHelpers:
    """Test governance convenience methods."""
    
    @pytest.mark.asyncio
    async def test_approve_pending_proposal(self, repo: ProposalRepository, submitted_proposal: Proposal):
        """Test approving a pending proposal."""
        await repo.save(submitted_proposal)
        
        approved = await repo.approve(
            submitted_proposal.id,
            reviewer_id="admin-001",
            comment="Approved for deployment"
        )
        
        assert approved.status == ProposalStatus.APPROVED
        assert approved.reviewed_by == "admin-001"
        assert approved.review_comment == "Approved for deployment"
    
    @pytest.mark.asyncio
    async def test_approve_not_found(self, repo: ProposalRepository):
        """Test approving non-existent proposal."""
        with pytest.raises(ProposalNotFoundError):
            await repo.approve("non-existent", "admin-001")
    
    @pytest.mark.asyncio
    async def test_approve_wrong_status(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test approving proposal not in PENDING status."""
        await repo.save(sample_proposal)  # Still in DRAFT
        
        with pytest.raises(InvalidTransitionError):
            await repo.approve(sample_proposal.id, "admin-001")
    
    @pytest.mark.asyncio
    async def test_reject_pending_proposal(self, repo: ProposalRepository, submitted_proposal: Proposal):
        """Test rejecting a pending proposal."""
        await repo.save(submitted_proposal)
        
        rejected = await repo.reject(
            submitted_proposal.id,
            reviewer_id="admin-001",
            reason="Not ready for production"
        )
        
        assert rejected.status == ProposalStatus.REJECTED
        assert rejected.reviewed_by == "admin-001"
        assert rejected.review_comment == "Not ready for production"
    
    @pytest.mark.asyncio
    async def test_execute_approved_proposal(self, repo: ProposalRepository, submitted_proposal: Proposal):
        """Test executing an approved proposal."""
        await repo.save(submitted_proposal)
        await repo.approve(submitted_proposal.id, "admin-001")
        
        executed = await repo.execute(
            submitted_proposal.id,
            executor_id="system",
            result={"deployment_id": "deploy-123", "status": "success"}
        )
        
        assert executed.status == ProposalStatus.EXECUTED
        assert executed.execution_result["deployment_id"] == "deploy-123"
    
    @pytest.mark.asyncio
    async def test_full_governance_workflow(self, repo: ProposalRepository):
        """Test complete governance workflow."""
        # 1. Create
        proposal = Proposal(
            action_type="deploy_service",
            payload={"service": "api-gateway", "version": "3.0.0"},
            created_by="agent-001",
            priority=ProposalPriority.CRITICAL,
        )
        
        # 2. Submit
        proposal.submit()
        await repo.save(proposal)
        
        # 3. Query pending
        pending = await repo.find_pending()
        assert len(pending) == 1
        
        # 4. Approve
        await repo.approve(proposal.id, "admin-001", "Approved after review")
        
        # 5. Execute
        await repo.execute(proposal.id, "system", result={"success": True})
        
        # 6. Verify final state
        final, history = await repo.get_with_history(proposal.id)
        
        assert final.status == ProposalStatus.EXECUTED
        assert len(history) == 3  # created, approved, executed


# =============================================================================
# BULK OPERATIONS TESTS
# =============================================================================

class TestBulkOperations:
    """Test bulk operations."""
    
    @pytest.mark.asyncio
    async def test_save_many(self, repo: ProposalRepository):
        """Test saving multiple proposals in one transaction."""
        proposals = [
            Proposal(action_type=f"action_{i}", created_by="agent-001")
            for i in range(10)
        ]
        
        saved = await repo.save_many(proposals, actor_id="batch-processor")
        
        assert len(saved) == 10
        
        # Verify all saved
        for p in proposals:
            found = await repo.find_by_id(p.id)
            assert found is not None


# =============================================================================
# DATABASE TESTS
# =============================================================================

class TestDatabase:
    """Test database functionality."""
    
    @pytest.mark.asyncio
    async def test_wal_mode_enabled(self, db: Database):
        """Test that WAL mode is enabled."""
        row = await db.fetchone("PRAGMA journal_mode;")
        assert row[0] == "wal"
    
    @pytest.mark.asyncio
    async def test_migrations_applied(self, db: Database):
        """Test that migrations are tracked."""
        rows = await db.fetchall("SELECT name FROM _migrations ORDER BY id")
        migration_names = [row["name"] for row in rows]
        
        assert "001_create_proposals" in migration_names
        assert "002_create_proposal_history" in migration_names
        assert "003_create_edit_operations" in migration_names
    
    @pytest.mark.asyncio
    async def test_health_check(self, db: Database):
        """Test database health check."""
        healthy = await db.health_check()
        assert healthy is True
    
    @pytest.mark.asyncio
    async def test_transaction_rollback_on_error(self, db: Database):
        """Test that transactions rollback on error."""
        try:
            async with db.transaction() as conn:
                await conn.execute(
                    "INSERT INTO proposals (id, action_type, payload, created_at, updated_at) "
                    "VALUES ('test-id', 'test', '{}', datetime('now'), datetime('now'))"
                )
                raise ValueError("Simulated error")
        except ValueError:
            pass
        
        # Should not exist due to rollback
        row = await db.fetchone("SELECT * FROM proposals WHERE id = 'test-id'")
        assert row is None


# =============================================================================
# CONCURRENT ACCESS TESTS
# =============================================================================

class TestConcurrentAccess:
    """Test concurrent database access."""
    
    @pytest.mark.asyncio
    async def test_concurrent_reads(self, repo: ProposalRepository, sample_proposal: Proposal):
        """Test concurrent read operations."""
        await repo.save(sample_proposal)
        
        async def read_proposal():
            return await repo.find_by_id(sample_proposal.id)
        
        # Execute 10 concurrent reads
        results = await asyncio.gather(*[read_proposal() for _ in range(10)])
        
        assert all(r is not None for r in results)
        assert all(r.id == sample_proposal.id for r in results)
    
    @pytest.mark.asyncio
    async def test_concurrent_writes_different_proposals(self, repo: ProposalRepository):
        """Test concurrent writes to different proposals."""
        proposals = [
            Proposal(action_type=f"action_{i}", created_by="agent-001")
            for i in range(10)
        ]
        
        async def save_proposal(p: Proposal):
            await repo.save(p)
            return p.id
        
        # Execute 10 concurrent writes
        ids = await asyncio.gather(*[save_proposal(p) for p in proposals])
        
        assert len(set(ids)) == 10  # All unique IDs


# =============================================================================
# RUN TESTS
# =============================================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v", "--asyncio-mode=auto"])


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/e2e/test_v3_full_stack.py
# ========================================================

import unittest
import sys
import os

# Add project root to path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.client import FoundryClient
from scripts.ontology.objects.core_definitions import Task, Agent
from scripts.llm.ollama_client import HybridRouter, OllamaClient
from scripts.relay.queue import RelayQueue

class TestV3Migration(unittest.TestCase):
    
    def test_foundation_ontology(self):
        """Phase 1: Validate FoundryClient and Object Registry"""
        client = FoundryClient()
        
        # Register Types
        client.ontology.objects.register(Task)
        client.ontology.objects.register(Agent)
        
        # Test Object Creation via OSDK pattern
        my_task = client.ontology.objects.Task.create(title="Refactor Orion", priority="high")
        self.assertEqual(my_task.title, "Refactor Orion")
        self.assertEqual(my_task.priority, "high")
        self.assertTrue(hasattr(my_task, 'id'))
        
        print("\n[Pass] Foundation Layer (OSDK Pattern) Verified")

    def test_hybrid_intelligence(self):
        """Phase 2: Validate Router and Mock LLM"""
        router = HybridRouter()
        
        # Simple task -> Local
        route1 = router.route("fix typo")
        self.assertEqual(route1, "LOCAL")
        
        # Complex task -> Relay
        route2 = router.route("architect a new cloud system with load balancing "*10)
        self.assertEqual(route2, "RELAY")
        
        # Mock Client (Async)
        import asyncio
        client = OllamaClient()
        # Since we are in a sync test method, we need to run async code
        res = asyncio.run(client.generate("hello", json_schema={"test": 1}))
        # Expect mock response if server not running
        self.assertTrue("mock" in res or "content" in res)
        
        print("[Pass] Intelligence Layer (Router/Client) Verified")

    def test_relay_queue(self):
        """Phase 2.5: Relay Queue Persistence"""
        q = RelayQueue() # In-memory for test
        tid = q.enqueue("Complex Prompt")
        
        task = q.dequeue()
        self.assertIsNotNone(task)
        self.assertEqual(task['id'], tid)
        
        q.complete(tid, "Response from Human")
        
        # Should be empty now
        task2 = q.dequeue()
        self.assertIsNone(task2)
        
        print("[Pass] Relay Layer (SQLite Queue) Verified")

    def test_semantic_action(self):
        """Phase 3: Validate ActionType, Validation, and SideEffects"""
        from scripts.ontology.actions import ActionType, SubmissionCriteria
        from scripts.ontology.side_effects import NotificationEffect
        
        # Define Action
        def is_high_priority(params):
            return params.get('priority') == 'high'

        action = ActionType(
            api_name="create_critical_task",
            display_name="Create Critical Task",
            parameters={"title": str, "priority": str},
            submission_criteria=[
                SubmissionCriteria(description="Must be high priority", validator=is_high_priority)
            ],
            side_effects=[
                NotificationEffect(recipient_id="admin", message_template="Critical Task Created: {title}")
            ]
        )
        
        # Test Validation Failure
        with self.assertRaises(ValueError):
            action.execute(title="Low Prio Task", priority="low")
            
        # Test Success + Side Effect
        # Ensure we capture stdout to verify print
        action.execute(title="Critical Bug", priority="high")
        print("[Pass] Semantic Action Layer Verified")

    def test_proposal_workflow(self):
        """Phase 4: Validate Proposal Object for HITL"""
        from scripts.ontology.objects.proposal import Proposal
        
        # 1. Draft Proposal
        prop = Proposal(
            action_type="deploy_production",
            parameters_json='{"version": "1.0.0"}',
            created_by_id="agent-007",
            status="pending"
        )
        self.assertEqual(prop.status, "pending")
        
        # 2. Approve (Simulated)
        prop.status = "approved"
        prop.reviewed_by_id = "human-admin"
        
        # 3. Kernel Execution (Stub verification)
        self.assertEqual(prop.status, "approved")
        self.assertEqual(prop.reviewed_by_id, "human-admin")
        print("[Pass] Proposal Workflow (HITL) Verified")

if __name__ == '__main__':
    unittest.main()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/e2e/test_v3_integration.py
# ========================================================

import unittest
import sys
import os

# Add project root to path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.client import FoundryClient
from scripts.ontology.objects.core_definitions import Task, Agent
from scripts.llm.ollama_client import HybridRouter, OllamaClient
from scripts.relay.queue import RelayQueue

class TestV3Migration(unittest.TestCase):
    
    def test_foundation_ontology(self):
        """Phase 1: Validate FoundryClient and Object Registry"""
        client = FoundryClient()
        
        # Register Types
        client.ontology.objects.register(Task)
        client.ontology.objects.register(Agent)
        
        # Test Object Creation via OSDK pattern
        my_task = client.ontology.objects.Task.create(title="Refactor Orion", priority="high")
        self.assertEqual(my_task.title, "Refactor Orion")
        self.assertEqual(my_task.priority, "high")
        self.assertTrue(hasattr(my_task, 'id'))
        
        print("\n[Pass] Foundation Layer (OSDK Pattern) Verified")

    def test_hybrid_intelligence(self):
        """Phase 2: Validate Router and Mock LLM"""
        router = HybridRouter()
        
        # Simple task -> Local
        route1 = router.route("fix typo")
        self.assertEqual(route1, "LOCAL")
        
        # Complex task -> Relay
        route2 = router.route("architect a new cloud system with load balancing "*10)
        self.assertEqual(route2, "RELAY")
        
        # Mock Client (Async)
        import asyncio
        client = OllamaClient()
        # Since we are in a sync test method, we need to run async code
        res = asyncio.run(client.generate("hello", json_schema={"test": 1}))
        # Expect mock response if server not running
        self.assertTrue("mock" in res or "content" in res)
        
        print("[Pass] Intelligence Layer (Router/Client) Verified")

    def test_relay_queue(self):
        """Phase 2.5: Relay Queue Persistence"""
        q = RelayQueue() # In-memory for test
        tid = q.enqueue("Complex Prompt")
        
        task = q.dequeue()
        self.assertIsNotNone(task)
        self.assertEqual(task['id'], tid)
        
        q.complete(tid, "Response from Human")
        
        # Should be empty now
        task2 = q.dequeue()
        self.assertIsNone(task2)
        
        print("[Pass] Relay Layer (SQLite Queue) Verified")

if __name__ == '__main__':
    unittest.main()


# ========================================================
# FILE: /home/palantir/orion-orchestrator-v2/tests/e2e/test_v3_production.py
# ========================================================

import unittest
import sys
import os
import asyncio
from typing import Dict, Any

# Add project root to path
sys.path.append("/home/palantir/orion-orchestrator-v2")

from scripts.ontology.objects.core_definitions import Task, Agent, CreateTaskAction
from scripts.ontology.objects.proposal import Proposal, ProposalStatus
from scripts.ontology.actions import ActionContext
from scripts.llm.ollama_client import HybridRouter, OllamaClient, RouterConfig
from scripts.relay.queue import RelayQueue

class TestV3Migration(unittest.TestCase):
    
    def test_foundation_ontology(self):
        """Phase 1: Validate Object Registry and Types"""
        # Test Object Creation
        my_task = Task(title="Refactor Orion", priority="high")
        self.assertEqual(my_task.title, "Refactor Orion")
        self.assertEqual(my_task.priority, "high")
        self.assertTrue(len(my_task.id) == 36)
        
        print("\n[Pass] Foundation Layer (Ontology Objects) Verified")

    def test_hybrid_intelligence(self):
        """Phase 2: Validate Router and Client"""
        config = RouterConfig()
        router = HybridRouter(config)
        
        # Simple task -> Local
        d1 = router.route("fix typo")
        self.assertEqual(d1.target.value, "LOCAL")
        
        # Complex task -> Relay
        d2 = router.route("architect a new cloud system with load balancing "*10)
        self.assertEqual(d2.target.value, "RELAY")
        
        # Mock Client (Async)
        client = OllamaClient(config)
        # We expect this to fail connection if server down, which is fine, 
        # or succeed if mocked. The key is import matches.
        # Check attributes
        self.assertTrue(hasattr(client, 'generate'))
        
        print("[Pass] Intelligence Layer (Router/Client) Verified")

    def test_relay_queue(self):
        """Phase 2.5: Relay Queue Persistence"""
        q = RelayQueue() # In-memory/SQLite
        tid = q.enqueue("Complex Prompt")
        
        task = q.dequeue()
        self.assertIsNotNone(task)
        self.assertEqual(task['id'], tid)
        
        q.complete(tid, "Response from Human")
        
        # Should be empty now
        task2 = q.dequeue()
        self.assertIsNone(task2)
        
        print("[Pass] Relay Layer (SQLite Queue) Verified")

    def test_semantic_action(self):
        """Phase 3: Validate ActionType"""
        action = CreateTaskAction()
        
        async def run_action():
            ctx = ActionContext.system()
            # Success
            res = await action.execute({'title': 'Critical Bug', 'priority': 'high'}, ctx)
            self.assertTrue(res.success)
            self.assertTrue(len(res.created_ids) > 0)
            
            # Failure
            res2 = await action.execute({'title': ''}, ctx)
            self.assertFalse(res2.success)
            
        asyncio.run(run_action())
        print("[Pass] Semantic Action Layer Verified")

    def test_proposal_workflow(self):
        """Phase 4: Validate Proposal Object for HITL"""
        # 1. Draft Proposal
        prop = Proposal(
            action_type="deploy_to_production",
            payload={"version": "1.0.0"},
            created_by="agent-007",
            status=ProposalStatus.DRAFT
        )
        self.assertEqual(prop.status, ProposalStatus.DRAFT)
        
        # 2. Submit
        prop.submit()
        self.assertEqual(prop.status, ProposalStatus.PENDING)
        
        # 3. Approve
        prop.approve(reviewer_id="human-admin", comment="LGTM")
        self.assertEqual(prop.status, ProposalStatus.APPROVED)
        self.assertEqual(prop.reviewed_by, "human-admin")
        
        print("[Pass] Proposal Workflow (HITL) Verified")

    def test_kernel_boot(self):
        """Phase 5: Verify Kernel Import"""
        try:
            from scripts.runtime.kernel import OrionRuntime
            print("[Pass] Kernel V3 Import Successful")
        except ImportError as e:
            self.fail(f"Kernel Move Failed: {e}")

if __name__ == '__main__':
    unittest.main()
