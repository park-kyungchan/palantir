---
name: golden-correct
description: |
  [D1·Drill·Correction] Generates corrected JSONL (Golden Sample) with segment-by-segment diff. Each correction explains rule violated, visual impact, and correct form.

  WHEN: After render-evaluate completes. Terminal skill in D1 drill cycle.
  DOMAIN: drill (skill 5 of 5). Terminal: golden-correct -> progress-track (D2).
  INPUT_FROM: render-evaluate (rendering diff + verdicts), jsonl-validate (JSONL errors), latex-parse (LaTeX errors), challenge-generate (golden answer).
  OUTPUT_TO: progress-track (correction count + categories).

  METHODOLOGY: (1) Retrieve hidden golden answer, (2) Align trainee vs golden segment-by-segment, (3) Explain each diff: rule + impact + fix, (4) Assemble corrected JSONL string, (5) Verify JSON.parse() + LaTeX validity.
  OUTPUT_FORMAT: L1 YAML correction summary, L2 diff table + golden JSONL string.
user-invocable: false
disable-model-invocation: false
---

# Drill — Golden Correct

## Execution Model
- **All levels**: Lead-direct. Correction generation is deterministic given upstream analysis.
- This is the "teaching moment" — every correction must be educational, not just mechanical.
- Terminal skill in the drill cycle. Output feeds progress-track for learning analytics.

## Decision Points

### Correction Presentation Strategy
```
IF render-evaluate.status == CRASH (JSON parse failure):
  -> Show minimal correction first: fix JSON structure only
  -> Then show full golden answer
  -> Lesson: "JSON validity is prerequisite — fix structure before content"

ELIF render-evaluate.score < 50%:
  -> Show corrections grouped by severity (FATAL → FAIL → WARN)
  -> Highlight the 3 most impactful corrections
  -> Full golden answer at end

ELIF render-evaluate.score >= 50%:
  -> Show segment-by-segment diff
  -> Each correction as a "micro-lesson"
  -> Golden answer at end as confirmation
```

### Diff Alignment Strategy
```
IF trainee submission structurally similar to golden:
  -> Character-level diff (precise alignment)
ELIF trainee submission restructured differently:
  -> Segment-level diff (match by mathematical content, not position)
ELIF trainee submission fundamentally different approach:
  -> Side-by-side comparison (trainee approach vs golden approach)
  -> Note if trainee approach is valid alternative
```

### Alternative Valid Solutions
```
IF trainee's approach is different but produces identical rendering:
  -> Mark as ✅ ALTERNATIVE VALID
  -> Show both approaches
  -> Note style preference if applicable
ELIF trainee's approach is different and produces different rendering:
  -> Mark as ❌ INCORRECT
  -> Show why golden approach is correct
```

## Methodology

### 1. Retrieve Golden Answer
Load the hidden golden answer generated by challenge-generate.
Verify it still passes validation (defensive check).

### 2. Segment-by-Segment Alignment
Align trainee and golden answers by mathematical content:

```
Trainee:  {"text": "함수 $f(x) = \frac{x^2}{2}$ 에서..."}
Golden:   {"text": "함수 $f(x) = \\frac{x^{2}}{2}$ 에서..."}
                                 ^^         ^^^
                                 |          |
                            escape fix  grouping fix
```

### 3. Explain Each Correction
For every diff point, provide a structured micro-lesson:

**Format:**
```
[Correction N] Category: ESCAPE | Rule: R1 (Backslash Double-Escape)
  Trainee: \frac
  Golden:  \\frac
  Rule: In JSONL, every LaTeX backslash must be double-escaped.
        \frac → JSON parser sees \ as escape character → tries to interpret \f
        \\frac → JSON parser sees \\ as literal \ → passes \frac to LaTeX
  Visual Impact: Without double-escape, JSON parser may fail entirely,
                 or produce garbled output where \f is interpreted as
                 a form feed character.
```

Each correction MUST include:
1. **What**: Exact characters that differ
2. **Why**: Which rule is violated (reference to JSONL R1-R5 or LaTeX rules)
3. **Impact**: What visual effect the error causes
4. **Fix**: The correct form with explanation

### 4. Assemble Complete Golden JSONL
Present the complete corrected string in a copyable format:

```json
{"text": "함수 $f(x) = \\frac{x^{2}}{2}$ 에서 $x > 0$일 때,\n$$\\int_0^x f(t)\\,dt = \\frac{x^{3}}{6}$$"}
```

Mark corrected portions with indicators:
```
{"text": "함수 $f(x) = [✓]\\frac{x^[✓]{2}}{2}$ 에서..."}
                        ^^^       ^^^
                     corrections marked
```

### 5. Verify Corrected String
Confirm the golden answer:
- Passes `JSON.parse()` — valid JSON
- Contains valid LaTeX — no syntax errors
- Renders correctly — matches target rendering
- All escape rules satisfied — R1-R5 compliant

## Failure Handling

### Golden Answer Has an Error
- **Cause**: Challenge generation produced imperfect golden answer
- **Action**: Self-correct the golden answer, note the issue, generate new verified answer
- **Route**: challenge-generate (flag for quality improvement)

### Trainee Solution Better Than Golden
- **Cause**: Trainee found a more elegant valid approach
- **Action**: Acknowledge the superior approach, update golden answer
- **Route**: progress-track (bonus points for superior solution)

### Too Many Corrections to Present
- **Cause**: >10 corrections — information overload
- **Action**: Group by category, present top 5 with "N more similar corrections"
- **Route**: progress-track (flag multiple weak areas)

## Anti-Patterns

### DO NOT: Just Show the Answer
The golden answer alone has no teaching value. Every correction must explain WHY.

### DO NOT: Use Diff Without Explanation
A character-level diff (`-\frac` / `+\\frac`) is insufficient. The trainee needs to understand the rule being violated, not just see the mechanical change.

### DO NOT: Present Corrections in Random Order
Order corrections by: FATAL → FAIL → WARN within each segment. Most impactful first.

### DO NOT: Skip Verification
Always verify the golden answer itself is correct. Trust but verify.

### DO NOT: Criticize the Trainee
Frame corrections as "the parser expects X" not "you made a mistake with X." The persona is a compiler, not a judge.

## Transitions

### Receives From
| Source | Data | Format |
|--------|------|--------|
| render-evaluate | Rendering diff, element verdicts | YAML L1 + L2 |
| jsonl-validate | JSONL errors with positions | YAML L1 |
| latex-parse | LaTeX errors with constructs | YAML L1 |
| challenge-generate | Golden answer (hidden) | Challenge spec |

### Sends To
| Target | Data | Trigger |
|--------|------|---------|
| progress-track | Correction count, categories, severity | Always (drill cycle complete) |

## Quality Gate
- Every correction has: what + why (rule) + impact + fix
- Golden answer verified: JSON parseable + LaTeX valid
- Corrections ordered by severity
- Alternative valid approaches acknowledged
- Complete JSONL string provided in copyable format

## Output

### L1
```yaml
domain: drill
skill: golden-correct
status: complete
correction_count: 0
categories:
  ESCAPE: 0
  GROUPING: 0
  OPERATOR: 0
  SIZING: 0
  TEXT: 0
  ENVIRONMENT: 0
  SEMANTIC: 0
severity:
  FATAL: 0
  FAIL: 0
  WARN: 0
alternative_valid: false
```

### L2
- Segment-by-segment correction table (what/why/impact/fix)
- Complete golden JSONL string (copyable)
- Verification confirmation
- Summary of rules violated (for trainee self-study)
