"""
ODA Prompt Template Library
===========================

Builds structured prompts with JSON Schema enforcement for subagents.
Ensures subagent outputs are always structured JSON.

V2.1.10 Feature: L2 Synthesizer + Structured Prompts

This module provides:
1. PromptTemplateBuilder - Main class for building structured prompts
2. Template loading from .claude/templates/prompts/
3. Schema injection from output_schemas.py
4. Budget recommendations per subagent type

Usage:
    from lib.oda.planning.prompt_templates import (
        PromptTemplateBuilder,
        build_structured_prompt,
        get_recommended_budget,
    )

    # Using builder class
    builder = PromptTemplateBuilder("explore")
    prompt = builder.build(
        task_description="Analyze auth module for security issues",
        budget=5000,
        additional_context="Focus on input validation"
    )

    # Using convenience function
    prompt = build_structured_prompt(
        subagent_type="explore",
        task_description="Analyze codebase structure",
        budget=5000
    )
"""

import json
from pathlib import Path
from typing import Optional

from lib.oda.planning.output_schemas import get_json_schema, SCHEMA_REGISTRY, L1Output


# Template directory
TEMPLATE_DIR = Path("/home/palantir/.claude/templates/prompts")


class PromptTemplateBuilder:
    """
    Builds structured prompts with JSON Schema enforcement.

    This class loads markdown templates for each subagent type and
    injects the appropriate JSON Schema to ensure structured output.

    Attributes:
        subagent_type: Normalized subagent type string
        schema: JSON Schema dictionary for the subagent type
        template: Loaded markdown template content

    Usage:
        builder = PromptTemplateBuilder("explore")
        prompt = builder.build(
            task_description="Analyze auth module for security issues",
            budget=5000,
            additional_context="Focus on input validation"
        )
    """

    def __init__(self, subagent_type: str):
        """
        Initialize builder for a specific subagent type.

        Args:
            subagent_type: One of "explore", "plan", "synthesis", "general-purpose"

        Raises:
            ValueError: If subagent_type is not supported
        """
        self.subagent_type = subagent_type.lower().replace("-", "_")
        self._validate_subagent_type()
        self.schema = get_json_schema(self._get_schema_key())
        self.template = self._load_template()

    def _get_schema_key(self) -> str:
        """Get the correct key for SCHEMA_REGISTRY lookup."""
        # Handle aliases
        if self.subagent_type in SCHEMA_REGISTRY:
            return self.subagent_type
        # Try with hyphen
        hyphenated = self.subagent_type.replace("_", "-")
        if hyphenated in SCHEMA_REGISTRY:
            return hyphenated
        return self.subagent_type

    def _validate_subagent_type(self) -> None:
        """Validate subagent type is supported."""
        valid_types = set()
        for key in SCHEMA_REGISTRY.keys():
            valid_types.add(key)
            valid_types.add(key.replace("-", "_"))
            valid_types.add(key.replace("_", "-"))

        if self.subagent_type not in valid_types:
            supported = sorted(set(SCHEMA_REGISTRY.keys()))
            raise ValueError(
                f"Unsupported subagent type: {self.subagent_type}. "
                f"Supported: {supported}"
            )

    def _load_template(self) -> str:
        """Load markdown template for this subagent type."""
        # Map subagent type to template file
        type_map = {
            "explore": "explore.md",
            "plan": "plan.md",
            "synthesis": "synthesis.md",
            "general_purpose": "general.md",
            "execution": "general.md",
        }

        template_name = type_map.get(self.subagent_type, "general.md")
        template_path = TEMPLATE_DIR / template_name

        if template_path.exists():
            return template_path.read_text()

        # Fallback to default template
        return self._default_template()

    def _default_template(self) -> str:
        """Return default template if specific template not found."""
        return """## Task
{task_description}

## MANDATORY: Output Schema
You MUST output ONLY valid JSON matching this schema:

```json
{schema_json}
```

## Constraints
- YOUR OUTPUT MUST NOT EXCEED {budget} TOKENS
- Output MUST be valid JSON (no text before/after)
- All string values properly quoted
- Follow the schema exactly

## Additional Context
{additional_context}
"""

    def build(
        self,
        task_description: str,
        budget: int = 5000,
        additional_context: str = "",
        include_examples: bool = False,
    ) -> str:
        """
        Build structured prompt with schema enforcement.

        Args:
            task_description: What the subagent should do
            budget: Maximum output tokens (enforced via prompt)
            additional_context: Extra context or constraints
            include_examples: Whether to include example outputs

        Returns:
            Formatted prompt string with embedded JSON Schema
        """
        schema_json = json.dumps(self.schema, indent=2)

        # Build the prompt
        prompt = self.template.format(
            task_description=task_description,
            schema_json=schema_json,
            budget=budget,
            additional_context=additional_context or "None provided.",
        )

        if include_examples:
            prompt += self._get_examples()

        return prompt

    def _get_examples(self) -> str:
        """Get example outputs for this subagent type."""
        examples = {
            "explore": '''

## Example Output
```json
{
  "summary": "Auth module has 3 critical input validation gaps",
  "files_analyzed": ["auth/login.py", "auth/session.py"],
  "patterns_found": ["singleton", "factory"],
  "findings": [
    {"file": "auth/login.py", "line": 42, "severity": "CRITICAL", "description": "No input sanitization on username", "category": "security"}
  ],
  "dependencies": ["bcrypt", "jwt"],
  "next_action_hint": "Add input validation middleware"
}
```
''',
            "plan": '''

## Example Output
```json
{
  "summary": "3-phase implementation for user authentication",
  "objective": "Add secure JWT-based authentication to the API",
  "total_phases": 3,
  "phases": [
    {"phase_number": 1, "name": "Setup", "tasks": ["Add dependencies", "Create models"], "dependencies": [], "estimated_effort": "small", "files_affected": ["requirements.txt"]}
  ],
  "critical_files": ["auth/models.py", "auth/views.py"],
  "risks": ["Session management complexity"],
  "prerequisites": ["Database connection configured"],
  "success_criteria": ["All auth tests pass"],
  "next_action_hint": "Start with Phase 1 setup tasks"
}
```
''',
            "synthesis": '''

## Example Output
```json
{
  "summary": "Synthesized 3 agent reports: 5 critical issues found across auth and API modules",
  "total_agents": 3,
  "agent_summaries": [
    {"agent_id": "a1b2c3d", "agent_type": "Explore", "status": "completed", "key_findings": ["SQL injection in user handler"], "files_referenced": ["lib/db.py"]}
  ],
  "critical_findings": ["SQL injection vulnerability", "Missing auth on admin endpoints"],
  "cross_module_concerns": ["Auth module tightly coupled with database layer"],
  "consolidated_files": ["lib/db.py", "lib/auth.py", "lib/api.py"],
  "recommended_next_action": "Fix SQL injection in lib/db.py first",
  "additional_recommendations": ["Add integration tests for auth flow"]
}
```
''',
            "general_purpose": '''

## Example Output
```json
{
  "summary": "Successfully implemented user authentication feature",
  "status": "success",
  "files_created": ["lib/auth/jwt.py", "lib/auth/middleware.py"],
  "files_modified": ["lib/api/routes.py", "requirements.txt"],
  "files_deleted": [],
  "verification_results": {"tests": "passed", "lint": "passed", "type_check": "passed"},
  "errors": [],
  "warnings": ["Consider adding rate limiting"],
  "next_action_hint": "Run full integration test suite"
}
```
''',
        }
        return examples.get(self.subagent_type, "")

    def get_schema_block(self) -> str:
        """Get just the schema block for manual prompt construction."""
        return f"""## MANDATORY: Output Schema
You MUST output ONLY valid JSON matching this schema:

```json
{json.dumps(self.schema, indent=2)}
```"""


def build_structured_prompt(
    subagent_type: str,
    task_description: str,
    budget: int = 5000,
    additional_context: str = "",
    include_examples: bool = False,
) -> str:
    """
    Convenience function to build a structured prompt.

    Args:
        subagent_type: Type of subagent ("explore", "plan", etc.)
        task_description: Task for the subagent
        budget: Output token budget
        additional_context: Extra context
        include_examples: Whether to include example outputs

    Returns:
        Formatted prompt with JSON Schema enforcement

    Example:
        >>> prompt = build_structured_prompt(
        ...     subagent_type="explore",
        ...     task_description="Analyze auth module",
        ...     budget=5000
        ... )
        >>> "JSON" in prompt
        True
    """
    builder = PromptTemplateBuilder(subagent_type)
    return builder.build(
        task_description=task_description,
        budget=budget,
        additional_context=additional_context,
        include_examples=include_examples,
    )


# Budget recommendations by subagent type
RECOMMENDED_BUDGETS = {
    "explore": 5000,
    "plan": 10000,
    "synthesis": 500,  # Intentionally small for L2 Synthesizer
    "general_purpose": 15000,
    "execution": 15000,
}


def get_recommended_budget(subagent_type: str) -> int:
    """
    Get recommended output budget for a subagent type.

    Args:
        subagent_type: Type of subagent

    Returns:
        Recommended token budget for the subagent type

    Example:
        >>> get_recommended_budget("explore")
        5000
        >>> get_recommended_budget("synthesis")
        500
    """
    normalized = subagent_type.lower().replace("-", "_")
    return RECOMMENDED_BUDGETS.get(normalized, 10000)


def list_available_templates() -> list[str]:
    """
    List all available prompt templates.

    Returns:
        List of template names (subagent types)
    """
    return sorted(set(SCHEMA_REGISTRY.keys()))


def get_template_path(subagent_type: str) -> Path:
    """
    Get the file path for a subagent's template.

    Args:
        subagent_type: Type of subagent

    Returns:
        Path to the template file (may not exist if using default)
    """
    type_map = {
        "explore": "explore.md",
        "plan": "plan.md",
        "synthesis": "synthesis.md",
        "general_purpose": "general.md",
        "execution": "general.md",
    }
    normalized = subagent_type.lower().replace("-", "_")
    template_name = type_map.get(normalized, "general.md")
    return TEMPLATE_DIR / template_name


# Export all public symbols
__all__ = [
    # Main class
    "PromptTemplateBuilder",
    # Convenience functions
    "build_structured_prompt",
    "get_recommended_budget",
    "list_available_templates",
    "get_template_path",
    # Constants
    "RECOMMENDED_BUDGETS",
    "TEMPLATE_DIR",
]
