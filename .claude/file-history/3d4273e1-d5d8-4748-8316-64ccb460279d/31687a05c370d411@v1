"""
Orion ODA v4.0 - LLM-Native Intent Classifier

Main entry point for intent classification.
Replaces TriggerDetector with LLM-based semantic understanding.

User Requirements (2026-01-13):
- "복잡한 과정 필요없이 LLM에게만 맡기려고 함"
- "완전 제거" (TriggerDetector)
- "커스텀 커맨드 고도화" (/ask, /plan, /audit)
- "실제 코드 수정 전까지는 LLM의 최대성능과 기능을 최대로 활용"

Design:
- No keywords, no regex, no Jaccard
- Direct LLM classification
- Simple, focused interface
"""
from __future__ import annotations

import asyncio
import logging
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Union

from lib.oda.llm.intent_adapter import (
    BaseIntentAdapter,
    CommandDescription,
    IntentAdapter,
    IntentMatchType,
    IntentResult,
)

logger = logging.getLogger(__name__)


# =============================================================================
# CONFIGURATION
# =============================================================================

@dataclass
class IntentClassifierConfig:
    """
    Configuration for IntentClassifier.

    Simplified configuration focused on LLM-first approach.
    """
    # Confidence thresholds
    clarification_threshold: float = 0.7  # Below this, ask user
    min_confidence: float = 0.3  # Below this, fallback to /ask

    # Adapter settings
    adapter_type: str = "claude"  # claude, openai, gemini, local
    enable_telemetry: bool = True

    # Default commands if none provided
    use_default_commands: bool = True


# =============================================================================
# DEFAULT COMMANDS
# =============================================================================

DEFAULT_COMMANDS: List[CommandDescription] = [
    CommandDescription(
        name="/ask",
        description="요구사항 분석 및 명확화, 프롬프트 엔지니어링, 사용자 의도 파악",
        examples=["도와줘", "이해 안돼", "어떻게 해야해?", "모르겠어"]
    ),
    CommandDescription(
        name="/plan",
        description="구현 계획 수립, 아키텍처 설계, 작업 분해",
        examples=["계획 세워줘", "어떻게 구현할지", "설계해줘", "구현"]
    ),
    CommandDescription(
        name="/audit",
        description="코드 품질 검사, 3-Stage Protocol, 코드 리뷰",
        examples=["코드 리뷰해줘", "검사해줘", "품질 확인", "리뷰"]
    ),
    CommandDescription(
        name="/deep-audit",
        description="심층 분석, RSIL 방법론, 집중 검토",
        examples=["깊이 분석해줘", "심층 검토", "자세히 봐줘", "분석"]
    ),
    CommandDescription(
        name="/governance",
        description="거버넌스 준수 확인, 제안 검토, 정책 확인",
        examples=["거버넌스 확인", "정책 검토", "규칙 확인"]
    ),
    CommandDescription(
        name="/memory",
        description="시맨틱 메모리 관리, 인사이트/패턴 저장",
        examples=["기억해", "저장해", "메모리 관리"]
    ),
    CommandDescription(
        name="/quality-check",
        description="품질 게이트 실행, E2E 테스트, 설정 검사",
        examples=["품질 검사", "테스트 실행", "검증"]
    ),
]


# =============================================================================
# INTENT CLASSIFIER
# =============================================================================

class IntentClassifier:
    """
    LLM-Native Intent Classifier.

    Simple, focused classifier that delegates to LLM for intent understanding.
    No complex fallback layers - just LLM classification.

    Usage:
        classifier = IntentClassifier()
        result = await classifier.classify("코드 리뷰해줘")
        print(result.command)  # "/audit"
        print(result.confidence)  # 0.92
    """

    def __init__(
        self,
        adapter: Optional[IntentAdapter] = None,
        config: Optional[IntentClassifierConfig] = None,
        commands: Optional[List[CommandDescription]] = None
    ):
        """
        Initialize IntentClassifier.

        Args:
            adapter: LLM adapter for classification (auto-created if None)
            config: Configuration options
            commands: Available commands (uses defaults if None)
        """
        self.config = config or IntentClassifierConfig()
        self._commands = commands or (DEFAULT_COMMANDS if self.config.use_default_commands else [])
        self._adapter = adapter or self._create_default_adapter()
        self._logger = logging.getLogger(f"{__name__}.IntentClassifier")

    def _create_default_adapter(self) -> IntentAdapter:
        """Create default adapter based on config."""
        adapter_type = self.config.adapter_type.lower()

        if adapter_type == "claude":
            from lib.oda.llm.adapters.claude_intent_adapter import ClaudeIntentAdapter
            return ClaudeIntentAdapter(mode="embedded")

        elif adapter_type == "openai":
            from lib.oda.llm.adapters.openai_intent_adapter import OpenAIIntentAdapter
            return OpenAIIntentAdapter()

        elif adapter_type == "gemini":
            from lib.oda.llm.adapters.gemini_intent_adapter import GeminiIntentAdapter
            return GeminiIntentAdapter()

        elif adapter_type == "local":
            from lib.oda.llm.adapters.local_intent_adapter import LocalIntentAdapter
            return LocalIntentAdapter()

        else:
            self._logger.warning(f"Unknown adapter type: {adapter_type}, using Claude")
            from lib.oda.llm.adapters.claude_intent_adapter import ClaudeIntentAdapter
            return ClaudeIntentAdapter(mode="embedded")

    @property
    def commands(self) -> List[CommandDescription]:
        """Get available commands."""
        return self._commands

    @commands.setter
    def commands(self, value: List[CommandDescription]):
        """Set available commands."""
        self._commands = value

    def add_command(self, command: CommandDescription):
        """Add a new command."""
        self._commands.append(command)

    def remove_command(self, name: str):
        """Remove a command by name."""
        self._commands = [c for c in self._commands if c.name != name]

    async def classify(
        self,
        user_input: str,
        commands: Optional[List[CommandDescription]] = None
    ) -> IntentResult:
        """
        Classify user intent.

        This is the main entry point for intent classification.
        Simple flow:
        1. Check explicit command (/xxx)
        2. Delegate to LLM for natural language

        Args:
            user_input: User's input to classify
            commands: Optional override for available commands

        Returns:
            IntentResult with command, confidence, reasoning
        """
        start_time = time.time()
        cmds = commands or self._commands

        self._logger.debug(f"Classifying: {user_input[:50]}...")

        try:
            result = await self._adapter.classify(user_input, cmds)

            # Apply confidence threshold
            if result.confidence < self.config.min_confidence:
                self._logger.info(
                    f"Low confidence ({result.confidence:.2f}), "
                    f"defaulting to /ask"
                )
                result = IntentResult(
                    command="/ask",
                    confidence=self.config.min_confidence,
                    reasoning=f"Low confidence classification, using /ask for clarification. "
                              f"Original: {result.reasoning}",
                    match_type=IntentMatchType.FALLBACK,
                    raw_input=user_input
                )

            # Log telemetry
            if self.config.enable_telemetry:
                latency_ms = (time.time() - start_time) * 1000
                self._log_telemetry(result, latency_ms)

            return result

        except Exception as e:
            self._logger.error(f"Classification error: {e}")
            return IntentResult(
                command="/ask",
                confidence=0.0,
                reasoning=f"Classification failed: {str(e)}",
                match_type=IntentMatchType.FALLBACK,
                raw_input=user_input
            )

    def classify_sync(
        self,
        user_input: str,
        commands: Optional[List[CommandDescription]] = None
    ) -> IntentResult:
        """
        Synchronous wrapper for classify().

        Useful for non-async contexts.
        """
        return asyncio.run(self.classify(user_input, commands))

    def needs_clarification(self, result: IntentResult) -> bool:
        """
        Check if result needs user clarification.

        Args:
            result: Classification result to check

        Returns:
            True if clarification needed
        """
        return (
            result.confidence < self.config.clarification_threshold and
            result.match_type != IntentMatchType.EXPLICIT
        )

    def _log_telemetry(self, result: IntentResult, latency_ms: float):
        """Log classification telemetry."""
        self._logger.info(
            f"Intent: {result.command} | "
            f"Confidence: {result.confidence:.2f} | "
            f"Type: {result.match_type.value} | "
            f"Latency: {latency_ms:.1f}ms"
        )


# =============================================================================
# FACTORY FUNCTIONS
# =============================================================================

def create_intent_classifier(
    adapter_type: str = "claude",
    commands: Optional[List[CommandDescription]] = None
) -> IntentClassifier:
    """
    Factory function for IntentClassifier.

    Args:
        adapter_type: Type of LLM adapter (claude, openai, gemini, local)
        commands: Available commands

    Returns:
        Configured IntentClassifier
    """
    config = IntentClassifierConfig(adapter_type=adapter_type)
    return IntentClassifier(config=config, commands=commands)


def get_default_commands() -> List[CommandDescription]:
    """Get the default command list."""
    return DEFAULT_COMMANDS.copy()


# =============================================================================
# BACKWARD COMPATIBILITY (TriggerDetector interface)
# =============================================================================

class LegacyTriggerMatch:
    """
    Legacy TriggerMatch interface for backward compatibility.

    Maps IntentResult to the old TriggerMatch format.
    """

    def __init__(self, intent_result: IntentResult):
        self._result = intent_result

    @property
    def skill_name(self) -> str:
        """Map command to skill name."""
        # Remove leading slash for skill name
        cmd = self._result.command
        return cmd[1:] if cmd.startswith('/') else cmd

    @property
    def confidence(self) -> float:
        return self._result.confidence

    @property
    def matched_keyword(self) -> Optional[str]:
        """Legacy field - always None for LLM classification."""
        return None

    @property
    def context_similarity(self) -> float:
        """Legacy field - map to confidence."""
        return self._result.confidence

    def to_dict(self) -> Dict[str, Any]:
        return {
            "skill_name": self.skill_name,
            "confidence": self.confidence,
            "matched_keyword": self.matched_keyword,
            "context_similarity": self.context_similarity,
            "reasoning": self._result.reasoning,
        }


def convert_to_trigger_match(intent_result: IntentResult) -> LegacyTriggerMatch:
    """Convert IntentResult to legacy TriggerMatch format."""
    return LegacyTriggerMatch(intent_result)
