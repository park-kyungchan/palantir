#!/bin/bash
# =============================================================================
# pd-task-processor.sh - Unified PostToolUse Hook for Task Subagents
# =============================================================================
# Consolidated from: post-task-output.sh + pd-posttooluse.sh
# Captures Agent ID for resume support and logs L1 summary with priority.
# Provides guidance to Main Agent based on priority level.
#
# Matcher: Task
# Version: 2.0.0 (Unified)
# Exit Codes:
#   0 - Success (with optional JSON output)
# =============================================================================

# Don't exit on error - handle failures gracefully
set +e

#=============================================================================
# Configuration
#=============================================================================

WORKSPACE_ROOT="${CLAUDE_WORKSPACE_ROOT:-$(pwd)}"
LOG_DIR="${WORKSPACE_ROOT}/.agent/logs"
TASK_LOG_FILE="${LOG_DIR}/task_execution.log"
AGENT_LOG_FILE="${LOG_DIR}/agent_ids.log"

# Cache configuration
CACHE_DIR="${HOME}/.claude/cache/l1l2"
CACHE_ENABLED="${CACHE_ENABLED:-true}"

# Ensure directories exist
mkdir -p "$LOG_DIR" 2>/dev/null
mkdir -p "$CACHE_DIR" 2>/dev/null

#=============================================================================
# JSON Helper (with jq fallback to python3)
#=============================================================================

HAS_JQ=false
if command -v jq &> /dev/null; then
    HAS_JQ=true
fi

json_get() {
    local field="$1"
    local json="$2"

    if $HAS_JQ; then
        echo "$json" | jq -r "$field // empty" 2>/dev/null || echo ""
    else
        echo "$json" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    keys = '$field'.lstrip('.').split('.')
    val = data
    for k in keys:
        if isinstance(val, dict):
            val = val.get(k, '')
        else:
            val = ''
    print(val if val else '')
except:
    print('')
" 2>/dev/null || echo ""
    fi
}

#=============================================================================
# YAML Field Extractor (with grep -oP fallback)
#=============================================================================

# Check grep -oP support once (Perl regex)
HAS_GREP_P=false
if echo "test" | grep -oP 'test' &>/dev/null; then
    HAS_GREP_P=true
fi

extract_yaml_field() {
    local field="$1"
    local text="$2"
    local default="${3:-}"

    # Try grep -oP first (Perl regex) - cached check
    if $HAS_GREP_P; then
        result=$(echo "$text" | grep -oP "${field}:\s*\K[^\s]+" 2>/dev/null | head -1)
        if [ -n "$result" ]; then
            echo "$result"
            return
        fi
    fi

    # Fallback: Python extraction (use stdin for safety)
    result=$(echo "$text" | python3 -c "
import sys, re
text = sys.stdin.read()
match = re.search(r'${field}:\s*(\S+)', text)
print(match.group(1) if match else '')
" 2>/dev/null)

    if [ -n "$result" ]; then
        echo "$result"
    else
        echo "$default"
    fi
}

#=============================================================================
# Cache Functions
#=============================================================================

save_to_cache() {
    local input_hash="$1"
    local l1_summary="$2"
    local agent_id="$3"
    local task_id="$4"
    local priority="$5"
    local status="$6"

    if [[ -z "$input_hash" || "$CACHE_ENABLED" != "true" ]]; then
        return 0
    fi

    local cache_file="${CACHE_DIR}/${input_hash}.json"
    local timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)

    if $HAS_JQ; then
        jq -n \
            --arg l1 "$l1_summary" \
            --arg aid "$agent_id" \
            --arg tid "$task_id" \
            --arg pri "$priority" \
            --arg st "$status" \
            --arg ts "$timestamp" \
            --arg hash "$input_hash" \
            '{
                l1Summary: $l1,
                metadata: {
                    originalAgentId: $aid,
                    taskId: $tid,
                    priority: $pri,
                    status: $st,
                    createdAt: $ts,
                    inputHash: $hash,
                    hits: 0
                }
            }' > "$cache_file" 2>/dev/null
    else
        python3 -c "
import json, sys
data = {
    'l1Summary': '''$l1_summary''',
    'metadata': {
        'originalAgentId': '$agent_id',
        'taskId': '$task_id',
        'priority': '$priority',
        'status': '$status',
        'createdAt': '$timestamp',
        'inputHash': '$input_hash',
        'hits': 0
    }
}
print(json.dumps(data, indent=2))
" > "$cache_file" 2>/dev/null
    fi

    return 0
}

#=============================================================================
# Session ID Reading (from file registry)
#=============================================================================

SESSION_REGISTRY="${HOME}/.agent/tmp/current_session.json"
ORCHESTRATOR_SESSION_ID="unknown"
if [ -f "$SESSION_REGISTRY" ]; then
    ORCHESTRATOR_SESSION_ID=$(json_get '.sessionId' "$(cat "$SESSION_REGISTRY")")
    [ -z "$ORCHESTRATOR_SESSION_ID" ] && ORCHESTRATOR_SESSION_ID="unknown"
fi

#=============================================================================
# Main Logic
#=============================================================================

INPUT=$(cat)
TOOL_NAME=$(json_get '.tool_name' "$INPUT")

# Only process Task tool results
if [[ "$TOOL_NAME" != "Task" ]]; then
    echo '{}'
    exit 0
fi

# Extract result info
AGENT_ID=$(json_get '.tool_result.agent_id' "$INPUT")
OUTPUT=$(json_get '.tool_result.output' "$INPUT")
SUBAGENT_TYPE=$(json_get '.tool_input.subagent_type' "$INPUT")
CACHE_INPUT_HASH=$(json_get '.tool_input._cacheInputHash' "$INPUT")
[ -z "$SUBAGENT_TYPE" ] && SUBAGENT_TYPE="unknown"

#=============================================================================
# Skip L1 parsing for conversational agents (sync with pd-task-interceptor.sh)
#=============================================================================
SKIP_AGENTS=(
    "prompt-assistant"
    "onboarding-guide"
    "statusline-setup"
    "claude-code-guide"
)

for skip in "${SKIP_AGENTS[@]}"; do
    if [[ "$SUBAGENT_TYPE" == "$skip" ]]; then
        # Log as non-L1 agent and exit early
        cat >> "$TASK_LOG_FILE" <<EOF
---
timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)
agent_id: $AGENT_ID
subagent_type: $SUBAGENT_TYPE
l1_compatible: false
note: "Conversational agent - L1/L2/L3 format not applicable"
---
EOF
        # Output minimal response
        cat <<RESPONSE
{
  "hookSpecificOutput": {
    "agentId": "$AGENT_ID",
    "l1Compatible": false
  }
}
RESPONSE
        exit 0
    fi
done

# Extract L1 fields from output (if present)
TASK_ID=$(extract_yaml_field 'taskId' "$OUTPUT" "")
PRIORITY=$(extract_yaml_field 'priority' "$OUTPUT" "")
STATUS=$(extract_yaml_field 'status' "$OUTPUT" "")
FINDINGS_COUNT=$(extract_yaml_field 'findingsCount' "$OUTPUT" "0")
CRITICAL_COUNT=$(extract_yaml_field 'criticalCount' "$OUTPUT" "0")
L2_PATH=$(extract_yaml_field 'l2Path' "$OUTPUT" "")
REQUIRES_L2=$(extract_yaml_field 'requiresL2Read' "$OUTPUT" "false")

# Check if L1 format was properly detected
L1_DETECTED=true
if [[ -z "$TASK_ID" || -z "$PRIORITY" ]]; then
    L1_DETECTED=false
    TASK_ID="${TASK_ID:-auto-$(date +%s | tail -c 9)}"
    PRIORITY="${PRIORITY:-UNSPECIFIED}"
    STATUS="${STATUS:-completed}"
fi

#=============================================================================
# Logging (Unified from both hooks)
#=============================================================================

# Log to task execution log (detailed)
cat >> "$TASK_LOG_FILE" <<EOF
---
timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)
agent_id: $AGENT_ID
task_id: $TASK_ID
subagent_type: $SUBAGENT_TYPE
l1_detected: $L1_DETECTED
priority: $PRIORITY
status: $STATUS
findings_count: $FINDINGS_COUNT
critical_count: $CRITICAL_COUNT
l2_path: $L2_PATH
requires_l2_read: $REQUIRES_L2
---
EOF

# Log agent ID for resume support (P7 pattern)
if [[ -n "$AGENT_ID" ]]; then
    echo "$(date -Iseconds) | AgentID: $AGENT_ID | Type: $SUBAGENT_TYPE | Priority: $PRIORITY" >> "$AGENT_LOG_FILE"
fi

#=============================================================================
# Cache L1 Result (for future reuse)
#=============================================================================

if [[ "$L1_DETECTED" == "true" && -n "$CACHE_INPUT_HASH" ]]; then
    # Extract L1 summary block from output
    L1_SUMMARY=$(echo "$OUTPUT" | python3 -c "
import sys, re
text = sys.stdin.read()
# Extract YAML block between \`\`\`yaml and \`\`\`
match = re.search(r'\`\`\`yaml\s*\n(.*?)\n\`\`\`', text, re.DOTALL)
if match:
    print(match.group(1))
else:
    # Fallback: extract key fields
    lines = []
    for field in ['taskId', 'agentType', 'summary', 'status', 'priority', 'l2Path']:
        m = re.search(rf'{field}:\s*(.+)', text)
        if m:
            lines.append(f'{field}: {m.group(1).strip()}')
    print('\n'.join(lines))
" 2>/dev/null)

    if [[ -n "$L1_SUMMARY" ]]; then
        save_to_cache "$CACHE_INPUT_HASH" "$L1_SUMMARY" "$AGENT_ID" "$TASK_ID" "$PRIORITY" "$STATUS"
    fi
fi

#=============================================================================
# Prompt File Lifecycle Management (pending â†’ completed)
#=============================================================================

if [[ -n "$ORCHESTRATOR_SESSION_ID" && "$ORCHESTRATOR_SESSION_ID" != "unknown" ]]; then
    PENDING_DIR="${WORKSPACE_ROOT}/.agent/prompts/pending"
    COMPLETED_DIR="${WORKSPACE_ROOT}/.agent/prompts/completed"
    LIFECYCLE_LOG="${WORKSPACE_ROOT}/.agent/logs/prompt_lifecycle.log"

    # Find prompt file by session prefix and recent timestamp (within 5 minutes)
    SESSION_PREFIX="${ORCHESTRATOR_SESSION_ID:0:8}"
    PROMPT_FILE=$(find "$PENDING_DIR" -name "${SESSION_PREFIX}-*.yaml" -mmin -5 2>/dev/null | head -1)

    if [[ -n "$PROMPT_FILE" && -f "$PROMPT_FILE" ]]; then
        mkdir -p "$COMPLETED_DIR" 2>/dev/null

        # Move prompt file to completed directory
        PROMPT_FILENAME=$(basename "$PROMPT_FILE")
        mv "$PROMPT_FILE" "$COMPLETED_DIR/" 2>/dev/null

        if [[ $? -eq 0 ]]; then
            # Log the lifecycle transition for audit trail
            echo "$(date -Iseconds) | MOVED | ${PROMPT_FILENAME} | Session: ${ORCHESTRATOR_SESSION_ID} | Agent: ${AGENT_ID}" >> "$LIFECYCLE_LOG"
        fi
    fi
fi

#=============================================================================
# Generate Guidance for Main Agent
#=============================================================================

GUIDANCE=""
case "$PRIORITY" in
    "CRITICAL")
        GUIDANCE="CRITICAL priority detected. MUST read recommendedRead sections in L3 immediately."
        ;;
    "HIGH")
        GUIDANCE="HIGH priority. SHOULD read recommendedRead sections in L3."
        ;;
    "MEDIUM")
        GUIDANCE="MEDIUM priority. MAY read L3 sections on demand."
        ;;
    "LOW")
        GUIDANCE="LOW priority. L1 summary is sufficient, skip L3."
        ;;
    *)
        GUIDANCE="Review L1 summary and decide if L3 reading is needed."
        ;;
esac

#=============================================================================
# Output Response
#=============================================================================

# Determine if cache was saved
CACHE_SAVED="false"
if [[ "$L1_DETECTED" == "true" && -n "$CACHE_INPUT_HASH" && -n "$L1_SUMMARY" ]]; then
    CACHE_SAVED="true"
fi

# Output guidance for CRITICAL/HIGH priority, or minimal output for others
if [[ "$PRIORITY" == "CRITICAL" || "$PRIORITY" == "HIGH" ]]; then
    cat <<RESPONSE
{
  "hookSpecificOutput": {
    "guidance": "$GUIDANCE",
    "l2Path": "$L2_PATH",
    "agentId": "$AGENT_ID",
    "priority": "$PRIORITY",
    "criticalCount": $CRITICAL_COUNT,
    "cacheSaved": $CACHE_SAVED,
    "cacheKey": "${CACHE_INPUT_HASH:-null}"
  }
}
RESPONSE
else
    cat <<RESPONSE
{
  "hookSpecificOutput": {
    "agentId": "$AGENT_ID",
    "priority": "$PRIORITY",
    "cacheSaved": $CACHE_SAVED
  }
}
RESPONSE
fi

exit 0
