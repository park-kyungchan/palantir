# Implementation: Vision-Native Prompt Engineering

To bridge the gap between "Pixels" (PDF Images) and "Structure" (SVDOM JSON), the pipeline uses a highly prescriptive system prompt for Vision Models (e.g., Gemini 3.0 Pro).

## 1. Prompt Objectives

The prompt is designed to minimize hallucination and maximize structural fidelity by:
- **Strict Format Enforcement**: Requiring RAW JSON output only.
- **Visual-Semantic Labeling**: Forcing the model to distinguish between content `type` (what it physically is) and `role` (how it functions).
- **Spatial Reasoning**: Explicitly requesting bounding boxes (`bbox`) in a normalized percentage-based coordinate system.

## 2. Core Instructions (De-rendering Rules)

### 2.1 Visual Handling
The model is instructed to never merge "Body Text" with "Tables". Tables must be treated as structural 2D arrays, preserving the internal flow and headers.

### 2.2 Mathematical Parsing
A critical component of "High-Fidelity" is the de-rendering of formulas into **LaTeX**. The model is instructed to ignore OCR artifacts and prioritize the mathematical logic of the visual expression.

### 2.3 De-rendering Depth: "Atomic"
The prompt sets a parameter `[De-rendering Depth] = High`. This instructs the model to split every distinct visual block (paragraph, equation, cell) into a separate SVDOM `Block`. This prevents large, uneditable "mega-blocks" of text.

## 3. Usage Pattern

The prompt is stored in `prompts/vision_derender.md` and should be used in a "Sequential Execution" loop:
1.  **Pre-processing**: Convert PDF pages to high-DPI images.
2.  **Vision Call**: Send image + System Prompt to the Vision API.
3.  **Ingestion**: Validate the resulting JSON against the `DigitalTwin` Pydantic schema to ensure downstream reliability.
